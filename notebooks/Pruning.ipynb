{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "081025ff",
   "metadata": {},
   "source": [
    "# TEST DELLE SOLUZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b705bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST CONCLUSO CON SUCCESSO!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cvxpy as cp\n",
    "\n",
    "def knapsack_specialized_pruning(xi, v, w, C):\n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "\n",
    "    if(w > v[-1] or w < v[0]):\n",
    "        #print(\"No solutions.\")\n",
    "        x = None\n",
    "        objective_values = None\n",
    "    else:\n",
    "        b_vector = np.argsort(xi/v)\n",
    "        b = 0\n",
    "        b_list_new = [b_vector[b]] \n",
    "        while(w/v[b_vector[b]] > 1 or x_plus[b_vector[b]] == 0 or int(b_vector[b]) < int(b_list_new[0])):\n",
    "            b += 1\n",
    "            if(x_plus[b_vector[b]] == 1 and int(b_vector[b]) > int(b_list_new[0])):\n",
    "                b_list_new.append(b_vector[b])\n",
    "            if(len(b_list_new) > 2):\n",
    "                b_list_new.pop(0)\n",
    "        \n",
    "        x = np.zeros(C)\n",
    "        \n",
    "        if(len(b_list_new) == 1):\n",
    "            x[b_list_new[0]] = round(float(w/v[b_list_new[0]]), 2)\n",
    "        else:\n",
    "            x1, x2 = torch.zeros(2, len(w), C, dtype=torch.float32)\n",
    "            x1[torch.arange(len(w)), b_list_new[0]] = 1\n",
    "            x2[torch.arange(len(w)), b_list_new[1]] = 1\n",
    "            numerator = w - torch.matmul(x2, v)\n",
    "            denominator = torch.matmul((x1 - x2), v)\n",
    "            theta = numerator / denominator\n",
    "            x[b_list_new[0]] = round(float(theta), 2)\n",
    "            x[b_list_new[1]] = round(float(1 - theta), 2)\n",
    "        objective_values = torch.matmul(torch.from_numpy(x).float(), xi) \n",
    "    \n",
    "    lambda_opt = 0\n",
    "    \n",
    "    return x, lambda_opt, objective_values, x_plus\n",
    "\n",
    "# Dimension of vectors xi, v, and x\n",
    "C = 5\n",
    "M = 1\n",
    "\n",
    "np.random.seed(43)  \n",
    "torch.manual_seed(43)\n",
    "for i in range(1000):\n",
    "    xi = torch.sort(torch.rand(C))[0]\n",
    "    v = torch.linspace(0, 1 - (1 / C), C)\n",
    "    w = torch.rand(M)\n",
    "    #w = v[torch.randint(0, C, (1,))]  \n",
    "    \n",
    "    #print(f\"\\nIteration: {i}\")\n",
    "    #print(\"DATI:\")\n",
    "    #print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "    #print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "    #print(\"w:\", w, \"\\n\")\n",
    "    \n",
    "    x_opt, lambda_opt, phi_opt, x_plus = knapsack_specialized_pruning(xi, v, w, C)\n",
    "    \n",
    "    # cvxpy solution with inequality constraint (pruning)\n",
    "    x_pruning = cp.Variable(C)\n",
    "    equality_constraint_pruning = v @ x_pruning == w\n",
    "    constraints_pruning = [\n",
    "        equality_constraint_pruning,\n",
    "        cp.sum(x_pruning) <= 1,\n",
    "        x_pruning >= 0,\n",
    "        x_pruning <= 1\n",
    "    ]\n",
    "    objective_pruning = cp.Minimize(xi @ x_pruning)\n",
    "    prob_pruning = cp.Problem(objective_pruning, constraints_pruning)\n",
    "    prob_pruning.solve(solver=cp.CLARABEL)\n",
    "\n",
    "    #if prob_pruning.value is not None and x_pruning.value is not None:\n",
    "    #    print(f\"Objective value (pruning): {prob_pruning.value:.2f}\")\n",
    "    #    print(\"Optimal x (pruning):\", \n",
    "    #          np.array2string(x_pruning.value, precision=2, separator=', ', suppress_small=True))\n",
    "    #else:\n",
    "    #    print(\"No solution found for the problem with pruning.\")\n",
    "        \n",
    "    if(phi_opt is not None):\n",
    "        #print(\"Objective value (knapsack_specialized_pruning):\", round(float(phi_opt), 2))\n",
    "        #print(\"Optimal x (knapsack_specialized_pruning):\", x_opt)\n",
    "        x1 = []\n",
    "        x2 = []\n",
    "        SUCCESS = 1\n",
    "        for j in range(C):\n",
    "            x1.append(round(float(x_pruning.value[j]), 2))\n",
    "            x2.append(round(float(x_opt[j]), 2))\n",
    "        if(x1 != x2):\n",
    "            SUCCESS = 0\n",
    "            print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "            print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "            print(\"w:\", round(float(w), 4), \"\\n\")\n",
    "            print(\"xi/v:\", xi/v)\n",
    "            for k in range(C):\n",
    "                print(f\"w/v[{k}]: {w/v[k]}\")\n",
    "            print(\"x_plus:\", x_plus)\n",
    "            print(\"Soluzione del solver:\", x1)\n",
    "            print(\"Soluzione mia:\", x2)\n",
    "            print(\"f.o. solver:\", round(prob_pruning.value, 4))\n",
    "            print(\"f.o. mia:\", round(float(phi_opt), 4))\n",
    "            print(f\"Il vincolo w=v*x è soddisfatto con la mia soluzione? w = {w}, v*x={v @ x_opt}\")\n",
    "            print(\"-\"*40)\n",
    "            \n",
    "    #else:\n",
    "    #    print(\"Objective value (knapsack_specialized_pruning):\", phi_opt)\n",
    "    #    print(\"Optimal x (knapsack_specialized_pruning):\", x_opt)\n",
    "    \n",
    "    #print(\"-\"*40)\n",
    "if(SUCCESS == 1):\n",
    "    print(\"TEST CONCLUSO CON SUCCESSO!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed5a6b",
   "metadata": {},
   "source": [
    "# Calcolo dei moltiplicatori: caso con due vincoli attivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc33316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATI:\n",
      "xi: [0.08, 0.09, 0.37, 0.5 , 0.84]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.3855]) \n",
      "\n",
      "x_opt: [0.   0.54 0.   0.46 0.  ]\n",
      "f.o.: tensor(0.2783)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.28\n",
      "Optimal x (pruning): [0.  , 0.54, 0.  , 0.46, 0.  ]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.01]\n",
      "Dual variable for sum(x) <= 1: [0.11]\n",
      "Dual variable for x >= 0: [0.19, 0.  , 0.08, 0.  , 0.15]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.         -1.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 2.49999987  1.49999998  1.49999998  0.50000002 -0.49999994]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-2.49999987 -0.49999998 -0.49999998  0.49999998  1.49999994]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.008207000363998\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.0082070002526813\n",
      "x_star: [0.  , 0.54, 0.  , 0.46, 0.  ]\n",
      "VS\n",
      "x_star: [0.  , 0.54, 0.  , 0.46, 0.  ]\n",
      "Elementi non nulli della prima colonna: [ 2.49999987 -2.49999987]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.07, 0.43, 0.48, 0.86, 0.98]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.6866]) \n",
      "\n",
      "x_opt: [0.   0.   0.28 0.   0.72]\n",
      "f.o.: tensor(0.8364)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.83\n",
      "Optimal x (pruning): [0.  , 0.  , 0.28, 0.  , 0.72]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.25]\n",
      "Dual variable for sum(x) <= 1: [0.02]\n",
      "Dual variable for x >= 0: [0.1 , 0.2 , 0.  , 0.14, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.         -1.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]\n",
      " [ 2.49999996  2.          2.          1.5         0.49999996]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-2.49999996 -1.         -1.         -0.5         0.50000004]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.2503732554558924\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.2503732557040879\n",
      "x_star: [0.  , 0.  , 0.28, 0.  , 0.72]\n",
      "VS\n",
      "x_star: [0.  , 0.  , 0.28, 0.  , 0.72]\n",
      "Elementi non nulli della prima colonna: [ 2.49999996 -2.49999996]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.21, 0.21, 0.59, 0.81, 0.86]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.3247]) \n",
      "\n",
      "x_opt: [0.   0.79 0.   0.   0.21]\n",
      "f.o.: tensor(0.3496)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.35\n",
      "Optimal x (pruning): [0.  , 0.79, 0.  , 0.  , 0.21]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.08]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.21, 0.  , 0.16, 0.17, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.0750511128447784\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.0750511127775293\n",
      "x_star: [0.  , 0.79, 0.  , 0.  , 0.21]\n",
      "VS\n",
      "x_star: [0.  , 0.79, 0.  , 0.  , 0.21]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.  , 0.13, 0.76, 0.88, 0.98]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.2781]) \n",
      "\n",
      "x_opt: [0.   0.87 0.   0.   0.13]\n",
      "f.o.: tensor(0.2370)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.24\n",
      "Optimal x (pruning): [0.  , 0.87, 0.  , 0.  , 0.13]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.42]\n",
      "Dual variable for sum(x) <= 1: [0.16]\n",
      "Dual variable for x >= 0: [0.16, 0.  , 0.35, 0.19, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.419107992165665\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.4191079915494031\n",
      "x_star: [0.  , 0.87, 0.  , 0.  , 0.13]\n",
      "VS\n",
      "x_star: [0.  , 0.87, 0.  , 0.  , 0.13]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.12, 0.15, 0.65, 0.68, 0.98]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.5585]) \n",
      "\n",
      "x_opt: [0.  0.1 0.  0.9 0. ]\n",
      "f.o.: tensor(0.6240)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.62\n",
      "Optimal x (pruning): [0. , 0.1, 0. , 0.9, 0. ]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.31]\n",
      "Dual variable for sum(x) <= 1: [0.11]\n",
      "Dual variable for x >= 0: [0.22, 0.  , 0.24, 0.  , 0.05]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.         -1.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 2.49999987  1.49999998  1.49999998  0.50000002 -0.49999994]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-2.49999987 -0.49999998 -0.49999998  0.49999998  1.49999994]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.3070551369384977\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.307055136491623\n",
      "x_star: [0. , 0.1, 0. , 0.9, 0. ]\n",
      "VS\n",
      "x_star: [0. , 0.1, 0. , 0.9, 0. ]\n",
      "Elementi non nulli della prima colonna: [ 2.49999987 -2.49999987]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.08, 0.14, 0.56, 0.84, 0.94]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.4758]) \n",
      "\n",
      "x_opt: [0.   0.54 0.   0.   0.46]\n",
      "f.o.: tensor(0.5066)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.51\n",
      "Optimal x (pruning): [ 0.  ,  0.54, -0.  ,  0.  ,  0.46]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.34]\n",
      "Dual variable for sum(x) <= 1: [0.13]\n",
      "Dual variable for x >= 0: [0.21, 0.  , 0.16, 0.16, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.3441658813133954\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.3441658802742589\n",
      "x_star: [0.  , 0.54, 0.  , 0.  , 0.46]\n",
      "VS\n",
      "x_star: [ 0.  ,  0.54, -0.  ,  0.  ,  0.46]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.13, 0.21, 0.36, 0.8 , 0.95]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.6825]) \n",
      "\n",
      "x_opt: [0.   0.   0.29 0.   0.71]\n",
      "f.o.: tensor(0.7749)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.77\n",
      "Optimal x (pruning): [0.  , 0.  , 0.29, 0.  , 0.71]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.47]\n",
      "Dual variable for sum(x) <= 1: [0.23]\n",
      "Dual variable for x >= 0: [0.37, 0.15, 0.  , 0.15, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.         -1.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]\n",
      " [ 2.49999996  2.          2.          1.5         0.49999996]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-2.49999996 -1.         -1.         -0.5         0.50000004]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.4736845869766981\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.4736845974704043\n",
      "x_star: [0.  , 0.  , 0.29, 0.  , 0.71]\n",
      "VS\n",
      "x_star: [0.  , 0.  , 0.29, 0.  , 0.71]\n",
      "Elementi non nulli della prima colonna: [ 2.49999996 -2.49999996]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.05, 0.1 , 0.53, 0.7 , 0.97]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.4495]) \n",
      "\n",
      "x_opt: [0.   0.58 0.   0.   0.42]\n",
      "f.o.: tensor(0.4621)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.46\n",
      "Optimal x (pruning): [0.  , 0.58, 0.  , 0.  , 0.42]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.46]\n",
      "Dual variable for sum(x) <= 1: [0.2]\n",
      "Dual variable for x >= 0: [0.24, 0.  , 0.14, 0.03, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.4557325623075283\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.4557325622487984\n",
      "x_star: [0.  , 0.58, 0.  , 0.  , 0.42]\n",
      "VS\n",
      "x_star: [0.  , 0.58, 0.  , 0.  , 0.42]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.07, 0.1 , 0.61, 0.67, 0.8 ]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7027]) \n",
      "\n",
      "x_opt: [0.   0.16 0.   0.   0.84]\n",
      "f.o.: tensor(0.6854)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.68\n",
      "Optimal x (pruning): [0.  , 0.16, 0.  , 0.  , 0.84]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.17]\n",
      "Dual variable for sum(x) <= 1: [0.14]\n",
      "Dual variable for x >= 0: [0.2 , 0.  , 0.28, 0.11, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.1682959223544211\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.1682959226274305\n",
      "x_star: [0.  , 0.16, 0.  , 0.  , 0.84]\n",
      "VS\n",
      "x_star: [0.  , 0.16, 0.  , 0.  , 0.84]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.03, 0.1 , 0.42, 0.49, 0.65]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.2884]) \n",
      "\n",
      "x_opt: [0.   0.85 0.   0.   0.15]\n",
      "f.o.: tensor(0.1804)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.18\n",
      "Optimal x (pruning): [0.  , 0.85, 0.  , 0.  , 0.15]\n",
      "Dual variable for equality constraint (v @ x == w): [-0.93]\n",
      "Dual variable for sum(x) <= 1: [0.09]\n",
      "Dual variable for x >= 0: [0.12, 0.  , 0.14, 0.02, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.9265202145796982\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -0.9265202124261778\n",
      "x_star: [0.  , 0.85, 0.  , 0.  , 0.15]\n",
      "VS\n",
      "x_star: [0.  , 0.85, 0.  , 0.  , 0.15]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.07, 0.1 , 0.14, 0.42, 0.86]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.6334]) \n",
      "\n",
      "x_opt: [0.   0.   0.   0.83 0.17]\n",
      "f.o.: tensor(0.4916)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.49\n",
      "Optimal x (pruning): [-0.  , -0.  ,  0.  ,  0.83,  0.17]\n",
      "Dual variable for equality constraint (v @ x == w): [-2.23]\n",
      "Dual variable for sum(x) <= 1: [0.92]\n",
      "Dual variable for x >= 0: [0.99, 0.57, 0.17, 0.  , 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.         -1.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]\n",
      " [ 0.          0.          0.          0.         -1.        ]\n",
      " [ 5.0000003   4.0000003   4.0000003   3.00000022  2.00000015]\n",
      " [-5.0000003  -3.0000003  -3.0000003  -2.00000022 -1.00000015]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -2.22704870862059\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -2.227048705909018\n",
      "x_star: [0.  , 0.  , 0.  , 0.83, 0.17]\n",
      "VS\n",
      "x_star: [-0.  , -0.  ,  0.  ,  0.83,  0.17]\n",
      "Elementi non nulli della prima colonna: [ 5.0000003 -5.0000003]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.04, 0.06, 0.39, 0.57, 0.81]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.2446]) \n",
      "\n",
      "x_opt: [0.   0.93 0.   0.   0.07]\n",
      "f.o.: tensor(0.1105)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.11\n",
      "Optimal x (pruning): [0.  , 0.93, 0.  , 0.  , 0.07]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.25]\n",
      "Dual variable for sum(x) <= 1: [0.19]\n",
      "Dual variable for x >= 0: [0.23, 0.  , 0.08, 0.01, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.2544288050965149\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.254428802445728\n",
      "x_star: [0.  , 0.93, 0.  , 0.  , 0.07]\n",
      "VS\n",
      "x_star: [0.  , 0.93, 0.  , 0.  , 0.07]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Funzione per formattare e stampare un array\n",
    "def print_dual(label, values):\n",
    "    formatted = np.where(np.abs(values) < epsilon, 0.0, values)\n",
    "    print(f\"{label}: {np.array2string(formatted, precision=2, separator=', ', suppress_small=True)}\")\n",
    "    \n",
    "np.random.seed(67)  # Con 45 ho fatto l'esempio sull'Ipad\n",
    "torch.manual_seed(67)\n",
    "\n",
    "# Soglia sotto cui i numeri vengono considerati come zero\n",
    "epsilon = 1e-5\n",
    "\n",
    "C = 5\n",
    "\n",
    "for _ in range(50):\n",
    "    xi = torch.sort(torch.rand(C))[0]\n",
    "    v = torch.linspace(0, 1 - (1 / C), C)\n",
    "    w = torch.rand(M)\n",
    "    #w = v[torch.randint(0, C, (1,))]  \n",
    "\n",
    "    x_opt, lambda_opt, phi_opt, x_plus = knapsack_specialized_pruning(xi, v, w, C)\n",
    "    \n",
    "    if(x_opt is None):\n",
    "        continue\n",
    "\n",
    "    if(np.count_nonzero(x_opt) == 2):\n",
    "    #if(x_opt[2] != 0 and x_opt[3] != 0):\n",
    "        print(\"DATI:\")\n",
    "        print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "        print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "        print(\"w:\", w, \"\\n\")\n",
    "\n",
    "        print(\"x_opt:\", x_opt)\n",
    "        print(\"f.o.:\", phi_opt)\n",
    "        print(\"lambda_opt: ?\")\n",
    "\n",
    "        x_pruning = cp.Variable(C)\n",
    "        equality_constraint_pruning = v @ x_pruning == w\n",
    "        constraints_pruning = [\n",
    "            equality_constraint_pruning,\n",
    "            cp.sum(x_pruning) <= 1,\n",
    "            x_pruning >= 0,\n",
    "            x_pruning <= 1\n",
    "        ]\n",
    "        objective_pruning = cp.Minimize(xi @ x_pruning)\n",
    "        prob_pruning = cp.Problem(objective_pruning, constraints_pruning)\n",
    "        prob_pruning.solve(solver=cp.CLARABEL)\n",
    "\n",
    "        if prob_pruning.value is not None and x_pruning.value is not None:\n",
    "            print(\"\\n---------------------- SOLVER SOLUTION -------------------------\")\n",
    "            print(f\"Objective value (pruning): {prob_pruning.value:.2f}\")\n",
    "            print(\"Optimal x (pruning):\", \n",
    "                  np.array2string(x_pruning.value, precision=2, separator=', ', suppress_small=True))\n",
    "            # Stampa dei moltiplicatori ottimali\n",
    "            print_dual(\"Dual variable for equality constraint (v @ x == w)\", equality_constraint_pruning.dual_value)\n",
    "            print_dual(\"Dual variable for sum(x) <= 1\", np.array([constraints_pruning[1].dual_value]))\n",
    "            print_dual(\"Dual variable for x >= 0\", np.array(constraints_pruning[2].dual_value))\n",
    "            print_dual(\"Dual variable for x <= 1\", np.array(constraints_pruning[3].dual_value))\n",
    "        else:\n",
    "            print(\"No solution found for the problem with pruning.\")\n",
    "\n",
    "        # ---------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "        print(\"\\n-------------------- METODO SPECIALIZZATO ---------------------\")\n",
    "\n",
    "        matrice = np.zeros((C, C))\n",
    "\n",
    "        matrice[0] = v\n",
    "        matrice[1] = np.ones(C, dtype=int)\n",
    "\n",
    "        zero_indices = np.where(x_opt == 0)[0]\n",
    "\n",
    "        for i in range(C-2):\n",
    "            if i < len(zero_indices):\n",
    "                matrice[i + 2][zero_indices[i]] = -1\n",
    "\n",
    "        det = np.linalg.det(matrice)\n",
    "        if det != 0:\n",
    "            inversa = np.linalg.inv(matrice)\n",
    "        else:\n",
    "            print(\"La matrice non è invertibile (determinante nullo).\")\n",
    "\n",
    "        if(float((xi @ inversa)[0]) > 0):\n",
    "            matrice = np.zeros((C, C))\n",
    "\n",
    "            matrice[0] = -v\n",
    "            matrice[1] = np.ones(C, dtype=int)\n",
    "\n",
    "            zero_indices = np.where(x_opt == 0)[0]\n",
    "\n",
    "            for i in range(C-2):\n",
    "                if i < len(zero_indices):\n",
    "                    matrice[i + 2][zero_indices[i]] = -1\n",
    "\n",
    "            det = np.linalg.det(matrice)\n",
    "            if det != 0:\n",
    "                inversa = np.linalg.inv(matrice)\n",
    "            else:\n",
    "                print(\"La matrice non è invertibile (determinante nullo).\")\n",
    "\n",
    "        print(\"La matrice di base è:\\n\", matrice)\n",
    "        print(\"L'inversa della matrice è:\\n\", inversa)\n",
    "        if(x_opt is not None):\n",
    "            print(\"\\n-------------------------- RISULTATI --------------------------\")\n",
    "            print(\"Dual variable for equality constraint (v @ x == w):\", float((xi @ inversa)[0]))\n",
    "            print(\"VS\")\n",
    "            print(\"Dual variable for equality constraint (v @ x == w):\", equality_constraint_pruning.dual_value[0])\n",
    "\n",
    "            x_star = inversa @ np.array([-float(w), 1, 0, 0, 0])\n",
    "            print(\"x_star:\", np.array2string(np.array(x_star), precision=2, separator=', '))\n",
    "            print(\"VS\")\n",
    "            print(\"x_star:\", np.array2string(x_pruning.value, precision=2, separator=', ', suppress_small=True))\n",
    "\n",
    "            prima_colonna = inversa[:, 0]\n",
    "            non_nulli = prima_colonna[prima_colonna != 0]\n",
    "            print(\"Elementi non nulli della prima colonna:\", non_nulli)\n",
    "\n",
    "        print(\"\\n\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356e25ac",
   "metadata": {},
   "source": [
    "# Caso con un vincolo attivo (diverso da 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233c591c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATI:\n",
      "xi: [0.08, 0.24, 0.56, 0.95, 1.  ]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.0262]) \n",
      "\n",
      "x_opt: [0.   0.13 0.   0.   0.  ]\n",
      "f.o.: tensor(0.0312)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.03\n",
      "Optimal x (pruning): [0.  , 0.13, 0.  , 0.  , 0.  ]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.2]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.08, 0.  , 0.08, 0.23, 0.04]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.1997, -0.0842, -0.0756, -0.2272, -0.0386], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]\n",
      " [ 0.          0.          0.          0.         -1.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[-0.         -1.         -0.         -0.         -0.        ]\n",
      " [-4.99999993 -0.          2.          3.00000007  4.        ]\n",
      " [-0.         -0.         -1.         -0.         -0.        ]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.1996954500720582\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.199695433757591\n",
      "x_star: [-1.  ,  0.13,  0.  ,  0.  ,  0.  ]\n",
      "VS\n",
      "x_star: [0.  , 0.13, 0.  , 0.  , 0.  ]\n",
      "Elementi non nulli della prima colonna: [-4.99999993]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.01, 0.11, 0.3 , 0.35, 0.55]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.1769]) \n",
      "\n",
      "x_opt: [0.   0.88 0.   0.   0.  ]\n",
      "f.o.: tensor(0.0949)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.10\n",
      "Optimal x (pruning): [ 0.  ,  0.88,  0.  , -0.  ,  0.  ]\n",
      "Dual variable for equality constraint (v @ x == w): [-0.54]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.01, 0.  , 0.09, 0.03, 0.11]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-0.5392, -0.0094, -0.0873, -0.0278, -0.1146], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]\n",
      " [ 0.          0.          0.          0.         -1.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[-0.         -1.         -0.         -0.         -0.        ]\n",
      " [-4.99999993 -0.          2.          3.00000007  4.        ]\n",
      " [-0.         -0.         -1.         -0.         -0.        ]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.5391624489551418\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -0.5391624503703387\n",
      "x_star: [-1.  ,  0.88,  0.  ,  0.  ,  0.  ]\n",
      "VS\n",
      "x_star: [ 0.  ,  0.88,  0.  , -0.  ,  0.  ]\n",
      "Elementi non nulli della prima colonna: [-4.99999993]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Funzione per formattare e stampare un array\n",
    "def print_dual(label, values):\n",
    "    formatted = np.where(np.abs(values) < epsilon, 0.0, values)\n",
    "    print(f\"{label}: {np.array2string(formatted, precision=2, separator=', ', suppress_small=True)}\")\n",
    "    \n",
    "np.random.seed(63)  # Con 45 ho fatto l'esempio sull'Ipad\n",
    "torch.manual_seed(63)\n",
    "\n",
    "# Soglia sotto cui i numeri vengono considerati come zero\n",
    "epsilon = 1e-5\n",
    "\n",
    "C = 5\n",
    "for i in range(50):\n",
    "\n",
    "    xi = torch.sort(torch.rand(C))[0]\n",
    "    v = torch.linspace(0, 1 - (1 / C), C)\n",
    "    w = torch.rand(M)\n",
    "    #w = v[torch.randint(0, C, (1,))]  \n",
    "\n",
    "    x_opt, lambda_opt, phi_opt, x_plus = knapsack_specialized_pruning(xi, v, w, C)\n",
    "    if(x_opt is None):\n",
    "        continue\n",
    "\n",
    "    if(np.count_nonzero(x_opt) == 1):\n",
    "        if(x_opt[1] != 0):\n",
    "            print(\"DATI:\")\n",
    "            print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "            print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "            print(\"w:\", w, \"\\n\")\n",
    "\n",
    "            print(\"x_opt:\", x_opt)\n",
    "            print(\"f.o.:\", phi_opt)\n",
    "            print(\"lambda_opt: ?\")\n",
    "\n",
    "            x_pruning = cp.Variable(C)\n",
    "            equality_constraint_pruning = v @ x_pruning == w\n",
    "            constraints_pruning = [\n",
    "                equality_constraint_pruning,\n",
    "                cp.sum(x_pruning) <= 1,\n",
    "                x_pruning >= 0,\n",
    "                x_pruning <= 1\n",
    "            ]\n",
    "            objective_pruning = cp.Minimize(xi @ x_pruning)\n",
    "            prob_pruning = cp.Problem(objective_pruning, constraints_pruning)\n",
    "            prob_pruning.solve(solver=cp.CLARABEL)\n",
    "\n",
    "            if prob_pruning.value is not None and x_pruning.value is not None:\n",
    "                print(\"\\n---------------------- SOLVER SOLUTION -------------------------\")\n",
    "                print(f\"Objective value (pruning): {prob_pruning.value:.2f}\")\n",
    "                print(\"Optimal x (pruning):\", \n",
    "                      np.array2string(x_pruning.value, precision=2, separator=', ', suppress_small=True))\n",
    "                # Stampa dei moltiplicatori ottimali\n",
    "                print_dual(\"Dual variable for equality constraint (v @ x == w)\", equality_constraint_pruning.dual_value)\n",
    "                print_dual(\"Dual variable for sum(x) <= 1\", np.array([constraints_pruning[1].dual_value]))\n",
    "                print_dual(\"Dual variable for x >= 0\", np.array(constraints_pruning[2].dual_value))\n",
    "                print_dual(\"Dual variable for x <= 1\", np.array(constraints_pruning[3].dual_value))\n",
    "            else:\n",
    "                print(\"No solution found for the problem with pruning.\")\n",
    "\n",
    "            # ---------------------------------------------------------------------------------------------------\n",
    "            # ---------------------------------------------------------------------------------------------------\n",
    "            # ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "            print(\"\\n-------------------- METODO SPECIALIZZATO ---------------------\")\n",
    "\n",
    "            # Calcolo la matrice\n",
    "            matrice = np.zeros((C, C))\n",
    "            matrice[0] = -v\n",
    "            matrice[1] = np.array([-1 if i == 0 else 0 for i in range(C)])\n",
    "            matrice[2] = np.array([-1 if i == 2 else 0 for i in range(C)])\n",
    "            matrice[3] = np.array([-1 if i == 3 else 0 for i in range(C)])\n",
    "            matrice[4] = np.array([-1 if i == 4 else 0 for i in range(C)])\n",
    "\n",
    "            # Calcolo l'inversa\n",
    "            det = np.linalg.det(matrice)\n",
    "            if det != 0:\n",
    "                inversa = np.linalg.inv(matrice)\n",
    "            else:\n",
    "                print(\"La matrice non è invertibile (determinante nullo).\")\n",
    "\n",
    "            if ((xi @ inversa) > 0).all():\n",
    "                # Calcolo la matrice\n",
    "                matrice = np.zeros((C, C))\n",
    "                matrice[0] = v\n",
    "                matrice[1] = np.array([-1 if i == 0 else 0 for i in range(C)])\n",
    "                matrice[2] = np.array([-1 if i == 2 else 0 for i in range(C)])\n",
    "                matrice[3] = np.array([-1 if i == 3 else 0 for i in range(C)])\n",
    "                matrice[4] = np.array([-1 if i == 4 else 0 for i in range(C)])\n",
    "\n",
    "                # Calcolo l'inversa\n",
    "                det = np.linalg.det(matrice)\n",
    "                if det != 0:\n",
    "                    inversa = np.linalg.inv(matrice)\n",
    "                else:\n",
    "                    print(\"La matrice non è invertibile (determinante nullo).\")\n",
    "\n",
    "            print(\"xi @ inversa:\", xi @ inversa)\n",
    "\n",
    "            # Cambio base\n",
    "            if(float((xi @ inversa)[0]) > 0):\n",
    "                matrice = np.zeros((C, C))\n",
    "                matrice[0] = -v\n",
    "                matrice[1] = np.ones(C, dtype=int)\n",
    "                zero_indices = np.where(x_opt == 0)[0]\n",
    "                for i in range(C-2):\n",
    "                    if i < len(zero_indices):\n",
    "                        matrice[i + 2][zero_indices[i]] = -1\n",
    "                det = np.linalg.det(matrice)\n",
    "                if det != 0:\n",
    "                    inversa = np.linalg.inv(matrice)\n",
    "                else:\n",
    "                    print(\"La matrice non è invertibile (determinante nullo).\")\n",
    "\n",
    "            # Stampo i risultati\n",
    "            print(\"La matrice di base è:\\n\", matrice)\n",
    "            print(\"L'inversa della matrice è:\\n\", inversa)\n",
    "            if(x_opt is not None):\n",
    "                print(\"\\n-------------------------- RISULTATI --------------------------\")\n",
    "                print(\"Dual variable for equality constraint (v @ x == w):\", float((xi @ inversa)[0]))\n",
    "                print(\"VS\")\n",
    "                print(\"Dual variable for equality constraint (v @ x == w):\", equality_constraint_pruning.dual_value[0])\n",
    "\n",
    "                x_star = inversa @ np.array([-float(w), 1, 0, 0, 0])\n",
    "                print(\"x_star:\", np.array2string(np.array(x_star), precision=2, separator=', '))\n",
    "                print(\"VS\")\n",
    "                print(\"x_star:\", np.array2string(x_pruning.value, precision=2, separator=', ', suppress_small=True))\n",
    "\n",
    "                prima_colonna = inversa[:, 0]\n",
    "                non_nulli = prima_colonna[prima_colonna != 0]\n",
    "                print(\"Elementi non nulli della prima colonna:\", non_nulli)\n",
    "\n",
    "            print(\"\\n\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec31274",
   "metadata": {},
   "source": [
    "# Caso con un vincolo attivo (uguale a 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ef9b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATI:\n",
      "xi: [0.  , 0.13, 0.68, 0.68, 0.98]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.1992]) \n",
      "\n",
      "x_opt: [0. 1. 0. 0. 0.]\n",
      "f.o.: tensor(0.1284)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.13\n",
      "Optimal x (pruning): [0., 1., 0., 0., 0.]\n",
      "Dual variable for equality constraint (v @ x == w): [-0.64]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.  , 0.  , 0.42, 0.29, 0.47]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.4187, -0.1553, -0.1582, -0.2649,  0.0180], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.4186530100506594\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -0.6422416245402826\n",
      "x_star: [ 0.,  1.,  0.,  0., -0.]\n",
      "VS\n",
      "x_star: [0., 1., 0., 0., 0.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.55, 0.68, 0.76, 0.85, 0.91]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7999]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.9110)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.91\n",
      "Optimal x (pruning): [-0.,  0.,  0.,  0.,  1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.14]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.55, 0.45, 0.31, 0.17, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-0.3888,  0.5999,  0.0470, -0.0080, -0.0196], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.3887851975045821\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.1387069868527382\n",
      "x_star: [0.0e+00, 2.2e-04, 0.0e+00, 0.0e+00, 1.0e+00]\n",
      "VS\n",
      "x_star: [-0.,  0.,  0.,  0.,  1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.02, 0.19, 0.62, 0.69, 0.83]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.2013]) \n",
      "\n",
      "x_opt: [0. 1. 0. 0. 0.]\n",
      "f.o.: tensor(0.1872)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.19\n",
      "Optimal x (pruning): [0., 1., 0., 0., 0.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.08]\n",
      "Dual variable for sum(x) <= 1: [0.03]\n",
      "Dual variable for x >= 0: [0.05, 0.  , 0.22, 0.07, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.0793, -0.0287, -0.0491, -0.2188, -0.0672], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.079321686238224\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.0793208964152794\n",
      "x_star: [0., 1., 0., 0., 0.]\n",
      "VS\n",
      "x_star: [0., 1., 0., 0., 0.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.04, 0.41, 0.47, 0.51, 0.64]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7966]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.6355)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.63\n",
      "Optimal x (pruning): [0., 0., 0., 0., 1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-0.79]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.04, 0.25, 0.15, 0.03, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-0.3773,  0.3337,  0.2893,  0.0148,  0.0522], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.3772870643344462\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -0.7944263549400031\n",
      "x_star: [0.  , 0.01, 0.  , 0.  , 0.99]\n",
      "VS\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.03, 0.1 , 0.64, 0.67, 0.83]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7976]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.8331)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.83\n",
      "Optimal x (pruning): [0., 0., 0., 0., 1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.23]\n",
      "Dual variable for sum(x) <= 1: [0.15]\n",
      "Dual variable for x >= 0: [0.18, 0.  , 0.3 , 0.09, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.2276, -0.1489, -0.1801, -0.3022, -0.0870], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.2275904234112736\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.227590598887799\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "VS\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.23, 0.31, 0.58, 0.6 , 0.83]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.6009]) \n",
      "\n",
      "x_opt: [0. 0. 0. 1. 0.]\n",
      "f.o.: tensor(0.5968)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.60\n",
      "Optimal x (pruning): [0., 0., 0., 1., 0.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.18]\n",
      "Dual variable for sum(x) <= 1: [0.11]\n",
      "Dual variable for x >= 0: [0.34, 0.19, 0.22, 0.  , 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-0.8731,  0.1347, -0.0906, -0.0949,  0.0618], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.8730859427687634\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.181892801924875\n",
      "x_star: [0.  , 0.33, 0.  , 0.  , 0.67]\n",
      "VS\n",
      "x_star: [0., 0., 0., 1., 0.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.14, 0.22, 0.61, 0.72, 0.95]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.1998]) \n",
      "\n",
      "x_opt: [0. 1. 0. 0. 0.]\n",
      "f.o.: tensor(0.2244)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.22\n",
      "Optimal x (pruning): [0., 1., 0., 0., 0.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.12]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.14, 0.  , 0.16, 0.05, 0.05]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.2048, -0.0166, -0.1585, -0.1469, -0.0156], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.2048323769644045\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.1220673015003322\n",
      "x_star: [ 0.00e+00,  1.00e+00,  0.00e+00,  0.00e+00, -2.79e-04]\n",
      "VS\n",
      "x_star: [0., 1., 0., 0., 0.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATI:\n",
      "xi: [0.01, 0.01, 0.31, 0.69, 0.91]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.2016]) \n",
      "\n",
      "x_opt: [0. 1. 0. 0. 0.]\n",
      "f.o.: tensor(0.0083)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.01\n",
      "Optimal x (pruning): [0., 1., 0., 0., 0.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.5]\n",
      "Dual variable for sum(x) <= 1: [0.29]\n",
      "Dual variable for x >= 0: [0.3 , 0.  , 0.  , 0.08, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.5049e+00, -2.9267e-01, -3.0002e-01, -5.2780e-04, -7.7748e-02],\n",
      "       dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.5049057974680395\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.5049054581156214\n",
      "x_star: [0., 1., 0., 0., 0.]\n",
      "VS\n",
      "x_star: [0., 1., 0., 0., 0.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.06, 0.29, 0.68, 0.74, 0.75]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7983]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.7548)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.75\n",
      "Optimal x (pruning): [-0.,  0., -0.,  0.,  1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-0.94]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.06, 0.1 , 0.3 , 0.18, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-0.7766,  0.1335,  0.0749, -0.2314, -0.1443], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.7766056938478496\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -0.9434722453992397\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "VS\n",
      "x_star: [-0.,  0., -0.,  0.,  1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.07, 0.11, 0.74, 0.78, 0.98]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7972]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.9843)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.98\n",
      "Optimal x (pruning): [0., 0., 0., 0., 1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.45]\n",
      "Dual variable for sum(x) <= 1: [0.18]\n",
      "Dual variable for x >= 0: [0.25, 0.  , 0.33, 0.08, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.4512, -0.1767, -0.2509, -0.3329, -0.0843], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.4511972449541504\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.451197502072866\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "VS\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.01, 0.07, 0.45, 0.69, 0.89]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7980]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.8915)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.89\n",
      "Optimal x (pruning): [0., 0., 0., 0., 1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.37]\n",
      "Dual variable for sum(x) <= 1: [0.21]\n",
      "Dual variable for x >= 0: [0.22, 0.  , 0.1 , 0.07, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.3707, -0.2051, -0.2157, -0.1047, -0.0683], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.370734452643974\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.3707345345315416\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "VS\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.11, 0.16, 0.53, 0.63, 0.83]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7979]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.8333)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.83\n",
      "Optimal x (pruning): [0., 0., 0., 0., 1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.13]\n",
      "Dual variable for sum(x) <= 1: [0.07]\n",
      "Dual variable for x >= 0: [0.18, 0.  , 0.15, 0.02, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.1289, -0.0699, -0.1819, -0.1476, -0.0182], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.128947916692278\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.1289480512073706\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "VS\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.07, 0.14, 0.23, 0.47, 0.49]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.4007]) \n",
      "\n",
      "x_opt: [0. 0. 1. 0. 0.]\n",
      "f.o.: tensor(0.2278)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.23\n",
      "Optimal x (pruning): [0., 0., 1., 0., 0.]\n",
      "Dual variable for equality constraint (v @ x == w): [-0.65]\n",
      "Dual variable for sum(x) <= 1: [0.03]\n",
      "Dual variable for x >= 0: [0.1 , 0.04, 0.  , 0.11, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-0.5804,  0.0238, -0.0430,  0.0281, -0.0975], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.580355814392033\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -0.650514295683436\n",
      "x_star: [0.  , 0.67, 0.  , 0.  , 0.33]\n",
      "VS\n",
      "x_star: [0., 0., 1., 0., 0.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATI:\n",
      "xi: [0.14, 0.6 , 0.62, 0.69, 0.85]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7994]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.8522)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.85\n",
      "Optimal x (pruning): [-0.,  0.,  0.,  0.,  1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.07]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.14, 0.39, 0.2 , 0.05, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-0.4171,  0.5186,  0.3803,  0.0638,  0.0792], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.417072170718429\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.065293640069026\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "VS\n",
      "x_star: [-0.,  0.,  0.,  0.,  1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.02, 0.09, 0.1 , 0.55, 0.7 ]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.4002]) \n",
      "\n",
      "x_opt: [0. 0. 1. 0. 0.]\n",
      "f.o.: tensor(0.1000)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.10\n",
      "Optimal x (pruning): [0., 0., 1., 0., 0.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.5]\n",
      "Dual variable for sum(x) <= 1: [0.5]\n",
      "Dual variable for x >= 0: [0.53, 0.29, 0.  , 0.15, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.0220, -0.1159, -0.1407,  0.1929, -0.0510], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.022012913892474\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.5042835013634255\n",
      "x_star: [0.  , 0.67, 0.  , 0.  , 0.33]\n",
      "VS\n",
      "x_star: [0., 0., 1., 0., 0.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.04, 0.3 , 0.33, 0.66, 0.96]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.3986]) \n",
      "\n",
      "x_opt: [0. 0. 1. 0. 0.]\n",
      "f.o.: tensor(0.3328)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.33\n",
      "Optimal x (pruning): [0., 0., 1., 0., 0.]\n",
      "Dual variable for equality constraint (v @ x == w): [-0.83]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.04, 0.13, 0.  , 0.16, 0.3 ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-1.1064,  0.0791,  0.0431,  0.1889,  0.0875], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -1.1064418985479787\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -0.8320156088254143\n",
      "x_star: [0.  , 0.67, 0.  , 0.  , 0.33]\n",
      "VS\n",
      "x_star: [0., 0., 1., 0., 0.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.17, 0.46, 0.58, 0.79, 0.92]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7994]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.9242)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.92\n",
      "Optimal x (pruning): [0., 0., 0., 0., 1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-1.16]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.17, 0.23, 0.12, 0.09, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-0.7658,  0.3116,  0.1420,  0.0366, -0.0170], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.7657533769942317\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -1.1552092335185353\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "VS\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.05, 0.36, 0.47, 0.55, 0.8 ]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.5974]) \n",
      "\n",
      "x_opt: [0. 0. 0. 1. 0.]\n",
      "f.o.: tensor(0.5512)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.55\n",
      "Optimal x (pruning): [0., 0., 0., 1., 0.]\n",
      "Dual variable for equality constraint (v @ x == w): [-0.92]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.05, 0.18, 0.1 , 0.  , 0.07]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-0.7363,  0.2138,  0.1615,  0.0364,  0.1043], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.7363043119067305\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -0.9187402320790935\n",
      "x_star: [0.  , 0.34, 0.  , 0.  , 0.66]\n",
      "VS\n",
      "x_star: [0., 0., 0., 1., 0.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.12, 0.18, 0.47, 0.49, 0.62]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7991]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.6193)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.62\n",
      "Optimal x (pruning): [0., 0., 0., 0., 1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-0.77]\n",
      "Dual variable for sum(x) <= 1: [0.]\n",
      "Dual variable for x >= 0: [0.12, 0.02, 0.16, 0.03, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi @ inversa: tensor([-0.7397,  0.0275, -0.0941, -0.1440, -0.0216], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.7397021739725942\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -0.7741231367701552\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "VS\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATI:\n",
      "xi: [0.05, 0.09, 0.31, 0.51, 0.55]\n",
      "v: [0. , 0.2, 0.4, 0.6, 0.8]\n",
      "w: tensor([0.7989]) \n",
      "\n",
      "x_opt: [0. 0. 0. 0. 1.]\n",
      "f.o.: tensor(0.5537)\n",
      "lambda_opt: ?\n",
      "\n",
      "---------------------- SOLVER SOLUTION -------------------------\n",
      "Objective value (pruning): 0.55\n",
      "Optimal x (pruning): [0., 0., 0., 0., 1.]\n",
      "Dual variable for equality constraint (v @ x == w): [-0.78]\n",
      "Dual variable for sum(x) <= 1: [0.07]\n",
      "Dual variable for x >= 0: [0.12, 0.  , 0.06, 0.11, 0.  ]\n",
      "Dual variable for x <= 1: [0., 0., 0., 0., 0.]\n",
      "\n",
      "-------------------- METODO SPECIALIZZATO ---------------------\n",
      "xi @ inversa: tensor([-0.7764, -0.0675, -0.1208, -0.0649, -0.1147], dtype=torch.float64)\n",
      "La matrice di base è:\n",
      " [[-0.         -0.2        -0.40000001 -0.60000002 -0.80000001]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [-1.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -1.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.          0.        ]]\n",
      "L'inversa della matrice è:\n",
      " [[ 0.          0.         -1.          0.          0.        ]\n",
      " [ 1.66666664  1.33333333  1.33333333  0.66666667  0.33333331]\n",
      " [-0.         -0.         -0.         -1.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.         -1.        ]\n",
      " [-1.66666664 -0.33333333 -0.33333333  0.33333333  0.66666669]]\n",
      "\n",
      "-------------------------- RISULTATI --------------------------\n",
      "Dual variable for equality constraint (v @ x == w): -0.7764437678986227\n",
      "VS\n",
      "Dual variable for equality constraint (v @ x == w): -0.7764448422436764\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "VS\n",
      "x_star: [0., 0., 0., 0., 1.]\n",
      "Elementi non nulli della prima colonna: [ 1.66666664 -1.66666664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Funzione per formattare e stampare un array\n",
    "def print_dual(label, values):\n",
    "    formatted = np.where(np.abs(values) < epsilon, 0.0, values)\n",
    "    print(f\"{label}: {np.array2string(formatted, precision=2, separator=', ', suppress_small=True)}\")\n",
    "    \n",
    "np.random.seed(63)  # Con 45 ho fatto l'esempio sull'Ipad\n",
    "torch.manual_seed(63)\n",
    "\n",
    "# Soglia sotto cui i numeri vengono considerati come zero\n",
    "epsilon = 1e-5\n",
    "\n",
    "C = 5\n",
    "for i in range(4000):\n",
    "\n",
    "    xi = torch.sort(torch.rand(C))[0]\n",
    "    v = torch.linspace(0, 1 - (1 / C), C)\n",
    "    w = torch.rand(M)\n",
    "    #w = v[torch.randint(0, C, (1,))]  \n",
    "\n",
    "    x_opt, lambda_opt, phi_opt, x_plus = knapsack_specialized_pruning(xi, v, w, C)\n",
    "    if(x_opt is None):\n",
    "        continue\n",
    "\n",
    "    if(np.count_nonzero(x_opt) == 1):\n",
    "        if(np.any(x_opt == 1)):\n",
    "            print(\"DATI:\")\n",
    "            print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "            print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "            print(\"w:\", w, \"\\n\")\n",
    "\n",
    "            print(\"x_opt:\", x_opt)\n",
    "            print(\"f.o.:\", phi_opt)\n",
    "            print(\"lambda_opt: ?\")\n",
    "\n",
    "            x_pruning = cp.Variable(C)\n",
    "            equality_constraint_pruning = v @ x_pruning == w\n",
    "            constraints_pruning = [\n",
    "                equality_constraint_pruning,\n",
    "                cp.sum(x_pruning) <= 1,\n",
    "                x_pruning >= 0,\n",
    "                x_pruning <= 1\n",
    "            ]\n",
    "            objective_pruning = cp.Minimize(xi @ x_pruning)\n",
    "            prob_pruning = cp.Problem(objective_pruning, constraints_pruning)\n",
    "            prob_pruning.solve(solver=cp.CLARABEL)\n",
    "\n",
    "            if prob_pruning.value is not None and x_pruning.value is not None:\n",
    "                print(\"\\n---------------------- SOLVER SOLUTION -------------------------\")\n",
    "                print(f\"Objective value (pruning): {prob_pruning.value:.2f}\")\n",
    "                print(\"Optimal x (pruning):\", \n",
    "                      np.array2string(x_pruning.value, precision=2, separator=', ', suppress_small=True))\n",
    "                # Stampa dei moltiplicatori ottimali\n",
    "                print_dual(\"Dual variable for equality constraint (v @ x == w)\", equality_constraint_pruning.dual_value)\n",
    "                print_dual(\"Dual variable for sum(x) <= 1\", np.array([constraints_pruning[1].dual_value]))\n",
    "                print_dual(\"Dual variable for x >= 0\", np.array(constraints_pruning[2].dual_value))\n",
    "                print_dual(\"Dual variable for x <= 1\", np.array(constraints_pruning[3].dual_value))\n",
    "            else:\n",
    "                print(\"No solution found for the problem with pruning.\")\n",
    "\n",
    "            # ---------------------------------------------------------------------------------------------------\n",
    "            # ---------------------------------------------------------------------------------------------------\n",
    "            # ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "            print(\"\\n-------------------- METODO SPECIALIZZATO ---------------------\")\n",
    "\n",
    "            # Calcolo la matrice\n",
    "            matrice = np.zeros((C, C))\n",
    "            matrice[0] = -v\n",
    "            matrice[1] = np.ones(C, dtype=int)\n",
    "            matrice[2] = np.array([-1 if i == 0 else 0 for i in range(C)])\n",
    "            matrice[3] = np.array([-1 if i == 2 else 0 for i in range(C)])\n",
    "            matrice[4] = np.array([-1 if i == 3 else 0 for i in range(C)])\n",
    "\n",
    "            # Calcolo l'inversa\n",
    "            det = np.linalg.det(matrice)\n",
    "            if det != 0:\n",
    "                inversa = np.linalg.inv(matrice)\n",
    "            else:\n",
    "                print(\"La matrice non è invertibile (determinante nullo).\")\n",
    "\n",
    "            if ((xi @ inversa) > 0).all():\n",
    "                # Calcolo la matrice\n",
    "                matrice = np.zeros((C, C))\n",
    "                matrice[0] = v\n",
    "                matrice[1] = np.ones(C, dtype=int)\n",
    "                matrice[2] = np.array([-1 if i == 0 else 0 for i in range(C)])\n",
    "                matrice[3] = np.array([-1 if i == 2 else 0 for i in range(C)])\n",
    "                matrice[4] = np.array([-1 if i == 3 else 0 for i in range(C)])\n",
    "\n",
    "                # Calcolo l'inversa\n",
    "                det = np.linalg.det(matrice)\n",
    "                if det != 0:\n",
    "                    inversa = np.linalg.inv(matrice)\n",
    "                else:\n",
    "                    print(\"La matrice non è invertibile (determinante nullo).\")\n",
    "\n",
    "            print(\"xi @ inversa:\", xi @ inversa)\n",
    "\n",
    "            # Cambio base\n",
    "            if(float((xi @ inversa)[0]) > 0):\n",
    "                matrice = np.zeros((C, C))\n",
    "                matrice[0] = -v\n",
    "                matrice[1] = np.ones(C, dtype=int)\n",
    "                zero_indices = np.where(x_opt == 0)[0]\n",
    "                for i in range(C-2):\n",
    "                    if i < len(zero_indices):\n",
    "                        matrice[i + 2][zero_indices[i]] = -1\n",
    "                det = np.linalg.det(matrice)\n",
    "                if det != 0:\n",
    "                    inversa = np.linalg.inv(matrice)\n",
    "                else:\n",
    "                    print(\"La matrice non è invertibile (determinante nullo).\")\n",
    "\n",
    "            # Stampo i risultati\n",
    "            print(\"La matrice di base è:\\n\", matrice)\n",
    "            print(\"L'inversa della matrice è:\\n\", inversa)\n",
    "            if(x_opt is not None):\n",
    "                print(\"\\n-------------------------- RISULTATI --------------------------\")\n",
    "                print(\"Dual variable for equality constraint (v @ x == w):\", float((xi @ inversa)[0]))\n",
    "                print(\"VS\")\n",
    "                print(\"Dual variable for equality constraint (v @ x == w):\", equality_constraint_pruning.dual_value[0])\n",
    "\n",
    "                x_star = inversa @ np.array([-float(w), 1, 0, 0, 0])\n",
    "                print(\"x_star:\", np.array2string(np.array(x_star), precision=2, separator=', '))\n",
    "                print(\"VS\")\n",
    "                print(\"x_star:\", np.array2string(x_pruning.value, precision=2, separator=', ', suppress_small=True))\n",
    "\n",
    "                prima_colonna = inversa[:, 0]\n",
    "                non_nulli = prima_colonna[prima_colonna != 0]\n",
    "                print(\"Elementi non nulli della prima colonna:\", non_nulli)\n",
    "\n",
    "            print(\"\\n\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b019ae32",
   "metadata": {},
   "source": [
    "# TEST DEI MOLTIPLICATORI (SENZA IL VINCOLO ATTIVO = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f806a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/cvxpy/reductions/solvers/solving_chain.py:356: FutureWarning: \n",
      "    You specified your problem should be solved by ECOS. Starting in\n",
      "    CXVPY 1.6.0, ECOS will no longer be installed by default with CVXPY.\n",
      "    Please either add ECOS as an explicit install dependency to your project\n",
      "    or switch to our new default solver, Clarabel, by either not specifying a\n",
      "    solver argument or specifying ``solver=cp.CLARABEL``. To suppress this\n",
      "    warning while continuing to use ECOS, you can filter this warning using\n",
      "    Python's ``warnings`` module until you are using 1.6.0.\n",
      "    \n",
      "  warnings.warn(ECOS_DEP_DEPRECATION_MSG, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST EFFETTUATO CON SUCCESSO!\n"
     ]
    }
   ],
   "source": [
    "# Dimension of vectors xi, v, and x\n",
    "C = 32\n",
    "M = 1\n",
    "\n",
    "SUCCESS = 1\n",
    "\n",
    "np.random.seed(43)  \n",
    "torch.manual_seed(43)\n",
    "for _ in range(10000):\n",
    "    xi = torch.sort(torch.rand(C))[0]\n",
    "    v = torch.linspace(0, 1 - (1 / C), C)\n",
    "    w = torch.rand(M)\n",
    "    #w = v[torch.randint(0, C, (1,))]  \n",
    "    \n",
    "    # cvxpy solution with inequality constraint (pruning)\n",
    "    x_pruning = cp.Variable(C)\n",
    "    equality_constraint_pruning = v @ x_pruning == w\n",
    "    constraints_pruning = [\n",
    "        equality_constraint_pruning,\n",
    "        cp.sum(x_pruning) <= 1,\n",
    "        x_pruning >= 0,\n",
    "        x_pruning <= 1\n",
    "    ]\n",
    "    objective_pruning = cp.Minimize(xi @ x_pruning)\n",
    "    prob_pruning = cp.Problem(objective_pruning, constraints_pruning)\n",
    "    prob_pruning.solve(solver=cp.ECOS)\n",
    "    \n",
    "    if(equality_constraint_pruning.dual_value is not None):\n",
    "        y1 = round(equality_constraint_pruning.dual_value[0], 2)\n",
    "        #print(\"Lagrange multiplier:\", y1)\n",
    "        #print(\"np.count_nonzero(np.abs(x_pruning.value) > 1e-6):\", np.count_nonzero(np.abs(x_pruning.value) > 1e-6))\n",
    "        if(np.count_nonzero(np.abs(x_pruning.value) > 1e-6) == 2):\n",
    "            i = np.nonzero(np.abs(x_pruning.value) > 1e-6) # i[0] è la lista [indice1, indice2]\n",
    "            diff = i[0][1] - i[0][0]\n",
    "            y2 = round(float(-C / diff * (xi[i[0][1]] - xi[i[0][0]])), 2)\n",
    "        else:\n",
    "            i = np.nonzero(np.abs(x_pruning.value) > 1e-6)\n",
    "            y2 = round(float(-C / i[0][0] * xi[i[0][0]]), 2) # i[0][0] è l'indice\n",
    "        if(y1 != y2 and np.all(x_pruning.value != 1)):\n",
    "            print(\"C'È STATO UN ERRORE NEL CALCOLO DEI MOLTIPLICATORI!\\n\")\n",
    "            print(\"DATI:\")\n",
    "            print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "            print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "            print(\"w:\", w, \"\\n\")\n",
    "            print(\"y1:\", y1)\n",
    "            print(\"y2:\", y2)\n",
    "            SUCCESS = 0\n",
    "        #print(\"Lagrange multiplier:\", y2, \"\\n\")\n",
    "if(SUCCESS == 1):\n",
    "    print(\"TEST EFFETTUATO CON SUCCESSO!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e757faa",
   "metadata": {},
   "source": [
    "# TEST DEI MOLTIPLICATORI (CON IL VINCOLO ATTIVO = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd67347a",
   "metadata": {},
   "source": [
    "### In realtà questo test è uguale a quello della cella sopra. \n",
    "### Ho solo sostituito la condizione \n",
    "### if(y1 != y2 and np.all(x_pruning.value != 1)): \n",
    "### con la condizione\n",
    "### if(y1 != y2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8213e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST EFFETTUATO CON SUCCESSO!\n"
     ]
    }
   ],
   "source": [
    "# Dimension of vectors xi, v, and x\n",
    "C = 5\n",
    "M = 1\n",
    "\n",
    "SUCCESS = 1\n",
    "\n",
    "np.random.seed(45)  \n",
    "torch.manual_seed(45)\n",
    "for _ in range(10000):\n",
    "    xi = torch.sort(torch.rand(C))[0]\n",
    "    v = torch.linspace(0, 1 - (1 / C), C)\n",
    "    w = torch.rand(M)\n",
    "    #w = v[torch.randint(0, C, (1,))]  \n",
    "    \n",
    "    # cvxpy solution with inequality constraint (pruning)\n",
    "    x_pruning = cp.Variable(C)\n",
    "    equality_constraint_pruning = v @ x_pruning == w\n",
    "    constraints_pruning = [\n",
    "        equality_constraint_pruning,\n",
    "        cp.sum(x_pruning) <= 1,\n",
    "        x_pruning >= 0,\n",
    "        x_pruning <= 1\n",
    "    ]\n",
    "    objective_pruning = cp.Minimize(xi @ x_pruning)\n",
    "    prob_pruning = cp.Problem(objective_pruning, constraints_pruning)\n",
    "    prob_pruning.solve(solver=cp.ECOS)\n",
    "    if(equality_constraint_pruning.dual_value is not None):\n",
    "        y1 = round(equality_constraint_pruning.dual_value[0], 2)\n",
    "        #print(\"Lagrange multiplier:\", y1)\n",
    "        #print(\"np.count_nonzero(np.abs(x_pruning.value) > 1e-6):\", np.count_nonzero(np.abs(x_pruning.value) > 1e-6))\n",
    "        if(np.count_nonzero(np.abs(x_pruning.value) > 1e-6) == 2):\n",
    "            i = np.nonzero(np.abs(x_pruning.value) > 1e-6) # i[0] è la lista [indice1, indice2]\n",
    "            diff = i[0][1] - i[0][0]\n",
    "            y2 = round(float(-C / diff * (xi[i[0][1]] - xi[i[0][0]])), 2)\n",
    "        else:\n",
    "            i = np.nonzero(np.abs(x_pruning.value) > 1e-6)\n",
    "            y2 = round(-float(xi[i[0][0]] / v[i[0][0]]), 2) # i[0][0] è l'indice\n",
    "        if(y1 != y2):\n",
    "            print(\"C'È STATO UN ERRORE NEL CALCOLO DEI MOLTIPLICATORI!\\n\")\n",
    "            print(\"DATI:\")\n",
    "            print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "            print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "            print(\"w:\", w, \"\\n\")\n",
    "            print(\"y1:\", y1)\n",
    "            print(\"y2:\", y2)\n",
    "            SUCCESS = 0\n",
    "        #print(\"Lagrange multiplier:\", y2, \"\\n\")\n",
    "if(SUCCESS == 1):\n",
    "    print(\"TEST EFFETTUATO CON SUCCESSO!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7adec",
   "metadata": {},
   "source": [
    "# TEST DELLE SOLUZIONI E DEI MOLTIPLICATORI CON v GENERCIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b11b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST CONCLUSO CON SUCCESSO!\n",
      "\n",
      "\n",
      "conta_istanze_risolubili: 710\n"
     ]
    }
   ],
   "source": [
    "def knapsack_specialized_pruning_complete(xi, v, w, C):\n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "\n",
    "    if(w > v[-1] or w < v[0]):\n",
    "        #print(\"No solutions.\")\n",
    "        x = None\n",
    "        objective_values = None\n",
    "    else:\n",
    "        b_vector = np.argsort(xi/v)\n",
    "        b = np.searchsorted(xi/v, 0)\n",
    "        b_list_new = [b_vector[b]] \n",
    "        #print(f\"Inizializzazione di b_vector[b]: {b_vector[b]}\")\n",
    "        #print(f\"w/v[b_vector[b]] > 1: {w/v[b_vector[b]] > 1}, x_plus[b_vector[b]] == 0: {x_plus[b_vector[b]] == 0}, int(b_vector[b]) < int(b_list_new[0]): {int(b_vector[b]) < int(b_list_new[0])}\")\n",
    "        while(w/v[b_vector[b]] > 1 or x_plus[b_vector[b]] == 0 or int(b_vector[b]) < int(b_list_new[0])):\n",
    "            b += 1\n",
    "            if(v[b_vector[b]] < 0):\n",
    "                continue\n",
    "            if(x_plus[b_vector[b]] == 1 and int(b_vector[b]) > int(b_list_new[0])):\n",
    "                b_list_new.append(b_vector[b])\n",
    "                #print(f\"w: {w}, v[b_vector[b]]: {v[b_vector[b]]}, w/v[b_vector[b]]: {w/v[b_vector[b]]}\")\n",
    "                #print(f\"b_list_new:\", b_list_new)\n",
    "                #print(\"xi (sicurezza):\", xi)\n",
    "            if(len(b_list_new) > 2):\n",
    "                b_list_new.pop(0)\n",
    "        #print(f\"b_list_new:\", b_list_new)\n",
    "        x = np.zeros(C)\n",
    "        \n",
    "        if(len(b_list_new) == 1):\n",
    "            x[b_list_new[0]] = round(float(w/v[b_list_new[0]]), 2)\n",
    "        else:\n",
    "            x1, x2 = torch.zeros(2, len(w), C, dtype=torch.float32)\n",
    "            x1[torch.arange(len(w)), b_list_new[0]] = 1\n",
    "            x2[torch.arange(len(w)), b_list_new[1]] = 1\n",
    "            numerator = w - torch.matmul(x2, v)\n",
    "            denominator = torch.matmul((x1 - x2), v)\n",
    "            theta = numerator / denominator\n",
    "            x[b_list_new[0]] = round(float(theta), 5)\n",
    "            x[b_list_new[1]] = round(float(1 - theta), 5)\n",
    "        objective_values = torch.matmul(torch.from_numpy(x).float(), xi) \n",
    "    \n",
    "    if(x is None):\n",
    "        lambda_opt = None\n",
    "    elif(np.all(x == 0)):\n",
    "        lambda_opt = None\n",
    "    elif(np.count_nonzero(np.abs(x) > 1e-6) == 2):\n",
    "        i = np.nonzero(np.abs(x) > 1e-6) # i[0] è la lista [indice1, indice2]\n",
    "        #print(\"i:\", i)\n",
    "        diff = i[0][1] - i[0][0]\n",
    "        passo = v[1] - v[0] # Nel caso semplice sarebbe 1/C\n",
    "        lambda_opt = round(float(-1 / (diff * passo) * (xi[i[0][1]] - xi[i[0][0]])), 2)\n",
    "    elif(np.count_nonzero(np.abs(x) > 1e-6) == 1):\n",
    "        i = np.nonzero(np.abs(x) > 1e-6)\n",
    "        #print(\"x:\", x)\n",
    "        #print(\"i:\", i)\n",
    "        lambda_opt = round(-float(xi[i[0][0]] / v[i[0][0]]), 2) # i[0][0] è l'indice\n",
    "    else:\n",
    "        print(\"A\"*10000000) # Caso da trattare\n",
    "    \n",
    "    return x, lambda_opt, objective_values, x_plus\n",
    "\n",
    "# Dimension of vectors xi, v, and x\n",
    "C = 17\n",
    "M = 1\n",
    "\n",
    "np.random.seed(43)  \n",
    "torch.manual_seed(43)\n",
    "conta_istanze_risolubili = 0\n",
    "SUCCESS = 1\n",
    "\n",
    "for i in range(1000):\n",
    "    xi = torch.sort(torch.rand(C))[0]\n",
    "    w0 = 0.3\n",
    "    r = 0.43\n",
    "    min_w, max_w = w0 - r, w0 + r\n",
    "    v = torch.linspace(min_w, max_w - (max_w - min_w)/C, steps=C)\n",
    "    w = torch.rand(M)\n",
    "    #w = v[torch.randint(0, C, (1,))]  \n",
    "    \n",
    "    #print(f\"\\nIteration: {i}\")\n",
    "    #print(\"DATI:\")\n",
    "    #print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "    #print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "    #print(\"w:\", w, \"\\n\")\n",
    "    \n",
    "    x_opt, lambda_opt, phi_opt, x_plus = knapsack_specialized_pruning_complete(xi, v, w, C)\n",
    "    \n",
    "    # cvxpy solution with inequality constraint (pruning)\n",
    "    x_pruning = cp.Variable(C)\n",
    "    equality_constraint_pruning = v @ x_pruning == w\n",
    "    constraints_pruning = [\n",
    "        equality_constraint_pruning,\n",
    "        cp.sum(x_pruning) <= 1,\n",
    "        x_pruning >= 0,\n",
    "        x_pruning <= 1\n",
    "    ]\n",
    "    objective_pruning = cp.Minimize(xi @ x_pruning)\n",
    "    prob_pruning = cp.Problem(objective_pruning, constraints_pruning)\n",
    "    prob_pruning.solve(solver=cp.ECOS)\n",
    "\n",
    "    #if prob_pruning.value is not None and x_pruning.value is not None:\n",
    "    #    print(f\"Objective value (pruning): {prob_pruning.value:.2f}\")\n",
    "    #    print(\"Optimal x (pruning):\", \n",
    "    #          np.array2string(x_pruning.value, precision=2, separator=', ', suppress_small=True))\n",
    "    #else:\n",
    "    #    print(\"No solution found for the problem with pruning.\")\n",
    "    \n",
    "    #print(\"x1:\", x_pruning.value)\n",
    "    #print(\"x2:\", x_opt)\n",
    "\n",
    "    if(lambda_opt is not None):\n",
    "        conta_istanze_risolubili += 1\n",
    "        if(not np.allclose(x_pruning.value, x_opt, rtol=1e-5, atol=1e-2)):\n",
    "            SUCCESS = 0\n",
    "            print(f\"{i} ERRORE NELLE SOLUZIONI:\")\n",
    "            print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "            print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "            print(\"w:\", round(float(w), 4), \"\\n\")\n",
    "            print(\"x_opt:\", x_opt)\n",
    "            print(\"x_pruning.value:\", x_pruning.value)\n",
    "            print(\"xi/v:\", xi/v)\n",
    "            print(\"x_plus:\", x_plus)\n",
    "            #print(\"Soluzione del solver:\", x1)\n",
    "            #print(\"Soluzione mia:\", x2)\n",
    "            #print(\"f.o. solver:\", round(prob_pruning.value, 4))\n",
    "            #print(\"f.o. mia:\", round(float(phi_opt), 4))\n",
    "            #print(f\"Il vincolo w=v*x è soddisfatto con la mia soluzione? w = {w}, v*x={v @ x_opt}\")\n",
    "            print(\"-\"*40)\n",
    "        if(np.abs(equality_constraint_pruning.dual_value[0] - lambda_opt) > 5e-2):\n",
    "            SUCCESS = 0\n",
    "            print(f\"{i} ERRORE NEI MOLTIPLICATORI:\")\n",
    "            print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "            print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "            print(\"w:\", round(float(w), 4), \"\\n\")\n",
    "            print(\"x_opt:\", x_opt)\n",
    "            print(\"x_pruning.value:\", x_pruning.value)\n",
    "            print(\"xi/v:\", xi/v)\n",
    "            print(\"x_plus:\", x_plus)\n",
    "            #print(\"Soluzione del solver:\", x1)\n",
    "            #print(\"Soluzione mia:\", x2)\n",
    "            #print(\"f.o. solver:\", round(prob_pruning.value, 4))\n",
    "            #print(\"f.o. mia:\", round(float(phi_opt), 4))\n",
    "            #print(f\"Il vincolo w=v*x è soddisfatto con la mia soluzione? w = {w}, v*x={v @ x_opt}\")\n",
    "            print(\"y1:\", equality_constraint_pruning.dual_value[:])\n",
    "            print(\"y2:\", lambda_opt)\n",
    "            print(\"-\"*40)\n",
    "            \n",
    "    #else:\n",
    "    #    print(\"Objective value (knapsack_specialized_pruning):\", phi_opt)\n",
    "    #    print(\"Optimal x (knapsack_specialized_pruning):\", x_opt)\n",
    "    \n",
    "    #print(\"-\"*40)\n",
    "if(SUCCESS == 1):\n",
    "    print(\"TEST CONCLUSO CON SUCCESSO!\")\n",
    "    \n",
    "print(\"\\n\\nconta_istanze_risolubili:\", conta_istanze_risolubili)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02286a29",
   "metadata": {},
   "source": [
    "# TEST CON w generico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b357a",
   "metadata": {},
   "source": [
    "### Effettuo anche un paio di conteggi e li stampo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc155b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST CONCLUSO CON SUCCESSO!\n",
      "\n",
      "\n",
      "conta_istanze_risolubili: 997\n",
      "conta_soluzioni_sotto_soglia: 86\n",
      "conta_soluzioni_errate: 0\n",
      "conta_moltiplicatori_errati: 0\n"
     ]
    }
   ],
   "source": [
    "def knapsack_specialized_pruning_complete(xi, v, w, C):\n",
    "    #print(\"************** DENTRO knapsack_specialized_pruning_complete **************\")\n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "    #print(\"xi:\", xi)\n",
    "    #print(\"x_plus:\", x_plus)\n",
    "    if(w > v[-1] or w < v[0]):\n",
    "        #print(\"No solutions.\")\n",
    "        x = None\n",
    "        objective_values = None\n",
    "    else:\n",
    "        #b_vector = np.argsort(xi/v)\n",
    "        ratio = (xi/v).numpy()\n",
    "        neg_indices = np.where(ratio < 0)[0]\n",
    "        neg_sorted = neg_indices[np.argsort(ratio[neg_indices])[::-1]]\n",
    "        pos_indices = np.where(ratio >= 0)[0]\n",
    "        pos_sorted = pos_indices[np.argsort(ratio[pos_indices])]\n",
    "        b_vector = np.concatenate([neg_sorted, pos_sorted])\n",
    "        \n",
    "        #print(\"b_vector:\", b_vector)\n",
    "        #print(\"w/v[b_vector[0]]:\", w/v[b_vector[0]])\n",
    "\n",
    "        b = 0\n",
    "        while(w/v[b_vector[b]] < 0 or x_plus[b_vector[b]] == 0):\n",
    "            b += 1\n",
    "            #print(f\"w/v[b_vector[{b}]]:\", w/v[b_vector[b]])\n",
    "\n",
    "        b_list_new = [b_vector[b]] \n",
    "        #print(\"b è stato inizializzato a:\", b)\n",
    "        #print(\"b_list_new:\", b_list_new)\n",
    "        \n",
    "        #print(f\"Inizializzazione di b_vector[b]: {b_vector[b]}\")\n",
    "        #print(f\"w/v[b_vector[b]] > 1: {w/v[b_vector[b]] > 1}, x_plus[b_vector[b]] == 0: {x_plus[b_vector[b]] == 0}, int(b_vector[b]) < int(b_list_new[0]): {int(b_vector[b]) < int(b_list_new[0])}\")\n",
    "        while(w/v[b_vector[b]] > 1 or x_plus[b_vector[b]] == 0 or int(b_vector[b]) < int(b_list_new[0])):\n",
    "            b += 1\n",
    "            if(w/v[b_vector[b]] < 0):\n",
    "                continue\n",
    "            if(x_plus[b_vector[b]] == 1 and int(b_vector[b]) > int(b_list_new[0])):\n",
    "                b_list_new.append(b_vector[b])\n",
    "                #print(f\"w: {w}, v[b_vector[b]]: {v[b_vector[b]]}, w/v[b_vector[b]]: {w/v[b_vector[b]]}\")\n",
    "                #print(f\"b_list_new:\", b_list_new)\n",
    "                #print(\"xi (sicurezza):\", xi)\n",
    "            if(len(b_list_new) > 2):\n",
    "                b_list_new.pop(0)\n",
    "                \n",
    "        if(len(b_list_new) == 1 and w/v[b_list_new[0]] > 1):\n",
    "            b_list_new[0] = 0\n",
    "            \n",
    "        #print(f\"b_list_new:\", b_list_new)\n",
    "        x = np.zeros(C)\n",
    "        \n",
    "        if(len(b_list_new) == 1):\n",
    "            x[b_list_new[0]] = round(float(w/v[b_list_new[0]]), 2)\n",
    "        else:\n",
    "            x1, x2 = torch.zeros(2, len(w), C, dtype=torch.float32)\n",
    "            x1[torch.arange(len(w)), b_list_new[0]] = 1\n",
    "            x2[torch.arange(len(w)), b_list_new[1]] = 1\n",
    "            numerator = w - torch.matmul(x2, v)\n",
    "            denominator = torch.matmul((x1 - x2), v)\n",
    "            theta = numerator / denominator\n",
    "            x[b_list_new[0]] = round(float(theta), 5)\n",
    "            x[b_list_new[1]] = round(float(1 - theta), 5)\n",
    "        objective_values = torch.matmul(torch.from_numpy(x).float(), xi) \n",
    "    \n",
    "    if(x is None):\n",
    "        lambda_opt = None\n",
    "    elif(np.all(x == 0)):\n",
    "        lambda_opt = None\n",
    "    elif(np.count_nonzero(np.abs(x) > 1e-6) == 2):\n",
    "        i = np.nonzero(np.abs(x) > 1e-6) # i[0] è la lista [indice1, indice2]\n",
    "        #print(\"i:\", i)\n",
    "        diff = i[0][1] - i[0][0]\n",
    "        passo = v[1] - v[0] # Nel caso semplice sarebbe 1/C\n",
    "        lambda_opt = round(float(-1 / (diff * passo) * (xi[i[0][1]] - xi[i[0][0]])), 2)\n",
    "    elif(np.count_nonzero(np.abs(x) > 1e-6) == 1):\n",
    "        i = np.nonzero(np.abs(x) > 1e-6)\n",
    "        #print(\"x:\", x)\n",
    "        #print(\"i:\", i)\n",
    "        lambda_opt = round(-float(xi[i[0][0]] / v[i[0][0]]), 2) # i[0][0] è l'indice\n",
    "    else:\n",
    "        print(\"ERROR: SOLUTION NOT ACCEPTABLE!\")\n",
    "\n",
    "    #print(\"**************************************************************************\")\n",
    "    return x, lambda_opt, objective_values, x_plus\n",
    "\n",
    "# Dimension of vectors xi, v, and x\n",
    "C = 29\n",
    "M = 1\n",
    "\n",
    "np.random.seed(42)  \n",
    "torch.manual_seed(42)\n",
    "\n",
    "conta_istanze_risolubili = 0\n",
    "conta_soluzioni_sotto_soglia = 0\n",
    "conta_moltiplicatori_errati = 0\n",
    "conta_soluzioni_errate = 0\n",
    "\n",
    "SUCCESS = 1\n",
    "\n",
    "for i in range(1000):\n",
    "    xi = torch.sort(torch.rand(C))[0]\n",
    "    w0 = 0\n",
    "    r = 1.1\n",
    "    min_w, max_w = w0 - r, w0 + r\n",
    "    v = torch.linspace(min_w, max_w - (max_w - min_w)/C, steps=C)\n",
    "    a = -1\n",
    "    b = 1\n",
    "    w = torch.rand(M) * (b - a) + a\n",
    "\n",
    "\n",
    "    #w = v[torch.randint(0, C, (1,))]  \n",
    "    \n",
    "    #print(f\"\\nIteration: {i}\")\n",
    "    #print(\"DATI:\")\n",
    "    #print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "    #print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "    #print(\"w:\", w, \"\\n\")\n",
    "    \n",
    "    x_opt, lambda_opt, phi_opt, x_plus = knapsack_specialized_pruning_complete(xi, v, w, C)\n",
    "    \n",
    "    soglia = 0.1\n",
    "    if(x_opt is not None):\n",
    "        if(np.max(x_opt) < soglia):\n",
    "            conta_soluzioni_sotto_soglia += 1\n",
    "            #print(\"x_opt:\", x_opt, \"lambda_opt:\", lambda_opt)\n",
    "            \n",
    "    # cvxpy solution with inequality constraint (pruning)\n",
    "    x_pruning = cp.Variable(C)\n",
    "    equality_constraint_pruning = v @ x_pruning == w\n",
    "    constraints_pruning = [\n",
    "        equality_constraint_pruning,\n",
    "        cp.sum(x_pruning) <= 1,\n",
    "        x_pruning >= 0,\n",
    "        x_pruning <= 1\n",
    "    ]\n",
    "    objective_pruning = cp.Minimize(xi @ x_pruning)\n",
    "    prob_pruning = cp.Problem(objective_pruning, constraints_pruning)\n",
    "    prob_pruning.solve(solver=cp.ECOS)\n",
    "\n",
    "    #if prob_pruning.value is not None and x_pruning.value is not None:\n",
    "    #    print(f\"Objective value (pruning): {prob_pruning.value:.2f}\")\n",
    "    #    print(\"Optimal x (pruning):\", \n",
    "    #          np.array2string(x_pruning.value, precision=2, separator=', ', suppress_small=True))\n",
    "    #else:\n",
    "    #    print(\"No solution found for the problem with pruning.\")\n",
    "    \n",
    "    #print(\"x1:\", x_pruning.value)\n",
    "    #print(\"x2:\", x_opt)\n",
    "\n",
    "    if(lambda_opt is not None):\n",
    "        conta_istanze_risolubili += 1\n",
    "        if(not np.allclose(x_pruning.value, x_opt, rtol=1e-5, atol=1e-2)):\n",
    "            conta_soluzioni_errate += 1\n",
    "            SUCCESS = 0\n",
    "            print(f\"{i} ERRORE NELLE SOLUZIONI:\")\n",
    "            print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "            print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "            print(\"w:\", round(float(w), 4), \"\\n\")\n",
    "            print(\"x_opt:\", x_opt)\n",
    "            print(\"x_pruning.value:\", x_pruning.value)\n",
    "            print(\"xi/v:\", xi/v)\n",
    "            print(\"x_plus:\", x_plus)\n",
    "            #print(\"Soluzione del solver:\", x1)\n",
    "            #print(\"Soluzione mia:\", x2)\n",
    "            #print(\"f.o. solver:\", round(prob_pruning.value, 4))\n",
    "            #print(\"f.o. mia:\", round(float(phi_opt), 4))\n",
    "            #print(f\"Il vincolo w=v*x è soddisfatto con la mia soluzione? w = {w}, v*x={v @ x_opt}\")\n",
    "            print(\"-\"*40)\n",
    "        if(np.abs(equality_constraint_pruning.dual_value[0] - lambda_opt) > 5e-2):\n",
    "            conta_moltiplicatori_errati += 1\n",
    "            SUCCESS = 0\n",
    "            print(f\"{i} ERRORE NEI MOLTIPLICATORI:\")\n",
    "            print(\"xi:\", np.array2string(np.array(xi), precision=2, separator=', '))\n",
    "            print(\"v:\", np.array2string(np.array(v), precision=2, separator=', '))\n",
    "            print(\"w:\", round(float(w), 4), \"\\n\")\n",
    "            print(\"x_opt:\", x_opt)\n",
    "            print(\"x_pruning.value:\", x_pruning.value)\n",
    "            print(\"xi/v:\", xi/v)\n",
    "            print(\"x_plus:\", x_plus)\n",
    "            #print(\"Soluzione del solver:\", x1)\n",
    "            #print(\"Soluzione mia:\", x2)\n",
    "            #print(\"f.o. solver:\", round(prob_pruning.value, 4))\n",
    "            #print(\"f.o. mia:\", round(float(phi_opt), 4))\n",
    "            #print(f\"Il vincolo w=v*x è soddisfatto con la mia soluzione? w = {w}, v*x={v @ x_opt}\")\n",
    "            print(\"y1:\", equality_constraint_pruning.dual_value[:])\n",
    "            print(\"y2:\", lambda_opt)\n",
    "            print(\"-\"*40)\n",
    "            print(\"\\n\\n\")\n",
    "            \n",
    "    #else:\n",
    "    #    print(\"Objective value (knapsack_specialized_pruning):\", phi_opt)\n",
    "    #    print(\"Optimal x (knapsack_specialized_pruning):\", x_opt)\n",
    "    \n",
    "    #print(\"-\"*40)\n",
    "if(SUCCESS == 1):\n",
    "    print(\"\\nTEST CONCLUSO CON SUCCESSO!\")\n",
    "    \n",
    "print(\"\\n\\nconta_istanze_risolubili:\", conta_istanze_risolubili)\n",
    "print(\"conta_soluzioni_sotto_soglia:\", conta_soluzioni_sotto_soglia)\n",
    "print(\"conta_soluzioni_errate:\", conta_soluzioni_errate)\n",
    "print(\"conta_moltiplicatori_errati:\", conta_moltiplicatori_errati)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec50bea",
   "metadata": {},
   "source": [
    "# VERSIONE PULITA SENZA DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "389c880b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST CONCLUSO CON SUCCESSO!\n",
      "\n",
      "\n",
      "conta_istanze_risolubili: 600\n",
      "conta_soluzioni_sotto_soglia: 106\n",
      "conta_soluzioni_errate: 0\n",
      "conta_moltiplicatori_errati: 0\n"
     ]
    }
   ],
   "source": [
    "def knapsack_specialized_pruning_complete(xi, v, w, C):\n",
    "\n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "            \n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "\n",
    "    if(w > v[-1] or w < v[0]):\n",
    "        x = None\n",
    "        objective_values = None\n",
    "    else:\n",
    "        ratio = (xi/v).numpy()\n",
    "        neg_indices = np.where(ratio < 0)[0]\n",
    "        neg_sorted = neg_indices[np.argsort(ratio[neg_indices])[::-1]]\n",
    "        pos_indices = np.where(ratio >= 0)[0]\n",
    "        pos_sorted = pos_indices[np.argsort(ratio[pos_indices])]\n",
    "        b_vector = np.concatenate([neg_sorted, pos_sorted])\n",
    "\n",
    "        b = 0\n",
    "        while(w/v[b_vector[b]] < 0 or x_plus[b_vector[b]] == 0):\n",
    "            b += 1\n",
    "\n",
    "        b_list_new = [b_vector[b]] \n",
    "        \n",
    "        while(w/v[b_vector[b]] > 1 or x_plus[b_vector[b]] == 0 or int(b_vector[b]) < int(b_list_new[0])):\n",
    "            b += 1\n",
    "            if(w/v[b_vector[b]] < 0):\n",
    "                continue\n",
    "            if(x_plus[b_vector[b]] == 1 and int(b_vector[b]) > int(b_list_new[0])):\n",
    "                b_list_new.append(b_vector[b])\n",
    "            if(len(b_list_new) > 2):\n",
    "                b_list_new.pop(0)\n",
    "                \n",
    "        if(len(b_list_new) == 1 and w/v[b_list_new[0]] > 1):\n",
    "            b_list_new[0] = 0\n",
    "            \n",
    "        x = np.zeros(C)\n",
    "        \n",
    "        if(len(b_list_new) == 1):\n",
    "            x[b_list_new[0]] = round(float(w/v[b_list_new[0]]), 5)\n",
    "        else:\n",
    "            x1, x2 = torch.zeros(2, len(w), C, dtype=torch.float32)\n",
    "            x1[torch.arange(len(w)), b_list_new[0]] = 1\n",
    "            x2[torch.arange(len(w)), b_list_new[1]] = 1\n",
    "            numerator = w - torch.matmul(x2, v)\n",
    "            denominator = torch.matmul((x1 - x2), v)\n",
    "            theta = numerator / denominator\n",
    "            x[b_list_new[0]] = round(float(theta), 5)\n",
    "            x[b_list_new[1]] = round(float(1 - theta), 5)\n",
    "        objective_values = torch.matmul(torch.from_numpy(x).float(), xi) \n",
    "    \n",
    "    if(x is None): # Al caso di soluzione vuota faccio corrispondere un moltiplicatore vuoto \n",
    "        lambda_opt = None\n",
    "    elif(np.all(x == 0)): # Al caso di soluzione nulla faccio corrispondere un moltiplicatore nullo\n",
    "        lambda_opt = 0\n",
    "    elif(np.count_nonzero(np.abs(x) > 1e-6) == 2):\n",
    "        i = np.nonzero(np.abs(x) > 1e-6) # i[0] è la lista [indice1, indice2]\n",
    "        diff = i[0][1] - i[0][0]\n",
    "        passo = v[1] - v[0] # Nel caso semplice sarebbe 1/C\n",
    "        lambda_opt = round(float(-1 / (diff * passo) * (xi[i[0][1]] - xi[i[0][0]])), 5)\n",
    "    elif(np.count_nonzero(np.abs(x) > 1e-6) == 1):\n",
    "        i = np.nonzero(np.abs(x) > 1e-6)\n",
    "        lambda_opt = round(-float(xi[i[0][0]] / v[i[0][0]]), 5) # i[0][0] è l'indice\n",
    "    else:\n",
    "        print(\"ERROR: SOLUTION NOT ACCEPTABLE!\")\n",
    "\n",
    "    return x, lambda_opt, objective_values, x_plus\n",
    "\n",
    "# Dimension of vectors xi, v, and x\n",
    "C = 29\n",
    "M = 1\n",
    "\n",
    "np.random.seed(42)  \n",
    "torch.manual_seed(42)\n",
    "\n",
    "conta_istanze_risolubili = 0\n",
    "conta_soluzioni_sotto_soglia = 0\n",
    "conta_moltiplicatori_errati = 0\n",
    "conta_soluzioni_errate = 0\n",
    "\n",
    "SUCCESS = 1\n",
    "\n",
    "for i in range(1000):\n",
    "    xi = torch.sort(torch.rand(C))[0]\n",
    "    w0 = -0.01\n",
    "    r = 1.32\n",
    "    min_w, max_w = w0 - r, w0 + r\n",
    "    v = torch.linspace(min_w, max_w - (max_w - min_w)/C, steps=C)\n",
    "    a = -0.23\n",
    "    b = 2.11\n",
    "    w = torch.rand(M) * (b - a) + a\n",
    "    \n",
    "    x_opt, lambda_opt, phi_opt, x_plus = knapsack_specialized_pruning_complete(xi, v, w, C)\n",
    "    \n",
    "    soglia = 0.1\n",
    "    if(x_opt is not None):\n",
    "        conta_istanze_risolubili += 1\n",
    "        if(np.max(x_opt) < soglia):\n",
    "            conta_soluzioni_sotto_soglia += 1\n",
    "            \n",
    "    # cvxpy solution with inequality constraint (pruning)\n",
    "    x_pruning = cp.Variable(C)\n",
    "    equality_constraint_pruning = v @ x_pruning == w\n",
    "    constraints_pruning = [\n",
    "        equality_constraint_pruning,\n",
    "        cp.sum(x_pruning) <= 1,\n",
    "        x_pruning >= 0,\n",
    "        x_pruning <= 1\n",
    "    ]\n",
    "    objective_pruning = cp.Minimize(xi @ x_pruning)\n",
    "    prob_pruning = cp.Problem(objective_pruning, constraints_pruning)\n",
    "    prob_pruning.solve(solver=cp.ECOS)\n",
    "    \n",
    "    if(x_opt is not None):\n",
    "        if(not np.allclose(x_pruning.value, x_opt, rtol=1e-5, atol=1e-2)):\n",
    "            conta_soluzioni_errate += 1\n",
    "            SUCCESS = 0\n",
    "            print(f\"{i} ERRORE NELLE SOLUZIONI:\")\n",
    "        if(np.abs(equality_constraint_pruning.dual_value[0] - lambda_opt) > 5e-2):\n",
    "            conta_moltiplicatori_errati += 1\n",
    "            SUCCESS = 0\n",
    "            print(f\"{i} ERRORE NEI MOLTIPLICATORI:\")\n",
    "            print(x_pruning.value)\n",
    "            \n",
    "if(SUCCESS == 1):\n",
    "    print(\"\\nTEST CONCLUSO CON SUCCESSO!\")\n",
    "    \n",
    "print(\"\\n\\nconta_istanze_risolubili:\", conta_istanze_risolubili)\n",
    "print(\"conta_soluzioni_sotto_soglia:\", conta_soluzioni_sotto_soglia)\n",
    "print(\"conta_soluzioni_errate:\", conta_soluzioni_errate)\n",
    "print(\"conta_moltiplicatori_errati:\", conta_moltiplicatori_errati)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58feb0",
   "metadata": {},
   "source": [
    "# CASO w > v[-1] or w < v[0] (NON PUÒ ESISTERE LA SOLUZIONE MA IN QUALCHE MODO BISOGNA DARLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "508a8336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0063\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81678\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80594\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81024\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.71524\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81978\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00051\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.12083\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81705\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.08103\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00474\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00638\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81675\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.7042\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.04646\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79982\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00284\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78509\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.71676\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01429\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81419\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01258\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.71301\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.09393\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01105\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81049\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81959\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.04227\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00952\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79192\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81204\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80934\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81387\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81265\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01361\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81375\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81666\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01361\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0157\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81623\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0002\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78797\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.73732\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.70514\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81094\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80395\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.69386\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03182\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81705\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.74676\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0068\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01579\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0066\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81601\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02742\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01108\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00087\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01668\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80505\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03422\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03176\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01246\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.74123\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81262\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03024\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01081\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.76227\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03758\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00828\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81432\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80437\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.7367\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79056\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0746\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79519\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81211\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.07473\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00759\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01613\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00411\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81007\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00602\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81912\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81394\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79412\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01009\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.82004\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01254\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80952\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.75659\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0542\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00626\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.04675\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01808\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.06339\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00581\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81846\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80933\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77221\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03553\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00062\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02412\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01789\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02371\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81517\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.04804\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03981\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.72563\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79407\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79819\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00563\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02243\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01556\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01094\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00537\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01479\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81062\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01132\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.7961\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.75621\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02203\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81474\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.07641\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00457\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.11881\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79999\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79511\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80207\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78325\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00841\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79822\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0691\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00212\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80913\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02232\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81072\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.76439\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79589\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01094\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0059\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.7979\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80227\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.06143\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02583\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80134\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00666\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0003\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81167\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80721\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.73225\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81849\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79322\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00315\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.06364\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77386\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81892\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00236\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80783\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81406\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77921\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79795\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03454\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00706\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01792\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81838\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.8141\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77367\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80559\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02531\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81923\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01061\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.76941\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81416\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79012\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78371\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00807\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80467\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00228\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78753\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03846\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.8081\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81183\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80227\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80179\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77919\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79269\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0331\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01843\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00398\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80854\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01328\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02904\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03697\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80857\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77158\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80084\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.06313\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00366\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78711\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01006\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.68153\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81051\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02176\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.091\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01418\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79177\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00173\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.10064\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81193\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01107\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.82005\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80615\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01138\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80792\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.04956\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.7842\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81924\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78586\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78476\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02236\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78283\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00834\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79843\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01656\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81127\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81039\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.7999\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00971\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02589\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77874\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77584\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80438\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80728\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80411\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01061\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00471\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00709\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.8042\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01969\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0128\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81566\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.13952\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01318\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81604\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77505\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79552\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00199\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79987\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78947\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81499\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79898\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01518\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00253\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79904\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80259\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01716\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03969\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.04466\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78855\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01743\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00257\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78058\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81984\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01309\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01165\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80246\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.6762\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81078\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.75608\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81255\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78854\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.7902\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01573\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81303\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80244\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.789\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0761\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79901\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00164\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80696\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0064\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0316\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81282\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.63624\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00558\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.76554\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.68366\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81622\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0033\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01873\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01737\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79642\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03677\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02128\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0517\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80023\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81957\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00647\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.07383\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.8181\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81779\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81924\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79566\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01141\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00707\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81382\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81862\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81894\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00559\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01031\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81535\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00233\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81864\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03125\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.8195\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.73559\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81873\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.75635\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01307\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81587\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.74022\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.69406\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03812\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02073\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.04962\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00492\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81206\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01559\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01847\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77218\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80985\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.03298\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80672\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01083\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.05404\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00357\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00766\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02403\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81913\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78947\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.04461\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78996\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80487\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80761\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.82021\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81376\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0187\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.82012\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81577\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79131\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80681\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81923\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78534\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.781\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77518\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.76065\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00678\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00437\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79285\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.0274\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80192\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01383\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81105\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80467\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.02725\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79192\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80638\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.75238\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81246\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.008\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79694\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00108\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01337\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01482\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78503\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.09528\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00962\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81606\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00876\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80858\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01912\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79474\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.04699\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.76113\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80322\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.78253\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77757\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.07533\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00548\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81499\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.8044\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79146\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81858\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.07357\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.76209\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.00839\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79896\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79046\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.77014\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81178\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.79931\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81568\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80362\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: 0.01945\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80673\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.80661\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "x_opt: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1.]\n",
      "x_pruning.value: None\n",
      "lambda_opt: -0.81137\n",
      "equality_constraint_pruning.dual_value: None\n",
      "--------------------------------------------------\n",
      "\n",
      "TEST CONCLUSO CON SUCCESSO!\n",
      "\n",
      "\n",
      "conta_istanze_risolubili: 592\n",
      "conta_soluzioni_sotto_soglia: 0\n",
      "conta_soluzioni_errate: 0\n",
      "conta_moltiplicatori_errati: 0\n"
     ]
    }
   ],
   "source": [
    "def knapsack_specialized_pruning_complete(xi, v, w, C):\n",
    "\n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "            \n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "\n",
    "    if(w > v[-1]):\n",
    "        x = np.zeros(C)\n",
    "        x[-1] = 1\n",
    "    elif(w < v[0]):\n",
    "        x = np.zeros(C)\n",
    "        x[0] = 1\n",
    "    else:\n",
    "        ratio = (xi/v).numpy()\n",
    "        neg_indices = np.where(ratio < 0)[0]\n",
    "        neg_sorted = neg_indices[np.argsort(ratio[neg_indices])[::-1]]\n",
    "        pos_indices = np.where(ratio >= 0)[0]\n",
    "        pos_sorted = pos_indices[np.argsort(ratio[pos_indices])]\n",
    "        b_vector = np.concatenate([neg_sorted, pos_sorted])\n",
    "\n",
    "        b = 0\n",
    "        while(w/v[b_vector[b]] < 0 or x_plus[b_vector[b]] == 0):\n",
    "            b += 1\n",
    "\n",
    "        b_list_new = [b_vector[b]] \n",
    "        \n",
    "        while(w/v[b_vector[b]] > 1 or x_plus[b_vector[b]] == 0 or int(b_vector[b]) < int(b_list_new[0])):\n",
    "            b += 1\n",
    "            if(w/v[b_vector[b]] < 0):\n",
    "                continue\n",
    "            if(x_plus[b_vector[b]] == 1 and int(b_vector[b]) > int(b_list_new[0])):\n",
    "                b_list_new.append(b_vector[b])\n",
    "            if(len(b_list_new) > 2):\n",
    "                b_list_new.pop(0)\n",
    "                \n",
    "        if(len(b_list_new) == 1 and w/v[b_list_new[0]] > 1):\n",
    "            b_list_new[0] = 0\n",
    "            \n",
    "        x = np.zeros(C)\n",
    "        \n",
    "        if(len(b_list_new) == 1):\n",
    "            x[b_list_new[0]] = round(float(w/v[b_list_new[0]]), 5)\n",
    "        else:\n",
    "            x1, x2 = torch.zeros(2, len(w), C, dtype=torch.float32)\n",
    "            x1[torch.arange(len(w)), b_list_new[0]] = 1\n",
    "            x2[torch.arange(len(w)), b_list_new[1]] = 1\n",
    "            numerator = w - torch.matmul(x2, v)\n",
    "            denominator = torch.matmul((x1 - x2), v)\n",
    "            theta = numerator / denominator\n",
    "            x[b_list_new[0]] = round(float(theta), 5)\n",
    "            x[b_list_new[1]] = round(float(1 - theta), 5)\n",
    "            \n",
    "        objective_values = torch.matmul(torch.from_numpy(x).float(), xi) \n",
    "    \n",
    "    if(x is None): # Al caso di soluzione vuota faccio corrispondere un moltiplicatore vuoto \n",
    "        lambda_opt = None\n",
    "    elif(np.all(x == 0)): # Al caso di soluzione nulla faccio corrispondere un moltiplicatore nullo\n",
    "        lambda_opt = 0\n",
    "    elif(np.count_nonzero(np.abs(x) > 1e-6) == 2):\n",
    "        i = np.nonzero(np.abs(x) > 1e-6) # i[0] è la lista [indice1, indice2]\n",
    "        diff = i[0][1] - i[0][0]\n",
    "        passo = v[1] - v[0] # Nel caso semplice sarebbe 1/C\n",
    "        lambda_opt = round(float(-1 / (diff * passo) * (xi[i[0][1]] - xi[i[0][0]])), 5)\n",
    "    elif(np.count_nonzero(np.abs(x) > 1e-6) == 1):\n",
    "        i = np.nonzero(np.abs(x) > 1e-6)\n",
    "        lambda_opt = round(-float(xi[i[0][0]] / v[i[0][0]]), 5) # i[0][0] è l'indice\n",
    "    else:\n",
    "        print(\"ERROR: SOLUTION NOT ACCEPTABLE!\")\n",
    "\n",
    "    objective_values = xi @ x\n",
    "    return x, lambda_opt, objective_values, x_plus\n",
    "\n",
    "# Dimension of vectors xi, v, and x\n",
    "C = 29\n",
    "M = 1\n",
    "\n",
    "np.random.seed(41)  \n",
    "torch.manual_seed(41)\n",
    "\n",
    "conta_istanze_risolubili = 0\n",
    "conta_soluzioni_sotto_soglia = 0\n",
    "conta_moltiplicatori_errati = 0\n",
    "conta_soluzioni_errate = 0\n",
    "\n",
    "SUCCESS = 1\n",
    "\n",
    "for i in range(1000):\n",
    "    xi = torch.sort(torch.rand(C))[0]\n",
    "    w0 = -0.01\n",
    "    r = 1.32\n",
    "    min_w, max_w = w0 - r, w0 + r\n",
    "    v = torch.linspace(min_w, max_w - (max_w - min_w)/C, steps=C)\n",
    "    a = -2\n",
    "    b = 2.2\n",
    "    w = torch.rand(M) * (b - a) + a\n",
    "    \n",
    "    x_opt, lambda_opt, phi_opt, x_plus = knapsack_specialized_pruning_complete(xi, v, w, C)\n",
    "            \n",
    "    # cvxpy solution with inequality constraint (pruning)\n",
    "    x_pruning = cp.Variable(C)\n",
    "    equality_constraint_pruning = v @ x_pruning == w\n",
    "    constraints_pruning = [\n",
    "        equality_constraint_pruning,\n",
    "        cp.sum(x_pruning) <= 1,\n",
    "        x_pruning >= 0,\n",
    "        x_pruning <= 1\n",
    "    ]\n",
    "    objective_pruning = cp.Minimize(xi @ x_pruning)\n",
    "    prob_pruning = cp.Problem(objective_pruning, constraints_pruning)\n",
    "    prob_pruning.solve(solver=cp.ECOS)\n",
    "    \n",
    "    soglia = 0.0001\n",
    "    if(x_pruning.value is not None):\n",
    "        conta_istanze_risolubili += 1\n",
    "        if(np.max(x_opt) < soglia):\n",
    "            conta_soluzioni_sotto_soglia += 1\n",
    "    \n",
    "    if(x_pruning.value is not None):\n",
    "        if(not np.allclose(x_pruning.value, x_opt, rtol=1e-5, atol=1e-2)):\n",
    "            conta_soluzioni_errate += 1\n",
    "            SUCCESS = 0\n",
    "            print(f\"{i} ERRORE NELLE SOLUZIONI:\")\n",
    "        if(np.abs(equality_constraint_pruning.dual_value[0] - lambda_opt) > 5e-2):\n",
    "            conta_moltiplicatori_errati += 1\n",
    "            SUCCESS = 0\n",
    "            print(f\"{i} ERRORE NEI MOLTIPLICATORI:\")\n",
    "            print(x_pruning.value)\n",
    "    else: # da eliminare una volta verificato che i casi di soluzione non ammissibile sono gestiti correttamente\n",
    "        print(\"x_opt:\", x_opt)\n",
    "        print(\"x_pruning.value:\", x_pruning.value)\n",
    "        print(\"lambda_opt:\", lambda_opt)\n",
    "        print(\"equality_constraint_pruning.dual_value:\", equality_constraint_pruning.dual_value)\n",
    "        print(\"-\"*50)\n",
    "            \n",
    "if(SUCCESS == 1):\n",
    "    print(\"\\nTEST CONCLUSO CON SUCCESSO!\")\n",
    "    \n",
    "print(\"\\n\\nconta_istanze_risolubili:\", conta_istanze_risolubili)\n",
    "print(\"conta_soluzioni_sotto_soglia:\", conta_soluzioni_sotto_soglia)\n",
    "print(\"conta_soluzioni_errate:\", conta_soluzioni_errate)\n",
    "print(\"conta_moltiplicatori_errati:\", conta_moltiplicatori_errati)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909397ca",
   "metadata": {},
   "source": [
    "# TEST CON PARALLELIZZAZIONE (vedi notebook PruningVectorized.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a82b595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006700e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2b6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70b9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19c778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02247ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ba21b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1402c723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ba0770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca51168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e345e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a8dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e084a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d417b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44a633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed21e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9950684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800aed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38ce9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
