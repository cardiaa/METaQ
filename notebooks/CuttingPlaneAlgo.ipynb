{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7563311b",
   "metadata": {},
   "source": [
    "## Single small istance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1ce936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [1 2 3]\n",
      "v: [0.         0.33333333 0.66666667]\n",
      "w: 0.3333333333333333\n",
      "\n",
      "x_sol: [0. 1. 0.]\n",
      "lambda_opt: 3.0\n",
      "phi_opt: 2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "# Creates a NumPy vector of size C with all zeros except for a 1 at the given index\n",
    "def get_unit_vector(index, C):\n",
    "    x = np.zeros(C)\n",
    "    x[index] = 1.0\n",
    "    return x\n",
    "\n",
    "# Initializes x1 (x2) as a vector with all zeros except for a 1 at the position \n",
    "# corresponding to the index of the largest (smallest) value of v for which w >= v[b] (w < v[b]).\n",
    "def initialize_B(v, w, C):\n",
    "    # List of indices b that satisfy w >= v[b]\n",
    "    b1_candidates = [b for b in range(C) if w >= v[b]]\n",
    "    # List of indices b that satisfy w < v[b]\n",
    "    b2_candidates = [b for b in range(C) if w < v[b]]\n",
    "\n",
    "    # Case where w is smaller than the minimum of v.\n",
    "    # Take the minimum of v.\n",
    "    if not b1_candidates: \n",
    "        b1 = np.argmin(v)\n",
    "    # Otherwise, take the index of the largest value of v for which w >= v[b]\n",
    "    else:\n",
    "        b1 = b1_candidates[-1]\n",
    "\n",
    "    # Case where w is larger than the maximum of v.\n",
    "    # Take the maximum of v.\n",
    "    if not b2_candidates:\n",
    "        b2 = np.argmax(v)\n",
    "    # Otherwise, take the index of the smallest value of v for which w < v[b]\n",
    "    else:\n",
    "        b2 = b2_candidates[0]  # Smallest v_b > w\n",
    "\n",
    "    # Vectors consisting of a 1 only in the b1-th (or b2-th) position\n",
    "    x1 = get_unit_vector(b1, C)\n",
    "    x2 = get_unit_vector(b2, C)\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "# For a fixed w, returns the solution x of (14)-(17),\n",
    "# the optimal multiplier, and the optimal value of the objective function.\n",
    "def cutting_plane_algorithm(xi, v, w, C):\n",
    "    # Count the iterations of the algorithm\n",
    "    iteration = 0\n",
    "    # Prevent infinite loops\n",
    "    max_iterations = 100  \n",
    "    \n",
    "    # Initialize x1 (x2) as a vector that satisfies w >= v * x1 (w < v * x2) \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    B = [x1, x2]\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        if iteration > max_iterations:\n",
    "            print(\"Maximum iterations reached.\")\n",
    "            break\n",
    "\n",
    "        x1, x2 = B\n",
    "\n",
    "        # Compute the intersection point (lambda^+, phi^+) also called (lambda_plus, phi_plus)\n",
    "        numerator = (xi @ x2 - xi @ x1)\n",
    "        denominator = ((w - v @ x1) - (w - v @ x2))\n",
    "        if denominator == 0:\n",
    "            lambda_plus = 0\n",
    "        else:\n",
    "            lambda_plus = numerator / denominator\n",
    "        phi_plus = xi @ x1 + lambda_plus * (w - v @ x1)\n",
    "\n",
    "        # Compute x^+ (x_plus) as the vector that has a 1 at the position \n",
    "        # where xi - lambda_plus * v is minimal\n",
    "        reduced_cost = xi - lambda_plus * v\n",
    "        b_plus = np.argmin(reduced_cost)\n",
    "        x_plus = get_unit_vector(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = xi @ x_plus + lambda_plus * (w - v @ x_plus)\n",
    "\n",
    "        # TERMINATION CONDITIONS\n",
    "        # Case 1:\n",
    "        # |phi_lambda_plus - phi_plus| <= 1e-08 + 1e-05 * phi_plus (see default of isclose())\n",
    "        if np.isclose(phi_lambda_plus, phi_plus):\n",
    "            # Compute theta^* as the coefficient of the convex combination of x1 and x2 \n",
    "            # that, when multiplied by v, gives w\n",
    "            numerator_theta = (w - v @ x2)\n",
    "            denominator_theta = v @ (x1 - x2)\n",
    "            if denominator_theta == 0:\n",
    "                theta_star = 0.5  # Arbitrary value since x1 == x2\n",
    "            else:\n",
    "                theta_star = numerator_theta / denominator_theta\n",
    "            x = theta_star * x1 + (1 - theta_star) * x2\n",
    "            return x, lambda_plus, phi_plus\n",
    "        # Case 2: w = v * x^+\n",
    "        # x^+ is a primal solution since, in this case, we have minimized xi*x \n",
    "        # while satisfying all constraints\n",
    "        elif np.isclose(w, v @ x_plus):\n",
    "            x = x_plus\n",
    "            phi_plus = xi @ x  # The term lambda^+ * (w - v * x^+) becomes 0\n",
    "            return x, lambda_plus, phi_plus\n",
    "        \n",
    "        else:\n",
    "            # Case 3: x^+ behaves like x1\n",
    "            # Iterate the algorithm with x^+ instead of x1\n",
    "            if w > v @ x_plus:\n",
    "                B = [x_plus, x2]\n",
    "            # Case 4: x^+ behaves like x2\n",
    "            # Iterate the algorithm with x^+ instead of x2\n",
    "            else:\n",
    "                B = [x1, x_plus]\n",
    "                \n",
    "C = 3\n",
    "xi = np.array([1,2,3])\n",
    "v = np.linspace(0, 1, C, endpoint=False)\n",
    "w = 1/3\n",
    "\n",
    "x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "\n",
    "# Comparison of solutions\n",
    "print(f\"xi:\", xi)\n",
    "print(\"v:\", v)\n",
    "print(\"w:\", w)\n",
    "\n",
    "print(\"\\nx_sol:\", x_opt)\n",
    "print(\"lambda_opt:\", lambda_opt)\n",
    "print(\"phi_opt:\", phi_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a3567",
   "metadata": {},
   "source": [
    "## Comparison of the results of cvxpy and the cutting plane algorithm in terms of correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ddec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm is correct!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dimension of vectors xi, v, and x\n",
    "C = 256\n",
    "                \n",
    "np.random.seed(42)  \n",
    "CORRECT = True\n",
    "\n",
    "for i in range(1000):\n",
    "    xi = torch.sort(torch.rand(C, device=device))[0]  \n",
    "    v = torch.linspace(0, 1 - (1 / C), C, device=device)  \n",
    "    w = v[torch.randint(0, C, (1,), device=device)]  \n",
    "    #w = torch.rand(M, device=device)\n",
    "    \n",
    "    x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "    \n",
    "    # Comparison with cvxpy\n",
    "    x = cp.Variable(C)\n",
    "    equality_constraint = v @ x == w\n",
    "    constraints = [\n",
    "        equality_constraint,\n",
    "        cp.sum(x) == 1,\n",
    "        x >= 0,\n",
    "        x <= 1\n",
    "    ]\n",
    "    objective = cp.Minimize(xi @ x)\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "    \n",
    "    # Comparison of solutions\n",
    "    if((abs(torch.norm(x_opt - x.value)) > 1e-3) and (phi_opt + 1e-4 < prob.value)):\n",
    "        print(\"ERROR! Algorithms provide different solutions!\")\n",
    "        CORRECT = False\n",
    "\n",
    "if(CORRECT == True):\n",
    "    print(\"The algorithm is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe9da1",
   "metadata": {},
   "source": [
    "## Counts the number of iteration to convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93067b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Dimension of vectors xi, v, and x\n",
    "C = 256\n",
    "\n",
    "# For a fixed w, returns the solution x of (14)-(17),\n",
    "# the optimal multiplier, and the optimal value of the objective function.\n",
    "def cutting_plane_algorithm_histo(xi, v, w, C):\n",
    "    # Count the iterations of the algorithm\n",
    "    iteration = 0\n",
    "    # Prevent infinite loops\n",
    "    max_iterations = 100  \n",
    "    \n",
    "    # Initialize x1 (x2) as a vector that satisfies w >= v * x1 (w < v * x2) \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    B = [x1, x2]\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        if iteration > max_iterations:\n",
    "            print(\"Maximum iterations reached.\")\n",
    "            break\n",
    "\n",
    "        x1, x2 = B\n",
    "\n",
    "        # Compute the intersection point (lambda^+, phi^+) also called (lambda_plus, phi_plus)\n",
    "        numerator = (xi @ x2 - xi @ x1)\n",
    "        denominator = ((w - v @ x1) - (w - v @ x2))\n",
    "        if denominator == 0:\n",
    "            lambda_plus = 0\n",
    "        else:\n",
    "            lambda_plus = numerator / denominator\n",
    "        phi_plus = xi @ x1 + lambda_plus * (w - v @ x1)\n",
    "\n",
    "        # Compute x^+ (x_plus) as the vector that has a 1 at the position \n",
    "        # where xi - lambda_plus * v is minimal\n",
    "        reduced_cost = xi - lambda_plus * v\n",
    "        b_plus = np.argmin(reduced_cost)\n",
    "        x_plus = get_unit_vector(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = xi @ x_plus + lambda_plus * (w - v @ x_plus)\n",
    "\n",
    "        # TERMINATION CONDITIONS\n",
    "        # Case 1:\n",
    "        # |phi_lambda_plus - phi_plus| <= 1e-08 + 1e-05 * phi_plus (see default of isclose())\n",
    "        if np.isclose(phi_lambda_plus, phi_plus):\n",
    "            # Compute theta^* as the coefficient of the convex combination of x1 and x2 \n",
    "            # that, when multiplied by v, gives w\n",
    "            numerator_theta = (w - v @ x2)\n",
    "            denominator_theta = v @ (x1 - x2)\n",
    "            if denominator_theta == 0:\n",
    "                theta_star = 0.5  # Arbitrary value since x1 == x2\n",
    "            else:\n",
    "                theta_star = numerator_theta / denominator_theta\n",
    "            x = theta_star * x1 + (1 - theta_star) * x2\n",
    "            return iteration, x, lambda_plus, phi_plus\n",
    "        # Case 2: w = v * x^+\n",
    "        # x^+ is a primal solution since, in this case, we have minimized xi*x \n",
    "        # while satisfying all constraints\n",
    "        elif np.isclose(w, v @ x_plus):\n",
    "            x = x_plus\n",
    "            phi_plus = xi @ x  # The term lambda^+ * (w - v * x^+) becomes 0\n",
    "            return iteration, x, lambda_plus, phi_plus\n",
    "        \n",
    "        else:\n",
    "            # Case 3: x^+ behaves like x1\n",
    "            # Iterate the algorithm with x^+ instead of x1\n",
    "            if w > v @ x_plus:\n",
    "                B = [x_plus, x2]\n",
    "            # Case 4: x^+ behaves like x2\n",
    "            # Iterate the algorithm with x^+ instead of x2\n",
    "            else:\n",
    "                B = [x1, x_plus]\n",
    "\n",
    "iterations = []\n",
    "for i in range(10000):\n",
    "    np.random.seed()  # For reproducibility with different seeds\n",
    "    xi = np.sort(np.random.random(C))\n",
    "    v = np.linspace(0, 1, C, endpoint=False)\n",
    "    w = np.random.choice(v)\n",
    "    \n",
    "    iteration, x_opt, lambda_opt, phi_opt = cutting_plane_algorithm_histo(xi, v, w, C)\n",
    "    iterations.append(iteration)\n",
    "\n",
    "# Count occurrences\n",
    "occurrences = Counter(iterations)\n",
    "\n",
    "# Data for the histogram\n",
    "labels = list(occurrences.keys())  # Labels (unique values)\n",
    "values = list(occurrences.values())  # Frequencies\n",
    "\n",
    "# Create the histogram\n",
    "plt.bar(labels, values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of iterations to converge')\n",
    "plt.ylabel('Occurrences')\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f220876",
   "metadata": {},
   "source": [
    "## For a fixed seed, here there is the simulation of 10 thousand \n",
    "## istances with cutting plane algorithm and with cvxpy to compare execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794c9a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cutting Plane Algorithm\n",
      "Time taken by the Cutting Plane algorithm: 0.20 seconds\n",
      "----------------------------------------\n",
      "Start cvxpy solver\n",
      "Time taken by the cvxpy solver: 3.19 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize data\n",
    "C = 256  # Size of vectors xi, v, and x\n",
    "N = 1000  # Number of iterations for timing comparison\n",
    "\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "# Generate random xi vector and v values\n",
    "xi = np.sort(np.random.random(C))  # Sorted random values for xi\n",
    "v = np.linspace(0, 1, C, endpoint=False)  # Evenly spaced values between 0 and 1\n",
    "w = np.random.choice(v)  # Randomly select a value from v as w\n",
    "\n",
    "# Measure execution time of the Cutting Plane Algorithm\n",
    "print(\"Start Cutting Plane Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the Cutting Plane algorithm: {training_time:.2f} seconds')\n",
    "\n",
    "print(\"-\" * 40)  # Separator for readability\n",
    "\n",
    "# Measure execution time of the cvxpy solver\n",
    "print(\"Start cvxpy solver\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    # Define optimization variable\n",
    "    x = cp.Variable(C)\n",
    "    \n",
    "    # Define constraints\n",
    "    equality_constraint = v @ x == w  # Enforce v * x = w\n",
    "    constraints = [\n",
    "        equality_constraint,\n",
    "        cp.sum(x) == 1,  # Ensure x sums to 1\n",
    "        x >= 0,  # Ensure non-negativity\n",
    "        x <= 1   # Ensure x values do not exceed 1\n",
    "    ]\n",
    "    \n",
    "    # Define objective function (minimize xi * x)\n",
    "    objective = cp.Minimize(xi @ x)\n",
    "    \n",
    "    # Solve the optimization problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the cvxpy solver: {training_time:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bb844",
   "metadata": {},
   "source": [
    "## Comparison between cvxpy and vectorized cutting plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e8344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken by Vectorized Cutting Plane Algorithm: 0.007 seconds\n",
      "Time taken by cvxpy solver: 16.647 seconds\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "C = 5  # Size of vectors xi, v, and x\n",
    "N = 10000  # Number of problems in the batch\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(10)\n",
    "xi_np = np.sort(np.random.random(C))  # Sorted random values for xi\n",
    "v_np = np.array([0.0, 0.2, 0.4, 0.6, 0.8])  # Fixed vector v\n",
    "w_np = np.random.choice(v_np, N)  # Randomly select N values from v as w\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "xi = torch.tensor(xi_np, dtype=torch.float32, device=device)\n",
    "v = torch.tensor(v_np, dtype=torch.float32, device=device)\n",
    "w = torch.tensor(w_np, dtype=torch.float32, device=device)\n",
    "\n",
    "# Function to generate unit vectors\n",
    "def get_unit_vectors(indices, size):\n",
    "    \"\"\" Creates unit vectors based on given indices. \"\"\"\n",
    "    x = torch.zeros(indices.size(0), size, device=device)\n",
    "    x[torch.arange(indices.size(0)), indices] = 1.0\n",
    "    return x\n",
    "\n",
    "# Function to initialize B with two vectors satisfying w >= v * x1 and w < v * x2\n",
    "def initialize_B(v, w, C):\n",
    "    \"\"\" Initializes x1 and x2 for the cutting plane algorithm. \"\"\"\n",
    "    v_expanded = v.unsqueeze(0).repeat(w.size(0), 1)  # Expand v to match w's batch size\n",
    "    w_expanded = w.unsqueeze(1)  # Expand w for broadcasting\n",
    "    diff = v_expanded - w_expanded  # Compute the difference\n",
    "\n",
    "    # Find indices where w is between v values\n",
    "    b1 = torch.sum(diff <= 0, dim=1) - 1\n",
    "    b2 = b1 + 1\n",
    "\n",
    "    # Clamp values to stay within valid index range\n",
    "    b1 = torch.clamp(b1, 0, C - 1)\n",
    "    b2 = torch.clamp(b2, 0, C - 1)\n",
    "\n",
    "    # Create unit vectors\n",
    "    x1 = get_unit_vectors(b1, C)\n",
    "    x2 = get_unit_vectors(b2, C)\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "# Vectorized cutting plane algorithm implementation\n",
    "def cutting_plane_algorithm_vectorized(xi, v, w, x1, x2):\n",
    "    \"\"\" Cutting plane algorithm optimized for batch processing with PyTorch. \"\"\"\n",
    "    max_iterations = 8  # Limit the number of iterations\n",
    "    iteration = 0\n",
    "    x_plus = x1.clone()  # Initialize x_plus\n",
    "    lambda_plus = torch.zeros(N, device=device)  # Initialize lambda_plus\n",
    "    phi_plus = torch.zeros(N, device=device)  # Initialize phi_plus\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "\n",
    "        # Compute necessary inner products\n",
    "        xi_x1 = torch.sum(xi * x1, dim=1)\n",
    "        xi_x2 = torch.sum(xi * x2, dim=1)\n",
    "        v_x1 = torch.sum(v * x1, dim=1)\n",
    "        v_x2 = torch.sum(v * x2, dim=1)\n",
    "\n",
    "        # Compute lambda^+ and phi^+\n",
    "        numerator = xi_x2 - xi_x1\n",
    "        denominator = (w - v_x1) - (w - v_x2) + 1e-8  # Avoid division by zero\n",
    "        lambda_plus = numerator / denominator\n",
    "        phi_plus = xi_x1 + lambda_plus * (w - v_x1)\n",
    "\n",
    "        # Compute x^+ as the unit vector minimizing xi - lambda^+ * v\n",
    "        reduced_cost = xi.unsqueeze(0) - lambda_plus.unsqueeze(1) * v.unsqueeze(0)\n",
    "        b_plus = torch.argmin(reduced_cost, dim=1)\n",
    "        x_plus = get_unit_vectors(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = torch.sum(xi * x_plus, dim=1) + lambda_plus * (w - torch.sum(v * x_plus, dim=1))\n",
    "\n",
    "        # Check termination conditions\n",
    "        termination_condition = torch.isclose(phi_lambda_plus, phi_plus, atol=1e-6)\n",
    "        w_equals_vx_plus = torch.isclose(w, torch.sum(v * x_plus, dim=1), atol=1e-6)\n",
    "\n",
    "        # If all samples satisfy termination conditions, return solution\n",
    "        if torch.all(termination_condition | w_equals_vx_plus):\n",
    "            numerator_theta = w - torch.sum(v * x2, dim=1)\n",
    "            denominator_theta = torch.sum(v * (x1 - x2), dim=1) + 1e-8  # Avoid division by zero\n",
    "            theta_star = numerator_theta / denominator_theta\n",
    "            theta_star = torch.clamp(theta_star, 0, 1)  # Ensure valid range\n",
    "\n",
    "            # Compute final solution as a convex combination of x1 and x2\n",
    "            x = theta_star.unsqueeze(1) * x1 + (1 - theta_star).unsqueeze(1) * x2\n",
    "            return x, lambda_plus, phi_plus\n",
    "\n",
    "        # Update B for the next iteration\n",
    "        condition = w > torch.sum(v * x_plus, dim=1)\n",
    "        x1 = torch.where(condition.unsqueeze(1), x_plus, x1)\n",
    "        x2 = torch.where(~condition.unsqueeze(1), x_plus, x2)\n",
    "\n",
    "    return x_plus, lambda_plus, phi_plus  # Return last computed values\n",
    "\n",
    "# Measure execution time for the vectorized Cutting Plane Algorithm\n",
    "x1, x2 = initialize_B(v, w, C)\n",
    "start_time = time.time()\n",
    "x_opt, lambda_opt, phi_opt = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "cutting_plane_time = time.time() - start_time\n",
    "print(f\"\\nTime taken by Vectorized Cutting Plane Algorithm: {cutting_plane_time:.3f} seconds\")\n",
    "\n",
    "# Measure execution time for cvxpy solver\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x = cp.Variable(C)\n",
    "\n",
    "    # Define constraints\n",
    "    constraints = [\n",
    "        v_np @ x == w_np[i],  # Equality constraint\n",
    "        cp.sum(x) == 1,  # Ensure sum of x is 1\n",
    "        x >= 0,  # Ensure non-negativity\n",
    "        x <= 1   # Ensure x values do not exceed 1\n",
    "    ]\n",
    "\n",
    "    # Define objective function (minimize xi * x)\n",
    "    objective = cp.Minimize(xi_np @ x)\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "cvxpy_time = time.time() - start_time\n",
    "print(f\"Time taken by cvxpy solver: {cvxpy_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a06739",
   "metadata": {},
   "source": [
    "## KNAPSACK SPECIALIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd8c0d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_specialized(xi, v, w, C):\n",
    "    \"\"\"\n",
    "    Solves a specialized knapsack problem using a specialized method in a vectorized way\n",
    "\n",
    "    Args:\n",
    "        xi (torch.Tensor): xi variables.\n",
    "        v (torch.Tensor): Quantization vector.\n",
    "        w (torch.Tensor): Weight vector.\n",
    "        C (int): Number of buckets of quantization.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Optimal allocation (x_opt), optimal multipliers (lambda_opt), and objective values.\n",
    "    \"\"\"\n",
    "    \n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "\n",
    "    # Determine optimal allocation based on w\n",
    "    w_idx = torch.searchsorted(v, w) \n",
    "    indices_breakpoints = torch.nonzero(x_plus == 1).squeeze()\n",
    "\n",
    "    if(w > v[-1]):\n",
    "        idx_right = indices_breakpoints[-1]\n",
    "        idx_left = idx_right\n",
    "    elif(w < v[0]):\n",
    "        idx_right = indices_breakpoints[0]\n",
    "        idx_left = idx_right    \n",
    "    else:\n",
    "        idx_right = indices_breakpoints[torch.searchsorted(indices_breakpoints, w_idx)]\n",
    "        idx_left = indices_breakpoints[torch.searchsorted(indices_breakpoints, w_idx) - 1]\n",
    "        \n",
    "    # Compute convex combination for optimal solution\n",
    "    x1, x2 = torch.zeros(2, len(w), C, dtype=torch.float32)\n",
    "\n",
    "    x1[torch.arange(len(w)), idx_left] = 1\n",
    "    x2[torch.arange(len(w)), idx_right] = 1\n",
    "\n",
    "    numerator = w - torch.matmul(x2, v)\n",
    "    denominator = torch.matmul((x1 - x2), v)\n",
    "    theta = numerator / denominator\n",
    "\n",
    "    mask_equal = (x1 == x2)\n",
    "    theta_expanded = theta.unsqueeze(1)\n",
    "    x_opt = torch.where(mask_equal, x1, x1 * theta_expanded + x2 * (1 - theta_expanded))\n",
    "\n",
    "    # Compute optimal multipliers\n",
    "    denominator = (v[idx_right] - v[idx_left])\n",
    "    denominator_zero_mask = denominator == 0\n",
    "\n",
    "    lambda_opt_nonzero = (xi[idx_right] - xi[idx_left]) / denominator\n",
    "    lambda_opt_zero_full = xi / v\n",
    "    lambda_opt_zero_full[0] = 0\n",
    "    lambda_opt_zero = lambda_opt_zero_full[idx_left]\n",
    "\n",
    "    lambda_opt = torch.where(denominator_zero_mask, lambda_opt_zero, lambda_opt_nonzero)\n",
    "\n",
    "    # Compute objective function values\n",
    "    objective_values = torch.matmul(x_opt, xi)\n",
    "\n",
    "    return x_opt, lambda_opt, objective_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0dcc0",
   "metadata": {},
   "source": [
    "## Verify correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18022b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm is correct!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  \n",
    "C = 256\n",
    "M = 1\n",
    "CORRECT = True\n",
    "\n",
    "for i in range(1000):\n",
    "    xi = torch.sort(torch.rand(C, device=device))[0]  \n",
    "    v = torch.linspace(0, 1 - (1 / C), C, device=device)  \n",
    "    #w = v[torch.randint(0, C, (1,), device=device)]  \n",
    "    w = torch.rand(M, device=device)\n",
    "\n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    x_opt1, lambda_opt1, phi_opt1 = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "    \n",
    "    x_opt2, lambda_opt2, phi_opt2 = knapsack_specialized(xi, v, w, C)\n",
    "    # Comparison of solutions\n",
    "    \n",
    "    if((abs(torch.norm(x_opt1 - x_opt2)) > 1e-3) and (phi_opt1 + 1e-4 < phi_opt2)):\n",
    "        print(\"ERROR! Algorithms provide different solutions!\")\n",
    "        CORRECT = False\n",
    "\n",
    "if(CORRECT == True):\n",
    "    print(\"The algorithm is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dbdb8e",
   "metadata": {},
   "source": [
    "## Specialized Algorithm Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f67295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_specialized_vectorized(xi, v, w, C):\n",
    "    \"\"\"\n",
    "    Solves a specialized knapsack problem using a specialized method in a vectorized way\n",
    "\n",
    "    Args:\n",
    "        xi (torch.Tensor): xi variables.\n",
    "        v (torch.Tensor): Quantization vector.\n",
    "        w (torch.Tensor): Weight vector.\n",
    "        C (int): Number of buckets of quantization.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Optimal allocation (x_opt), optimal multipliers (lambda_opt), and objective values.\n",
    "    \"\"\"\n",
    "    \n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "\n",
    "    # Determine optimal allocation based on w\n",
    "    w_idx = torch.searchsorted(v, w) \n",
    "    indices_breakpoints = torch.nonzero(x_plus == 1).squeeze()\n",
    "\n",
    "    # Creation of masks for extreme cases\n",
    "    mask_right = w > v[-1]\n",
    "    mask_left = w < v[0]\n",
    "\n",
    "    # Find indices using searchsorted\n",
    "    search_idx = torch.searchsorted(indices_breakpoints, w_idx)\n",
    "\n",
    "    # Ensure that the indices are valid\n",
    "    search_idx = torch.clamp(search_idx, 1, len(indices_breakpoints) - 1)\n",
    "\n",
    "    # Initialize idx_right and idx_left with the result of the search\n",
    "    idx_right = indices_breakpoints[search_idx]\n",
    "    idx_left = indices_breakpoints[search_idx - 1]\n",
    "\n",
    "    # Correct the indices for extreme cases\n",
    "    idx_right = torch.where(mask_right, indices_breakpoints[-1], idx_right)\n",
    "    idx_left = torch.where(mask_right, indices_breakpoints[-1], idx_left)\n",
    "\n",
    "    # Correct the indices for the case when w < v[0]\n",
    "    idx_right = torch.where(mask_left, indices_breakpoints[0], idx_right)\n",
    "    idx_left = torch.where(mask_left, indices_breakpoints[0], idx_left)\n",
    "\n",
    "    # Compute convex combination for optimal solution\n",
    "    x1, x2 = torch.zeros(2, len(w), C, dtype=torch.float32)\n",
    "\n",
    "    x1[torch.arange(len(w)), idx_left] = 1\n",
    "    x2[torch.arange(len(w)), idx_right] = 1\n",
    "\n",
    "    numerator = w - torch.matmul(x2, v)\n",
    "    denominator = torch.matmul((x1 - x2), v)\n",
    "    theta = numerator / denominator\n",
    "\n",
    "    mask_equal = (x1 == x2)\n",
    "    theta_expanded = theta.unsqueeze(1)\n",
    "    x_opt = torch.where(mask_equal, x1, x1 * theta_expanded + x2 * (1 - theta_expanded))\n",
    "\n",
    "    # Compute optimal multipliers\n",
    "    denominator = (v[idx_right] - v[idx_left])\n",
    "    denominator_zero_mask = denominator == 0\n",
    "\n",
    "    lambda_opt_nonzero = (xi[idx_right] - xi[idx_left]) / denominator\n",
    "    lambda_opt_zero_full = xi / v\n",
    "    lambda_opt_zero_full[0] = 0\n",
    "    lambda_opt_zero = lambda_opt_zero_full[idx_left]\n",
    "\n",
    "    lambda_opt = torch.where(denominator_zero_mask, lambda_opt_zero, lambda_opt_nonzero)\n",
    "\n",
    "    # Compute objective function values\n",
    "    objective_values = torch.matmul(x_opt, xi)\n",
    "\n",
    "    return x_opt, lambda_opt, objective_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61015d",
   "metadata": {},
   "source": [
    "## Verify correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "109e7da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm is correct!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  \n",
    "C = 256\n",
    "M = 100\n",
    "CORRECT = True\n",
    "\n",
    "for i in range(1000):\n",
    "    xi = torch.sort(torch.rand(C, device=device))[0]  \n",
    "    v = torch.linspace(0, 1 - (1 / C), C, device=device)  \n",
    "    #w = v[torch.randint(0, C, (1,), device=device)]  \n",
    "    w = torch.rand(M, device=device)\n",
    "    \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    x_opt1, lambda_opt1, phi_opt1 = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "    \n",
    "    x_opt2, lambda_opt2, phi_opt2 = knapsack_specialized_vectorized(xi, v, w, C)\n",
    "    \n",
    "    # Comparison of solutions\n",
    "    if(torch.any(torch.abs(x_opt1 - x_opt2) > 1e-3) and torch.any(phi_opt1 + 1e-4 < phi_opt2)):\n",
    "        print(\"ERROR! Algorithms provide different solutions!\")\n",
    "        CORRECT = False\n",
    "\n",
    "if(CORRECT == True):\n",
    "    print(\"The algorithm is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8bac7c",
   "metadata": {},
   "source": [
    "## Compare execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f42027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cutting Plane Algorithm\n",
      "Time taken by the Cutting Plane algorithm: 215.98 seconds\n",
      "----------------------------------------\n",
      "Start Specialized Algorithm\n",
      "Time taken by the specialized algorithm: 18.66 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize data\n",
    "C = 256  \n",
    "N = 1000  # Number of iterations for timing comparison\n",
    "M = 44000 # Parallelization\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "v = torch.linspace(0, 1 - (1 / C), C, device=device)  \n",
    "\n",
    "# Measure execution time of the Cutting Plane Algorithm\n",
    "print(\"Start Cutting Plane Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    xi = torch.sort(torch.rand(C, device=device))[0]  \n",
    "    w = torch.rand(M, device=device)\n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    x_opt1, lambda_opt1, phi_opt1 = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "training_time1 = time.time() - start_time\n",
    "print(f'Time taken by the Cutting Plane algorithm: {training_time1:.2f} seconds')\n",
    "\n",
    "print(\"-\" * 40)  # Separator for readability\n",
    "\n",
    "# Measure execution time of the specialized algorithm\n",
    "print(\"Start Specialized Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x_opt2, lambda_opt2, phi_opt2 = knapsack_specialized_vectorized(xi, v, w, C)\n",
    "training_time2 = time.time() - start_time\n",
    "print(f'Time taken by the specialized algorithm: {training_time2:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "768c669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specialized algorithm results in 11.58x better performance\n"
     ]
    }
   ],
   "source": [
    "print(f\"The specialized algorithm results in {training_time1 / training_time2:.2f}x better performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
