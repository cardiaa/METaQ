{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7563311b",
   "metadata": {},
   "source": [
    "## Single small istance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1ce936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [1 2 3]\n",
      "v: [0.         0.33333333 0.66666667]\n",
      "w: 0.3333333333333333\n",
      "\n",
      "x_sol: [0. 1. 0.]\n",
      "lambda_opt: 3.0\n",
      "phi_opt: 2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "# Creates a NumPy vector of size C with all zeros except for a 1 at the given index\n",
    "def get_unit_vector(index, C):\n",
    "    x = np.zeros(C)\n",
    "    x[index] = 1.0\n",
    "    return x\n",
    "\n",
    "# Initializes x1 (x2) as a vector with all zeros except for a 1 at the position \n",
    "# corresponding to the index of the largest (smallest) value of v for which w >= v[b] (w < v[b]).\n",
    "def initialize_B(v, w, C):\n",
    "    # List of indices b that satisfy w >= v[b]\n",
    "    b1_candidates = [b for b in range(C) if w >= v[b]]\n",
    "    # List of indices b that satisfy w < v[b]\n",
    "    b2_candidates = [b for b in range(C) if w < v[b]]\n",
    "\n",
    "    # Case where w is smaller than the minimum of v.\n",
    "    # Take the minimum of v.\n",
    "    if not b1_candidates: \n",
    "        b1 = np.argmin(v)\n",
    "    # Otherwise, take the index of the largest value of v for which w >= v[b]\n",
    "    else:\n",
    "        b1 = b1_candidates[-1]\n",
    "\n",
    "    # Case where w is larger than the maximum of v.\n",
    "    # Take the maximum of v.\n",
    "    if not b2_candidates:\n",
    "        b2 = np.argmax(v)\n",
    "    # Otherwise, take the index of the smallest value of v for which w < v[b]\n",
    "    else:\n",
    "        b2 = b2_candidates[0]  # Smallest v_b > w\n",
    "\n",
    "    # Vectors consisting of a 1 only in the b1-th (or b2-th) position\n",
    "    x1 = get_unit_vector(b1, C)\n",
    "    x2 = get_unit_vector(b2, C)\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "# For a fixed w, returns the solution x of (14)-(17),\n",
    "# the optimal multiplier, and the optimal value of the objective function.\n",
    "def cutting_plane_algorithm(xi, v, w, C):\n",
    "    # Count the iterations of the algorithm\n",
    "    iteration = 0\n",
    "    # Prevent infinite loops\n",
    "    max_iterations = 100  \n",
    "    \n",
    "    # Initialize x1 (x2) as a vector that satisfies w >= v * x1 (w < v * x2) \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    B = [x1, x2]\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        if iteration > max_iterations:\n",
    "            print(\"Maximum iterations reached.\")\n",
    "            break\n",
    "\n",
    "        x1, x2 = B\n",
    "\n",
    "        # Compute the intersection point (lambda^+, phi^+) also called (lambda_plus, phi_plus)\n",
    "        numerator = (xi @ x2 - xi @ x1)\n",
    "        denominator = ((w - v @ x1) - (w - v @ x2))\n",
    "        if denominator == 0:\n",
    "            lambda_plus = 0\n",
    "        else:\n",
    "            lambda_plus = numerator / denominator\n",
    "        phi_plus = xi @ x1 + lambda_plus * (w - v @ x1)\n",
    "\n",
    "        # Compute x^+ (x_plus) as the vector that has a 1 at the position \n",
    "        # where xi - lambda_plus * v is minimal\n",
    "        reduced_cost = xi - lambda_plus * v\n",
    "        b_plus = np.argmin(reduced_cost)\n",
    "        x_plus = get_unit_vector(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = xi @ x_plus + lambda_plus * (w - v @ x_plus)\n",
    "\n",
    "        # TERMINATION CONDITIONS\n",
    "        # Case 1:\n",
    "        # |phi_lambda_plus - phi_plus| <= 1e-08 + 1e-05 * phi_plus (see default of isclose())\n",
    "        if np.isclose(phi_lambda_plus, phi_plus):\n",
    "            # Compute theta^* as the coefficient of the convex combination of x1 and x2 \n",
    "            # that, when multiplied by v, gives w\n",
    "            numerator_theta = (w - v @ x2)\n",
    "            denominator_theta = v @ (x1 - x2)\n",
    "            if denominator_theta == 0:\n",
    "                theta_star = 0.5  # Arbitrary value since x1 == x2\n",
    "            else:\n",
    "                theta_star = numerator_theta / denominator_theta\n",
    "            x = theta_star * x1 + (1 - theta_star) * x2\n",
    "            return x, lambda_plus, phi_plus\n",
    "        # Case 2: w = v * x^+\n",
    "        # x^+ is a primal solution since, in this case, we have minimized xi*x \n",
    "        # while satisfying all constraints\n",
    "        elif np.isclose(w, v @ x_plus):\n",
    "            x = x_plus\n",
    "            phi_plus = xi @ x  # The term lambda^+ * (w - v * x^+) becomes 0\n",
    "            return x, lambda_plus, phi_plus\n",
    "        \n",
    "        else:\n",
    "            # Case 3: x^+ behaves like x1\n",
    "            # Iterate the algorithm with x^+ instead of x1\n",
    "            if w > v @ x_plus:\n",
    "                B = [x_plus, x2]\n",
    "            # Case 4: x^+ behaves like x2\n",
    "            # Iterate the algorithm with x^+ instead of x2\n",
    "            else:\n",
    "                B = [x1, x_plus]\n",
    "                \n",
    "C = 3\n",
    "xi = np.array([1,2,3])\n",
    "v = np.linspace(0, 1, C, endpoint=False)\n",
    "w = 1/3\n",
    "\n",
    "x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "\n",
    "# Comparison of solutions\n",
    "print(f\"xi:\", xi)\n",
    "print(\"v:\", v)\n",
    "print(\"w:\", w)\n",
    "\n",
    "print(\"\\nx_sol:\", x_opt)\n",
    "print(\"lambda_opt:\", lambda_opt)\n",
    "print(\"phi_opt:\", phi_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a3567",
   "metadata": {},
   "source": [
    "## Comparison of the results of cvxpy and the cutting plane algorithm in terms of correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ddec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0\n",
      "Difference in objective values: 1.1973563251999053e-09\n",
      "Difference in x: 1.030955100270796e-06\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 1\n",
      "Difference in objective values: 6.150421838491127e-11\n",
      "Difference in x: 8.065169592554692e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 2\n",
      "Difference in objective values: 1.9672916629076553e-09\n",
      "Difference in x: 1.1838869384236914e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 3\n",
      "Difference in objective values: 3.264444270456579e-11\n",
      "Difference in x: 6.600135777258744e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 4\n",
      "Difference in objective values: 1.812779926169128e-10\n",
      "Difference in x: 8.532771178929163e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 5\n",
      "Difference in objective values: 1.8395349132838135e-10\n",
      "Difference in x: 1.0499098136354973e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 6\n",
      "Difference in objective values: 1.721746634153476e-09\n",
      "Difference in x: 1.4561615169800928e-06\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 7\n",
      "Difference in objective values: 8.365874659688188e-11\n",
      "Difference in x: 9.507084449186415e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 8\n",
      "Difference in objective values: 1.6498263866182583e-09\n",
      "Difference in x: 2.0105486011552192e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 9\n",
      "Difference in objective values: 1.0609002565331593e-10\n",
      "Difference in x: 4.974098847671697e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 10\n",
      "Difference in objective values: 3.8621317255405074e-10\n",
      "Difference in x: 2.660986713835668e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 11\n",
      "Difference in objective values: 1.6252933443539064e-09\n",
      "Difference in x: 6.721214424832257e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 12\n",
      "Difference in objective values: 2.164629475664981e-09\n",
      "Difference in x: 3.3570360540200255e-06\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 13\n",
      "Difference in objective values: 1.0664857885700485e-10\n",
      "Difference in x: 7.187101631683347e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 14\n",
      "Difference in objective values: 1.3382140881534887e-09\n",
      "Difference in x: 7.115687896162939e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 15\n",
      "Difference in objective values: 2.364543005839437e-10\n",
      "Difference in x: 1.971318201643916e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 16\n",
      "Difference in objective values: 8.492817560323829e-11\n",
      "Difference in x: 6.1371750295304514e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 17\n",
      "Difference in objective values: 4.006267539935493e-11\n",
      "Difference in x: 1.8537540454564828e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 18\n",
      "Difference in objective values: 4.4017123279616044e-11\n",
      "Difference in x: 1.0407722344201146e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 19\n",
      "Difference in objective values: 2.371799978639899e-10\n",
      "Difference in x: 2.302380988006146e-08\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Dimension of vectors xi, v, and x\n",
    "C = 256\n",
    "                \n",
    "np.random.seed(42)  \n",
    "for i in range(20):\n",
    "    xi = np.sort(np.random.random(C))\n",
    "    v = np.linspace(0, 1, C, endpoint=False)\n",
    "    w = np.random.choice(v)\n",
    "    \n",
    "    x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "    \n",
    "    # Comparison with cvxpy\n",
    "    x = cp.Variable(C)\n",
    "    equality_constraint = v @ x == w\n",
    "    constraints = [\n",
    "        equality_constraint,\n",
    "        cp.sum(x) == 1,\n",
    "        x >= 0,\n",
    "        x <= 1\n",
    "    ]\n",
    "    objective = cp.Minimize(xi @ x)\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "    \n",
    "    print(f\"\\nIteration: {i}\")\n",
    "\n",
    "    # Comparison of solutions\n",
    "    print(f\"Difference in objective values: {abs(phi_opt - prob.value)}\")\n",
    "    print(f\"Difference in x: {np.linalg.norm(x_opt - x.value)}\")\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe9da1",
   "metadata": {},
   "source": [
    "## Counts the number of iteration to convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93067b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Dimension of vectors xi, v, and x\n",
    "C = 256\n",
    "\n",
    "# For a fixed w, returns the solution x of (14)-(17),\n",
    "# the optimal multiplier, and the optimal value of the objective function.\n",
    "def cutting_plane_algorithm_histo(xi, v, w, C):\n",
    "    # Count the iterations of the algorithm\n",
    "    iteration = 0\n",
    "    # Prevent infinite loops\n",
    "    max_iterations = 100  \n",
    "    \n",
    "    # Initialize x1 (x2) as a vector that satisfies w >= v * x1 (w < v * x2) \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    B = [x1, x2]\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        if iteration > max_iterations:\n",
    "            print(\"Maximum iterations reached.\")\n",
    "            break\n",
    "\n",
    "        x1, x2 = B\n",
    "\n",
    "        # Compute the intersection point (lambda^+, phi^+) also called (lambda_plus, phi_plus)\n",
    "        numerator = (xi @ x2 - xi @ x1)\n",
    "        denominator = ((w - v @ x1) - (w - v @ x2))\n",
    "        if denominator == 0:\n",
    "            lambda_plus = 0\n",
    "        else:\n",
    "            lambda_plus = numerator / denominator\n",
    "        phi_plus = xi @ x1 + lambda_plus * (w - v @ x1)\n",
    "\n",
    "        # Compute x^+ (x_plus) as the vector that has a 1 at the position \n",
    "        # where xi - lambda_plus * v is minimal\n",
    "        reduced_cost = xi - lambda_plus * v\n",
    "        b_plus = np.argmin(reduced_cost)\n",
    "        x_plus = get_unit_vector(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = xi @ x_plus + lambda_plus * (w - v @ x_plus)\n",
    "\n",
    "        # TERMINATION CONDITIONS\n",
    "        # Case 1:\n",
    "        # |phi_lambda_plus - phi_plus| <= 1e-08 + 1e-05 * phi_plus (see default of isclose())\n",
    "        if np.isclose(phi_lambda_plus, phi_plus):\n",
    "            # Compute theta^* as the coefficient of the convex combination of x1 and x2 \n",
    "            # that, when multiplied by v, gives w\n",
    "            numerator_theta = (w - v @ x2)\n",
    "            denominator_theta = v @ (x1 - x2)\n",
    "            if denominator_theta == 0:\n",
    "                theta_star = 0.5  # Arbitrary value since x1 == x2\n",
    "            else:\n",
    "                theta_star = numerator_theta / denominator_theta\n",
    "            x = theta_star * x1 + (1 - theta_star) * x2\n",
    "            return iteration, x, lambda_plus, phi_plus\n",
    "        # Case 2: w = v * x^+\n",
    "        # x^+ is a primal solution since, in this case, we have minimized xi*x \n",
    "        # while satisfying all constraints\n",
    "        elif np.isclose(w, v @ x_plus):\n",
    "            x = x_plus\n",
    "            phi_plus = xi @ x  # The term lambda^+ * (w - v * x^+) becomes 0\n",
    "            return iteration, x, lambda_plus, phi_plus\n",
    "        \n",
    "        else:\n",
    "            # Case 3: x^+ behaves like x1\n",
    "            # Iterate the algorithm with x^+ instead of x1\n",
    "            if w > v @ x_plus:\n",
    "                B = [x_plus, x2]\n",
    "            # Case 4: x^+ behaves like x2\n",
    "            # Iterate the algorithm with x^+ instead of x2\n",
    "            else:\n",
    "                B = [x1, x_plus]\n",
    "\n",
    "iterations = []\n",
    "for i in range(10000):\n",
    "    np.random.seed()  # For reproducibility with different seeds\n",
    "    xi = np.sort(np.random.random(C))\n",
    "    v = np.linspace(0, 1, C, endpoint=False)\n",
    "    w = np.random.choice(v)\n",
    "    \n",
    "    iteration, x_opt, lambda_opt, phi_opt = cutting_plane_algorithm_histo(xi, v, w, C)\n",
    "    iterations.append(iteration)\n",
    "\n",
    "# Count occurrences\n",
    "occurrences = Counter(iterations)\n",
    "\n",
    "# Data for the histogram\n",
    "labels = list(occurrences.keys())  # Labels (unique values)\n",
    "values = list(occurrences.values())  # Frequencies\n",
    "\n",
    "# Create the histogram\n",
    "plt.bar(labels, values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of iterations to converge')\n",
    "plt.ylabel('Occurrences')\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f220876",
   "metadata": {},
   "source": [
    "## For a fixed seed, here there is the simulation of 10 thousand \n",
    "## istances with cutting plane algorithm and with cvxpy to compare execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794c9a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cutting Plane Algorithm\n",
      "Time taken by the Cutting Plane algorithm: 0.18 seconds\n",
      "----------------------------------------\n",
      "Start cvxpy solver\n",
      "Time taken by the cvxpy solver: 2.95 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize data\n",
    "C = 256  # Size of vectors xi, v, and x\n",
    "N = 1000  # Number of iterations for timing comparison\n",
    "\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "# Generate random xi vector and v values\n",
    "xi = np.sort(np.random.random(C))  # Sorted random values for xi\n",
    "v = np.linspace(0, 1, C, endpoint=False)  # Evenly spaced values between 0 and 1\n",
    "w = np.random.choice(v)  # Randomly select a value from v as w\n",
    "\n",
    "# Measure execution time of the Cutting Plane Algorithm\n",
    "print(\"Start Cutting Plane Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the Cutting Plane algorithm: {training_time:.2f} seconds')\n",
    "\n",
    "print(\"-\" * 40)  # Separator for readability\n",
    "\n",
    "# Measure execution time of the cvxpy solver\n",
    "print(\"Start cvxpy solver\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    # Define optimization variable\n",
    "    x = cp.Variable(C)\n",
    "    \n",
    "    # Define constraints\n",
    "    equality_constraint = v @ x == w  # Enforce v * x = w\n",
    "    constraints = [\n",
    "        equality_constraint,\n",
    "        cp.sum(x) == 1,  # Ensure x sums to 1\n",
    "        x >= 0,  # Ensure non-negativity\n",
    "        x <= 1   # Ensure x values do not exceed 1\n",
    "    ]\n",
    "    \n",
    "    # Define objective function (minimize xi * x)\n",
    "    objective = cp.Minimize(xi @ x)\n",
    "    \n",
    "    # Solve the optimization problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the cvxpy solver: {training_time:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bb844",
   "metadata": {},
   "source": [
    "## Comparison between cvxpy and vectorized cutting plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e8344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken by Vectorized Cutting Plane Algorithm: 0.005 seconds\n",
      "Time taken by cvxpy solver: 14.667 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Configure PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "C = 5  # Size of vectors xi, v, and x\n",
    "N = 10000  # Number of problems in the batch\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(10)\n",
    "xi_np = np.sort(np.random.random(C))  # Sorted random values for xi\n",
    "v_np = np.array([0.0, 0.2, 0.4, 0.6, 0.8])  # Fixed vector v\n",
    "w_np = np.random.choice(v_np, N)  # Randomly select N values from v as w\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "xi = torch.tensor(xi_np, dtype=torch.float32, device=device)\n",
    "v = torch.tensor(v_np, dtype=torch.float32, device=device)\n",
    "w = torch.tensor(w_np, dtype=torch.float32, device=device)\n",
    "\n",
    "# Function to generate unit vectors\n",
    "def get_unit_vectors(indices, size):\n",
    "    \"\"\" Creates unit vectors based on given indices. \"\"\"\n",
    "    x = torch.zeros(indices.size(0), size, device=device)\n",
    "    x[torch.arange(indices.size(0)), indices] = 1.0\n",
    "    return x\n",
    "\n",
    "# Function to initialize B with two vectors satisfying w >= v * x1 and w < v * x2\n",
    "def initialize_B(v, w, C):\n",
    "    \"\"\" Initializes x1 and x2 for the cutting plane algorithm. \"\"\"\n",
    "    v_expanded = v.unsqueeze(0).repeat(w.size(0), 1)  # Expand v to match w's batch size\n",
    "    w_expanded = w.unsqueeze(1)  # Expand w for broadcasting\n",
    "    diff = v_expanded - w_expanded  # Compute the difference\n",
    "\n",
    "    # Find indices where w is between v values\n",
    "    b1 = torch.sum(diff <= 0, dim=1) - 1\n",
    "    b2 = b1 + 1\n",
    "\n",
    "    # Clamp values to stay within valid index range\n",
    "    b1 = torch.clamp(b1, 0, C - 1)\n",
    "    b2 = torch.clamp(b2, 0, C - 1)\n",
    "\n",
    "    # Create unit vectors\n",
    "    x1 = get_unit_vectors(b1, C)\n",
    "    x2 = get_unit_vectors(b2, C)\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "# Vectorized cutting plane algorithm implementation\n",
    "def cutting_plane_algorithm_vectorized(xi, v, w, x1, x2):\n",
    "    \"\"\" Cutting plane algorithm optimized for batch processing with PyTorch. \"\"\"\n",
    "    max_iterations = 8  # Limit the number of iterations\n",
    "    iteration = 0\n",
    "    x_plus = x1.clone()  # Initialize x_plus\n",
    "    lambda_plus = torch.zeros(N, device=device)  # Initialize lambda_plus\n",
    "    phi_plus = torch.zeros(N, device=device)  # Initialize phi_plus\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "\n",
    "        # Compute necessary inner products\n",
    "        xi_x1 = torch.sum(xi * x1, dim=1)\n",
    "        xi_x2 = torch.sum(xi * x2, dim=1)\n",
    "        v_x1 = torch.sum(v * x1, dim=1)\n",
    "        v_x2 = torch.sum(v * x2, dim=1)\n",
    "\n",
    "        # Compute lambda^+ and phi^+\n",
    "        numerator = xi_x2 - xi_x1\n",
    "        denominator = (w - v_x1) - (w - v_x2) + 1e-8  # Avoid division by zero\n",
    "        lambda_plus = numerator / denominator\n",
    "        phi_plus = xi_x1 + lambda_plus * (w - v_x1)\n",
    "\n",
    "        # Compute x^+ as the unit vector minimizing xi - lambda^+ * v\n",
    "        reduced_cost = xi.unsqueeze(0) - lambda_plus.unsqueeze(1) * v.unsqueeze(0)\n",
    "        b_plus = torch.argmin(reduced_cost, dim=1)\n",
    "        x_plus = get_unit_vectors(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = torch.sum(xi * x_plus, dim=1) + lambda_plus * (w - torch.sum(v * x_plus, dim=1))\n",
    "\n",
    "        # Check termination conditions\n",
    "        termination_condition = torch.isclose(phi_lambda_plus, phi_plus, atol=1e-6)\n",
    "        w_equals_vx_plus = torch.isclose(w, torch.sum(v * x_plus, dim=1), atol=1e-6)\n",
    "\n",
    "        # If all samples satisfy termination conditions, return solution\n",
    "        if torch.all(termination_condition | w_equals_vx_plus):\n",
    "            numerator_theta = w - torch.sum(v * x2, dim=1)\n",
    "            denominator_theta = torch.sum(v * (x1 - x2), dim=1) + 1e-8  # Avoid division by zero\n",
    "            theta_star = numerator_theta / denominator_theta\n",
    "            theta_star = torch.clamp(theta_star, 0, 1)  # Ensure valid range\n",
    "\n",
    "            # Compute final solution as a convex combination of x1 and x2\n",
    "            x = theta_star.unsqueeze(1) * x1 + (1 - theta_star).unsqueeze(1) * x2\n",
    "            return x, lambda_plus, phi_plus\n",
    "\n",
    "        # Update B for the next iteration\n",
    "        condition = w > torch.sum(v * x_plus, dim=1)\n",
    "        x1 = torch.where(condition.unsqueeze(1), x_plus, x1)\n",
    "        x2 = torch.where(~condition.unsqueeze(1), x_plus, x2)\n",
    "\n",
    "    return x_plus, lambda_plus, phi_plus  # Return last computed values\n",
    "\n",
    "# Measure execution time for the vectorized Cutting Plane Algorithm\n",
    "x1, x2 = initialize_B(v, w, C)\n",
    "start_time = time.time()\n",
    "x_opt, lambda_opt, phi_opt = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "cutting_plane_time = time.time() - start_time\n",
    "print(f\"\\nTime taken by Vectorized Cutting Plane Algorithm: {cutting_plane_time:.3f} seconds\")\n",
    "\n",
    "# Measure execution time for cvxpy solver\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x = cp.Variable(C)\n",
    "\n",
    "    # Define constraints\n",
    "    constraints = [\n",
    "        v_np @ x == w_np[i],  # Equality constraint\n",
    "        cp.sum(x) == 1,  # Ensure sum of x is 1\n",
    "        x >= 0,  # Ensure non-negativity\n",
    "        x <= 1   # Ensure x values do not exceed 1\n",
    "    ]\n",
    "\n",
    "    # Define objective function (minimize xi * x)\n",
    "    objective = cp.Minimize(xi_np @ x)\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "cvxpy_time = time.time() - start_time\n",
    "print(f\"Time taken by cvxpy solver: {cvxpy_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a06739",
   "metadata": {},
   "source": [
    "## KNAPSACK SPECIALIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd0bc56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_specialized(xi, v, w, C):\n",
    "    \"\"\"\n",
    "    Solves a specialized knapsack problem using a specialized method in a vectorized way\n",
    "\n",
    "    Args:\n",
    "        xi (torch.Tensor): xi variables.\n",
    "        v (torch.Tensor): Quantization vector.\n",
    "        w (torch.Tensor): Weight vector.\n",
    "        C (int): Number of buckets of quantization.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Optimal allocation (x_opt), optimal multipliers (lambda_opt), and objective values.\n",
    "    \"\"\"\n",
    "    \n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "\n",
    "    # Determine optimal allocation based on w\n",
    "    w_idx = torch.searchsorted(v, w)\n",
    "    x_opt = torch.zeros(len(w), C, dtype=torch.float32)\n",
    "    lambda_opt = torch.zeros(len(w), dtype=torch.float32)\n",
    "\n",
    "    indices_1 = torch.nonzero(x_plus == 1).squeeze()\n",
    "    indices_1_sorted = indices_1.sort().values\n",
    "\n",
    "    left_positions = torch.searchsorted(indices_1_sorted, w_idx, right=False) - 1\n",
    "    left_positions = torch.clamp(left_positions, min=0)\n",
    "\n",
    "    right_positions = torch.searchsorted(indices_1_sorted, w_idx, right=True)\n",
    "    right_positions = torch.clamp(right_positions, max=indices_1_sorted.size(0) - 1)\n",
    "\n",
    "    idx_left = torch.where(x_plus[w_idx] == 1, w_idx, indices_1_sorted[left_positions])\n",
    "    idx_right = torch.where(x_plus[w_idx] == 1, w_idx, indices_1_sorted[right_positions])\n",
    "\n",
    "    # Handle cases where idx_left == idx_right\n",
    "    mask_idx_equal = idx_left == idx_right\n",
    "    not_c_minus_1_mask = (idx_left != (C - 1)) & mask_idx_equal\n",
    "    is_c_minus_1_mask = (idx_left == (C - 1)) & mask_idx_equal\n",
    "\n",
    "    if torch.any(not_c_minus_1_mask):\n",
    "        idx_right[not_c_minus_1_mask] = indices_1_sorted[\n",
    "            torch.searchsorted(indices_1_sorted, idx_left[not_c_minus_1_mask], right=True)\n",
    "        ]\n",
    "\n",
    "    if torch.any(is_c_minus_1_mask):\n",
    "        idx_left[is_c_minus_1_mask] = indices_1_sorted[\n",
    "            torch.searchsorted(indices_1_sorted, idx_right[is_c_minus_1_mask], right=False) - 1\n",
    "        ]\n",
    "\n",
    "    # Compute convex combination for optimal solution\n",
    "    x1 = torch.zeros(len(w), C, dtype=torch.float32)\n",
    "    x2 = torch.zeros(len(w), C, dtype=torch.float32)\n",
    "    x1[torch.arange(len(w)), idx_left] = 1\n",
    "    x2[torch.arange(len(w)), idx_right] = 1\n",
    "\n",
    "    numerator = w - torch.matmul(x2, v)\n",
    "    denominator = torch.matmul((x1 - x2), v)\n",
    "    theta = numerator / denominator\n",
    "\n",
    "    mask_equal = (x1 == x2)\n",
    "    theta_expanded = theta.unsqueeze(1)\n",
    "    x_opt = torch.where(mask_equal, x1, x1 * theta_expanded + x2 * (1 - theta_expanded))\n",
    "\n",
    "    # Compute optimal multipliers\n",
    "    denominator = (v[idx_right] - v[idx_left])\n",
    "    denominator_zero_mask = denominator == 0\n",
    "\n",
    "    lambda_opt_nonzero = (xi[idx_right] - xi[idx_left]) / denominator\n",
    "    lambda_opt_zero_full = xi / v\n",
    "    lambda_opt_zero_full[0] = 0\n",
    "    lambda_opt_zero = lambda_opt_zero_full[idx_left]\n",
    "\n",
    "    lambda_opt = torch.where(denominator_zero_mask, lambda_opt_zero, lambda_opt_nonzero)\n",
    "\n",
    "    # Compute objective function values\n",
    "    objective_values = torch.matmul(x_opt, xi)\n",
    "\n",
    "    return x_opt, lambda_opt, objective_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61015d",
   "metadata": {},
   "source": [
    "## Verify correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "109e7da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 1\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 2\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 3\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 4\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 5\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 6\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 7\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 8\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 9\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 10\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 11\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 12\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 13\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 14\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 15\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 16\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 17\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 18\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 19\n",
      "Difference in objective values: 0.0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  \n",
    "\n",
    "for i in range(20):\n",
    "    xi = torch.sort(torch.rand(C, device=device))[0]  \n",
    "    v = torch.linspace(0, 1 - (1 / C), C, device=device)  \n",
    "    w = v[torch.randint(0, C, (1,), device=device)]  \n",
    "    \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    x_opt1, lambda_opt1, phi_opt1 = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "    \n",
    "    x_opt2, lambda_opt2, phi_opt2 = knapsack_specialized(xi, v, w, C)\n",
    "    \n",
    "    print(f\"\\nIteration: {i}\")\n",
    "\n",
    "    # Comparison of solutions\n",
    "    print(f\"Difference in objective values: {float(abs(phi_opt1 - phi_opt2))}\")\n",
    "    print(f\"Difference in x: {np.linalg.norm(x_opt1 - x_opt2)}\")\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8bac7c",
   "metadata": {},
   "source": [
    "## Compare execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f42027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cutting Plane Algorithm\n",
      "Time taken by the Cutting Plane algorithm: 4.58 seconds\n",
      "----------------------------------------\n",
      "Start Specialized Algorithm\n",
      "Time taken by the specialized algorithm: 2.27 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize data\n",
    "C = 256  \n",
    "N = 10000  # Number of iterations for timing comparison\n",
    "\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "v = torch.linspace(0, 1 - (1 / C), C, device=device)  \n",
    "\n",
    "# Measure execution time of the Cutting Plane Algorithm\n",
    "print(\"Start Cutting Plane Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    xi = torch.sort(torch.rand(C, device=device))[0]  \n",
    "    w = v[torch.randint(0, C, (1,), device=device)]  \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    x_opt1, lambda_opt1, phi_opt1 = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the Cutting Plane algorithm: {training_time:.2f} seconds')\n",
    "\n",
    "print(\"-\" * 40)  # Separator for readability\n",
    "\n",
    "# Measure execution time of the specialized algorithm\n",
    "print(\"Start Specialized Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x_opt2, lambda_opt2, phi_opt2 = knapsack_specialized(xi, v, w, C)\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the specialized algorithm: {training_time:.2f} seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
