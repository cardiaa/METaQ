{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7563311b",
   "metadata": {},
   "source": [
    "## Single small istance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1ce936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [1 2 3]\n",
      "v: [0.         0.33333333 0.66666667]\n",
      "w: 0.3333333333333333\n",
      "\n",
      "x_sol: [0. 1. 0.]\n",
      "lambda_opt: 3.0\n",
      "phi_opt: 2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "# Creates a NumPy vector of size C with all zeros except for a 1 at the given index\n",
    "def get_unit_vector(index, C):\n",
    "    x = np.zeros(C)\n",
    "    x[index] = 1.0\n",
    "    return x\n",
    "\n",
    "# Initializes x1 (x2) as a vector with all zeros except for a 1 at the position \n",
    "# corresponding to the index of the largest (smallest) value of v for which w >= v[b] (w < v[b]).\n",
    "def initialize_B(v, w, C):\n",
    "    # List of indices b that satisfy w >= v[b]\n",
    "    b1_candidates = [b for b in range(C) if w >= v[b]]\n",
    "    # List of indices b that satisfy w < v[b]\n",
    "    b2_candidates = [b for b in range(C) if w < v[b]]\n",
    "\n",
    "    # Case where w is smaller than the minimum of v.\n",
    "    # Take the minimum of v.\n",
    "    if not b1_candidates: \n",
    "        b1 = np.argmin(v)\n",
    "    # Otherwise, take the index of the largest value of v for which w >= v[b]\n",
    "    else:\n",
    "        b1 = b1_candidates[-1]\n",
    "\n",
    "    # Case where w is larger than the maximum of v.\n",
    "    # Take the maximum of v.\n",
    "    if not b2_candidates:\n",
    "        b2 = np.argmax(v)\n",
    "    # Otherwise, take the index of the smallest value of v for which w < v[b]\n",
    "    else:\n",
    "        b2 = b2_candidates[0]  # Smallest v_b > w\n",
    "\n",
    "    # Vectors consisting of a 1 only in the b1-th (or b2-th) position\n",
    "    x1 = get_unit_vector(b1, C)\n",
    "    x2 = get_unit_vector(b2, C)\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "# For a fixed w, returns the solution x of (14)-(17),\n",
    "# the optimal multiplier, and the optimal value of the objective function.\n",
    "def cutting_plane_algorithm(xi, v, w, C):\n",
    "    # Count the iterations of the algorithm\n",
    "    iteration = 0\n",
    "    # Prevent infinite loops\n",
    "    max_iterations = 100  \n",
    "    \n",
    "    # Initialize x1 (x2) as a vector that satisfies w >= v * x1 (w < v * x2) \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    B = [x1, x2]\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        if iteration > max_iterations:\n",
    "            print(\"Maximum iterations reached.\")\n",
    "            break\n",
    "\n",
    "        x1, x2 = B\n",
    "\n",
    "        # Compute the intersection point (lambda^+, phi^+) also called (lambda_plus, phi_plus)\n",
    "        numerator = (xi @ x2 - xi @ x1)\n",
    "        denominator = ((w - v @ x1) - (w - v @ x2))\n",
    "        if denominator == 0:\n",
    "            lambda_plus = 0\n",
    "        else:\n",
    "            lambda_plus = numerator / denominator\n",
    "        phi_plus = xi @ x1 + lambda_plus * (w - v @ x1)\n",
    "\n",
    "        # Compute x^+ (x_plus) as the vector that has a 1 at the position \n",
    "        # where xi - lambda_plus * v is minimal\n",
    "        reduced_cost = xi - lambda_plus * v\n",
    "        b_plus = np.argmin(reduced_cost)\n",
    "        x_plus = get_unit_vector(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = xi @ x_plus + lambda_plus * (w - v @ x_plus)\n",
    "\n",
    "        # TERMINATION CONDITIONS\n",
    "        # Case 1:\n",
    "        # |phi_lambda_plus - phi_plus| <= 1e-08 + 1e-05 * phi_plus (see default of isclose())\n",
    "        if np.isclose(phi_lambda_plus, phi_plus):\n",
    "            # Compute theta^* as the coefficient of the convex combination of x1 and x2 \n",
    "            # that, when multiplied by v, gives w\n",
    "            numerator_theta = (w - v @ x2)\n",
    "            denominator_theta = v @ (x1 - x2)\n",
    "            if denominator_theta == 0:\n",
    "                theta_star = 0.5  # Arbitrary value since x1 == x2\n",
    "            else:\n",
    "                theta_star = numerator_theta / denominator_theta\n",
    "            x = theta_star * x1 + (1 - theta_star) * x2\n",
    "            return x, lambda_plus, phi_plus\n",
    "        # Case 2: w = v * x^+\n",
    "        # x^+ is a primal solution since, in this case, we have minimized xi*x \n",
    "        # while satisfying all constraints\n",
    "        elif np.isclose(w, v @ x_plus):\n",
    "            x = x_plus\n",
    "            phi_plus = xi @ x  # The term lambda^+ * (w - v * x^+) becomes 0\n",
    "            return x, lambda_plus, phi_plus\n",
    "        \n",
    "        else:\n",
    "            # Case 3: x^+ behaves like x1\n",
    "            # Iterate the algorithm with x^+ instead of x1\n",
    "            if w > v @ x_plus:\n",
    "                B = [x_plus, x2]\n",
    "            # Case 4: x^+ behaves like x2\n",
    "            # Iterate the algorithm with x^+ instead of x2\n",
    "            else:\n",
    "                B = [x1, x_plus]\n",
    "                \n",
    "C = 3\n",
    "xi = np.array([1,2,3])\n",
    "v = np.linspace(0, 1, C, endpoint=False)\n",
    "w = 1/3\n",
    "\n",
    "x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "\n",
    "# Comparison of solutions\n",
    "print(f\"xi:\", xi)\n",
    "print(\"v:\", v)\n",
    "print(\"w:\", w)\n",
    "\n",
    "print(\"\\nx_sol:\", x_opt)\n",
    "print(\"lambda_opt:\", lambda_opt)\n",
    "print(\"phi_opt:\", phi_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a3567",
   "metadata": {},
   "source": [
    "## Comparison of the results of cvxpy and the cutting plane algorithm in terms of correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ddec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0\n",
      "Difference in objective values: 1.1973563251999053e-09\n",
      "Difference in x: 1.030955100270796e-06\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 1\n",
      "Difference in objective values: 6.150421838491127e-11\n",
      "Difference in x: 8.065169592554692e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 2\n",
      "Difference in objective values: 1.9672916629076553e-09\n",
      "Difference in x: 1.1838869384236914e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 3\n",
      "Difference in objective values: 3.264444270456579e-11\n",
      "Difference in x: 6.600135777258744e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 4\n",
      "Difference in objective values: 1.812779926169128e-10\n",
      "Difference in x: 8.532771178929163e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 5\n",
      "Difference in objective values: 1.8395349132838135e-10\n",
      "Difference in x: 1.0499098136354973e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 6\n",
      "Difference in objective values: 1.721746634153476e-09\n",
      "Difference in x: 1.4561615169800928e-06\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 7\n",
      "Difference in objective values: 8.365874659688188e-11\n",
      "Difference in x: 9.507084449186415e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 8\n",
      "Difference in objective values: 1.6498263866182583e-09\n",
      "Difference in x: 2.0105486011552192e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 9\n",
      "Difference in objective values: 1.0609002565331593e-10\n",
      "Difference in x: 4.974098847671697e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 10\n",
      "Difference in objective values: 3.8621317255405074e-10\n",
      "Difference in x: 2.660986713835668e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 11\n",
      "Difference in objective values: 1.6252933443539064e-09\n",
      "Difference in x: 6.721214424832257e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 12\n",
      "Difference in objective values: 2.164629475664981e-09\n",
      "Difference in x: 3.3570360540200255e-06\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 13\n",
      "Difference in objective values: 1.0664857885700485e-10\n",
      "Difference in x: 7.187101631683347e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 14\n",
      "Difference in objective values: 1.3382140881534887e-09\n",
      "Difference in x: 7.115687896162939e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 15\n",
      "Difference in objective values: 2.364543005839437e-10\n",
      "Difference in x: 1.971318201643916e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 16\n",
      "Difference in objective values: 8.492817560323829e-11\n",
      "Difference in x: 6.1371750295304514e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 17\n",
      "Difference in objective values: 4.006267539935493e-11\n",
      "Difference in x: 1.8537540454564828e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 18\n",
      "Difference in objective values: 4.4017123279616044e-11\n",
      "Difference in x: 1.0407722344201146e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 19\n",
      "Difference in objective values: 2.371799978639899e-10\n",
      "Difference in x: 2.302380988006146e-08\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Dimension of vectors xi, v, and x\n",
    "C = 256\n",
    "                \n",
    "np.random.seed(42)  \n",
    "for i in range(20):\n",
    "    xi = np.sort(np.random.random(C))\n",
    "    v = np.linspace(0, 1, C, endpoint=False)\n",
    "    w = np.random.choice(v)\n",
    "    \n",
    "    x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "    \n",
    "    # Comparison with cvxpy\n",
    "    x = cp.Variable(C)\n",
    "    equality_constraint = v @ x == w\n",
    "    constraints = [\n",
    "        equality_constraint,\n",
    "        cp.sum(x) == 1,\n",
    "        x >= 0,\n",
    "        x <= 1\n",
    "    ]\n",
    "    objective = cp.Minimize(xi @ x)\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "    \n",
    "    print(f\"\\nIteration: {i}\")\n",
    "\n",
    "    # Comparison of solutions\n",
    "    print(f\"Difference in objective values: {abs(phi_opt - prob.value)}\")\n",
    "    print(f\"Difference in x: {np.linalg.norm(x_opt - x.value)}\")\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe9da1",
   "metadata": {},
   "source": [
    "## Counts the number of iteration to convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93067b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Dimension of vectors xi, v, and x\n",
    "C = 256\n",
    "\n",
    "# For a fixed w, returns the solution x of (14)-(17),\n",
    "# the optimal multiplier, and the optimal value of the objective function.\n",
    "def cutting_plane_algorithm_histo(xi, v, w, C):\n",
    "    # Count the iterations of the algorithm\n",
    "    iteration = 0\n",
    "    # Prevent infinite loops\n",
    "    max_iterations = 100  \n",
    "    \n",
    "    # Initialize x1 (x2) as a vector that satisfies w >= v * x1 (w < v * x2) \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    B = [x1, x2]\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        if iteration > max_iterations:\n",
    "            print(\"Maximum iterations reached.\")\n",
    "            break\n",
    "\n",
    "        x1, x2 = B\n",
    "\n",
    "        # Compute the intersection point (lambda^+, phi^+) also called (lambda_plus, phi_plus)\n",
    "        numerator = (xi @ x2 - xi @ x1)\n",
    "        denominator = ((w - v @ x1) - (w - v @ x2))\n",
    "        if denominator == 0:\n",
    "            lambda_plus = 0\n",
    "        else:\n",
    "            lambda_plus = numerator / denominator\n",
    "        phi_plus = xi @ x1 + lambda_plus * (w - v @ x1)\n",
    "\n",
    "        # Compute x^+ (x_plus) as the vector that has a 1 at the position \n",
    "        # where xi - lambda_plus * v is minimal\n",
    "        reduced_cost = xi - lambda_plus * v\n",
    "        b_plus = np.argmin(reduced_cost)\n",
    "        x_plus = get_unit_vector(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = xi @ x_plus + lambda_plus * (w - v @ x_plus)\n",
    "\n",
    "        # TERMINATION CONDITIONS\n",
    "        # Case 1:\n",
    "        # |phi_lambda_plus - phi_plus| <= 1e-08 + 1e-05 * phi_plus (see default of isclose())\n",
    "        if np.isclose(phi_lambda_plus, phi_plus):\n",
    "            # Compute theta^* as the coefficient of the convex combination of x1 and x2 \n",
    "            # that, when multiplied by v, gives w\n",
    "            numerator_theta = (w - v @ x2)\n",
    "            denominator_theta = v @ (x1 - x2)\n",
    "            if denominator_theta == 0:\n",
    "                theta_star = 0.5  # Arbitrary value since x1 == x2\n",
    "            else:\n",
    "                theta_star = numerator_theta / denominator_theta\n",
    "            x = theta_star * x1 + (1 - theta_star) * x2\n",
    "            return iteration, x, lambda_plus, phi_plus\n",
    "        # Case 2: w = v * x^+\n",
    "        # x^+ is a primal solution since, in this case, we have minimized xi*x \n",
    "        # while satisfying all constraints\n",
    "        elif np.isclose(w, v @ x_plus):\n",
    "            x = x_plus\n",
    "            phi_plus = xi @ x  # The term lambda^+ * (w - v * x^+) becomes 0\n",
    "            return iteration, x, lambda_plus, phi_plus\n",
    "        \n",
    "        else:\n",
    "            # Case 3: x^+ behaves like x1\n",
    "            # Iterate the algorithm with x^+ instead of x1\n",
    "            if w > v @ x_plus:\n",
    "                B = [x_plus, x2]\n",
    "            # Case 4: x^+ behaves like x2\n",
    "            # Iterate the algorithm with x^+ instead of x2\n",
    "            else:\n",
    "                B = [x1, x_plus]\n",
    "\n",
    "iterations = []\n",
    "for i in range(10000):\n",
    "    np.random.seed()  # For reproducibility with different seeds\n",
    "    xi = np.sort(np.random.random(C))\n",
    "    v = np.linspace(0, 1, C, endpoint=False)\n",
    "    w = np.random.choice(v)\n",
    "    \n",
    "    iteration, x_opt, lambda_opt, phi_opt = cutting_plane_algorithm_histo(xi, v, w, C)\n",
    "    iterations.append(iteration)\n",
    "\n",
    "# Count occurrences\n",
    "occurrences = Counter(iterations)\n",
    "\n",
    "# Data for the histogram\n",
    "labels = list(occurrences.keys())  # Labels (unique values)\n",
    "values = list(occurrences.values())  # Frequencies\n",
    "\n",
    "# Create the histogram\n",
    "plt.bar(labels, values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of iterations to converge')\n",
    "plt.ylabel('Occurrences')\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f220876",
   "metadata": {},
   "source": [
    "## For a fixed seed, here there is the simulation of 10 thousand \n",
    "## istances with cutting plane algorithm and with cvxpy to compare execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794c9a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cutting Plane Algorithm\n",
      "Time taken by the Cutting Plane algorithm: 0.21 seconds\n",
      "----------------------------------------\n",
      "Start cvxpy solver\n",
      "Time taken by the cvxpy solver: 3.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize data\n",
    "C = 256  # Size of vectors xi, v, and x\n",
    "N = 1000  # Number of iterations for timing comparison\n",
    "\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "# Generate random xi vector and v values\n",
    "xi = np.sort(np.random.random(C))  # Sorted random values for xi\n",
    "v = np.linspace(0, 1, C, endpoint=False)  # Evenly spaced values between 0 and 1\n",
    "w = np.random.choice(v)  # Randomly select a value from v as w\n",
    "\n",
    "# Measure execution time of the Cutting Plane Algorithm\n",
    "print(\"Start Cutting Plane Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the Cutting Plane algorithm: {training_time:.2f} seconds')\n",
    "\n",
    "print(\"-\" * 40)  # Separator for readability\n",
    "\n",
    "# Measure execution time of the cvxpy solver\n",
    "print(\"Start cvxpy solver\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    # Define optimization variable\n",
    "    x = cp.Variable(C)\n",
    "    \n",
    "    # Define constraints\n",
    "    equality_constraint = v @ x == w  # Enforce v * x = w\n",
    "    constraints = [\n",
    "        equality_constraint,\n",
    "        cp.sum(x) == 1,  # Ensure x sums to 1\n",
    "        x >= 0,  # Ensure non-negativity\n",
    "        x <= 1   # Ensure x values do not exceed 1\n",
    "    ]\n",
    "    \n",
    "    # Define objective function (minimize xi * x)\n",
    "    objective = cp.Minimize(xi @ x)\n",
    "    \n",
    "    # Solve the optimization problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the cvxpy solver: {training_time:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bb844",
   "metadata": {},
   "source": [
    "## Comparison between cvxpy and vectorized cutting plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e8344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken by Vectorized Cutting Plane Algorithm: 0.002 seconds\n",
      "Time taken by cvxpy solver: 14.850 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Configure PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "C = 5  # Size of vectors xi, v, and x\n",
    "N = 10000  # Number of problems in the batch\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(10)\n",
    "xi_np = np.sort(np.random.random(C))  # Sorted random values for xi\n",
    "v_np = np.array([0.0, 0.2, 0.4, 0.6, 0.8])  # Fixed vector v\n",
    "w_np = np.random.choice(v_np, N)  # Randomly select N values from v as w\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "xi = torch.tensor(xi_np, dtype=torch.float32, device=device)\n",
    "v = torch.tensor(v_np, dtype=torch.float32, device=device)\n",
    "w = torch.tensor(w_np, dtype=torch.float32, device=device)\n",
    "\n",
    "# Function to generate unit vectors\n",
    "def get_unit_vectors(indices, size):\n",
    "    \"\"\" Creates unit vectors based on given indices. \"\"\"\n",
    "    x = torch.zeros(indices.size(0), size, device=device)\n",
    "    x[torch.arange(indices.size(0)), indices] = 1.0\n",
    "    return x\n",
    "\n",
    "# Function to initialize B with two vectors satisfying w >= v * x1 and w < v * x2\n",
    "def initialize_B(v, w, C):\n",
    "    \"\"\" Initializes x1 and x2 for the cutting plane algorithm. \"\"\"\n",
    "    v_expanded = v.unsqueeze(0).repeat(w.size(0), 1)  # Expand v to match w's batch size\n",
    "    w_expanded = w.unsqueeze(1)  # Expand w for broadcasting\n",
    "    diff = v_expanded - w_expanded  # Compute the difference\n",
    "\n",
    "    # Find indices where w is between v values\n",
    "    b1 = torch.sum(diff <= 0, dim=1) - 1\n",
    "    b2 = b1 + 1\n",
    "\n",
    "    # Clamp values to stay within valid index range\n",
    "    b1 = torch.clamp(b1, 0, C - 1)\n",
    "    b2 = torch.clamp(b2, 0, C - 1)\n",
    "\n",
    "    # Create unit vectors\n",
    "    x1 = get_unit_vectors(b1, C)\n",
    "    x2 = get_unit_vectors(b2, C)\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "# Vectorized cutting plane algorithm implementation\n",
    "def cutting_plane_algorithm_vectorized(xi, v, w, x1, x2):\n",
    "    \"\"\" Cutting plane algorithm optimized for batch processing with PyTorch. \"\"\"\n",
    "    max_iterations = 8  # Limit the number of iterations\n",
    "    iteration = 0\n",
    "    x_plus = x1.clone()  # Initialize x_plus\n",
    "    lambda_plus = torch.zeros(N, device=device)  # Initialize lambda_plus\n",
    "    phi_plus = torch.zeros(N, device=device)  # Initialize phi_plus\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "\n",
    "        # Compute necessary inner products\n",
    "        xi_x1 = torch.sum(xi * x1, dim=1)\n",
    "        xi_x2 = torch.sum(xi * x2, dim=1)\n",
    "        v_x1 = torch.sum(v * x1, dim=1)\n",
    "        v_x2 = torch.sum(v * x2, dim=1)\n",
    "\n",
    "        # Compute lambda^+ and phi^+\n",
    "        numerator = xi_x2 - xi_x1\n",
    "        denominator = (w - v_x1) - (w - v_x2) + 1e-8  # Avoid division by zero\n",
    "        lambda_plus = numerator / denominator\n",
    "        phi_plus = xi_x1 + lambda_plus * (w - v_x1)\n",
    "\n",
    "        # Compute x^+ as the unit vector minimizing xi - lambda^+ * v\n",
    "        reduced_cost = xi.unsqueeze(0) - lambda_plus.unsqueeze(1) * v.unsqueeze(0)\n",
    "        b_plus = torch.argmin(reduced_cost, dim=1)\n",
    "        x_plus = get_unit_vectors(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = torch.sum(xi * x_plus, dim=1) + lambda_plus * (w - torch.sum(v * x_plus, dim=1))\n",
    "\n",
    "        # Check termination conditions\n",
    "        termination_condition = torch.isclose(phi_lambda_plus, phi_plus, atol=1e-6)\n",
    "        w_equals_vx_plus = torch.isclose(w, torch.sum(v * x_plus, dim=1), atol=1e-6)\n",
    "\n",
    "        # If all samples satisfy termination conditions, return solution\n",
    "        if torch.all(termination_condition | w_equals_vx_plus):\n",
    "            numerator_theta = w - torch.sum(v * x2, dim=1)\n",
    "            denominator_theta = torch.sum(v * (x1 - x2), dim=1) + 1e-8  # Avoid division by zero\n",
    "            theta_star = numerator_theta / denominator_theta\n",
    "            theta_star = torch.clamp(theta_star, 0, 1)  # Ensure valid range\n",
    "\n",
    "            # Compute final solution as a convex combination of x1 and x2\n",
    "            x = theta_star.unsqueeze(1) * x1 + (1 - theta_star).unsqueeze(1) * x2\n",
    "            return x, lambda_plus, phi_plus\n",
    "\n",
    "        # Update B for the next iteration\n",
    "        condition = w > torch.sum(v * x_plus, dim=1)\n",
    "        x1 = torch.where(condition.unsqueeze(1), x_plus, x1)\n",
    "        x2 = torch.where(~condition.unsqueeze(1), x_plus, x2)\n",
    "\n",
    "    return x_plus, lambda_plus, phi_plus  # Return last computed values\n",
    "\n",
    "# Measure execution time for the vectorized Cutting Plane Algorithm\n",
    "x1, x2 = initialize_B(v, w, C)\n",
    "start_time = time.time()\n",
    "x_opt, lambda_opt, phi_opt = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "cutting_plane_time = time.time() - start_time\n",
    "print(f\"\\nTime taken by Vectorized Cutting Plane Algorithm: {cutting_plane_time:.3f} seconds\")\n",
    "\n",
    "# Measure execution time for cvxpy solver\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x = cp.Variable(C)\n",
    "\n",
    "    # Define constraints\n",
    "    constraints = [\n",
    "        v_np @ x == w_np[i],  # Equality constraint\n",
    "        cp.sum(x) == 1,  # Ensure sum of x is 1\n",
    "        x >= 0,  # Ensure non-negativity\n",
    "        x <= 1   # Ensure x values do not exceed 1\n",
    "    ]\n",
    "\n",
    "    # Define objective function (minimize xi * x)\n",
    "    objective = cp.Minimize(xi_np @ x)\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "cvxpy_time = time.time() - start_time\n",
    "print(f\"Time taken by cvxpy solver: {cvxpy_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a06739",
   "metadata": {},
   "source": [
    "## KNAPSACK SPECIALIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f67295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_specialized(xi, v, w, C):\n",
    "    \"\"\"\n",
    "    Solves a specialized knapsack problem using a specialized method in a vectorized way\n",
    "\n",
    "    Args:\n",
    "        xi (torch.Tensor): xi variables.\n",
    "        v (torch.Tensor): Quantization vector.\n",
    "        w (torch.Tensor): Weight vector.\n",
    "        C (int): Number of buckets of quantization.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Optimal allocation (x_opt), optimal multipliers (lambda_opt), and objective values.\n",
    "    \"\"\"\n",
    "    \n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "\n",
    "    # Determine optimal allocation based on w\n",
    "    w_idx = torch.searchsorted(v, w) \n",
    "    indices_breakpoints = torch.nonzero(x_plus == 1).squeeze()\n",
    "\n",
    "    # Creation of masks for extreme cases\n",
    "    mask_right = w > v[-1]\n",
    "    mask_left = w < v[0]\n",
    "\n",
    "    # Find indices using searchsorted\n",
    "    search_idx = torch.searchsorted(indices_breakpoints, w_idx)\n",
    "\n",
    "    # Ensure that the indices are valid\n",
    "    search_idx = torch.clamp(search_idx, 1, len(indices_breakpoints) - 1)\n",
    "\n",
    "    # Initialize idx_right and idx_left with the result of the search\n",
    "    idx_right = indices_breakpoints[search_idx]\n",
    "    idx_left = indices_breakpoints[search_idx - 1]\n",
    "\n",
    "    # Correct the indices for extreme cases\n",
    "    idx_right = torch.where(mask_right, indices_breakpoints[-1], idx_right)\n",
    "    idx_left = torch.where(mask_right, indices_breakpoints[-1], idx_left)\n",
    "\n",
    "    # Correct the indices for the case when w < v[0]\n",
    "    idx_right = torch.where(mask_left, indices_breakpoints[0], idx_right)\n",
    "    idx_left = torch.where(mask_left, indices_breakpoints[0], idx_left)\n",
    "\n",
    "    # Compute convex combination for optimal solution\n",
    "    x1, x2 = torch.zeros(2, len(w), C, dtype=torch.float32)\n",
    "\n",
    "    x1[torch.arange(len(w)), idx_left] = 1\n",
    "    x2[torch.arange(len(w)), idx_right] = 1\n",
    "\n",
    "    numerator = w - torch.matmul(x2, v)\n",
    "    denominator = torch.matmul((x1 - x2), v)\n",
    "    theta = numerator / denominator\n",
    "\n",
    "    mask_equal = (x1 == x2)\n",
    "    theta_expanded = theta.unsqueeze(1)\n",
    "    x_opt = torch.where(mask_equal, x1, x1 * theta_expanded + x2 * (1 - theta_expanded))\n",
    "\n",
    "    # Compute optimal multipliers\n",
    "    denominator = (v[idx_right] - v[idx_left])\n",
    "    denominator_zero_mask = denominator == 0\n",
    "\n",
    "    lambda_opt_nonzero = (xi[idx_right] - xi[idx_left]) / denominator\n",
    "    lambda_opt_zero_full = xi / v\n",
    "    lambda_opt_zero_full[0] = 0\n",
    "    lambda_opt_zero = lambda_opt_zero_full[idx_left]\n",
    "\n",
    "    lambda_opt = torch.where(denominator_zero_mask, lambda_opt_zero, lambda_opt_nonzero)\n",
    "\n",
    "    # Compute objective function values\n",
    "    objective_values = torch.matmul(x_opt, xi)\n",
    "\n",
    "    return x_opt, lambda_opt, objective_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61015d",
   "metadata": {},
   "source": [
    "## Verify correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "109e7da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm is correct!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  \n",
    "C = 256\n",
    "M = 100\n",
    "CORRECT = True\n",
    "\n",
    "for i in range(1000):\n",
    "    xi = torch.sort(torch.rand(C, device=device))[0]  \n",
    "    v = torch.linspace(0, 1 - (1 / C), C, device=device)  \n",
    "    #w = v[torch.randint(0, C, (1,), device=device)]  \n",
    "    w = torch.rand(M, device=device)\n",
    "    \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    x_opt1, lambda_opt1, phi_opt1 = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "    \n",
    "    x_opt2, lambda_opt2, phi_opt2 = knapsack_specialized(xi, v, w, C)\n",
    "    \n",
    "    # Comparison of solutions\n",
    "    if(torch.any(torch.abs(x_opt1 - x_opt2) > 1e-3) and torch.any(phi_opt1 + 1e-4 < phi_opt2)):\n",
    "        #print(\"x_opt1:\", x_opt1)\n",
    "        print(\"phi_opt1:\", phi_opt1)\n",
    "        #print(\"x_opt2:\", x_opt2)\n",
    "        print(\"phi_opt2:\", phi_opt2)\n",
    "        print(\"ERROR! Algorithms provide different solutions!\")\n",
    "        CORRECT = False\n",
    "\n",
    "if(CORRECT == True):\n",
    "    print(\"The algorithm is correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8bac7c",
   "metadata": {},
   "source": [
    "## Compare execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f42027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cutting Plane Algorithm\n",
      "Time taken by the Cutting Plane algorithm: 214.12 seconds\n",
      "----------------------------------------\n",
      "Start Specialized Algorithm\n",
      "Time taken by the specialized algorithm: 18.87 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize data\n",
    "C = 256  \n",
    "N = 1000  # Number of iterations for timing comparison\n",
    "M = 44000 # Parallelization\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "v = torch.linspace(0, 1 - (1 / C), C, device=device)  \n",
    "\n",
    "# Measure execution time of the Cutting Plane Algorithm\n",
    "print(\"Start Cutting Plane Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    xi = torch.sort(torch.rand(C, device=device))[0]  \n",
    "    w = torch.rand(M, device=device)\n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    x_opt1, lambda_opt1, phi_opt1 = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "training_time1 = time.time() - start_time\n",
    "print(f'Time taken by the Cutting Plane algorithm: {training_time1:.2f} seconds')\n",
    "\n",
    "print(\"-\" * 40)  # Separator for readability\n",
    "\n",
    "# Measure execution time of the specialized algorithm\n",
    "print(\"Start Specialized Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x_opt2, lambda_opt2, phi_opt2 = knapsack_specialized(xi, v, w, C)\n",
    "training_time2 = time.time() - start_time\n",
    "print(f'Time taken by the specialized algorithm: {training_time2:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b72ae400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specialized algorithm results in 11.35x better performance\n"
     ]
    }
   ],
   "source": [
    "print(f\"The specialized algorithm results in {training_time1 / training_time2:.2f}x better performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
