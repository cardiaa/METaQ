{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7563311b",
   "metadata": {},
   "source": [
    "## Single small istance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1ce936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [1 2 3]\n",
      "v: [0.         0.33333333 0.66666667]\n",
      "w: 0.3333333333333333\n",
      "\n",
      "x_sol: [0. 1. 0.]\n",
      "lambda_opt: 3.0\n",
      "phi_opt: 2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "# Creates a NumPy vector of size C with all zeros except for a 1 at the given index\n",
    "def get_unit_vector(index, C):\n",
    "    x = np.zeros(C)\n",
    "    x[index] = 1.0\n",
    "    return x\n",
    "\n",
    "# Initializes x1 (x2) as a vector with all zeros except for a 1 at the position \n",
    "# corresponding to the index of the largest (smallest) value of v for which w >= v[b] (w < v[b]).\n",
    "def initialize_B(v, w, C):\n",
    "    # List of indices b that satisfy w >= v[b]\n",
    "    b1_candidates = [b for b in range(C) if w >= v[b]]\n",
    "    # List of indices b that satisfy w < v[b]\n",
    "    b2_candidates = [b for b in range(C) if w < v[b]]\n",
    "\n",
    "    # Case where w is smaller than the minimum of v.\n",
    "    # Take the minimum of v.\n",
    "    if not b1_candidates: \n",
    "        b1 = np.argmin(v)\n",
    "    # Otherwise, take the index of the largest value of v for which w >= v[b]\n",
    "    else:\n",
    "        b1 = b1_candidates[-1]\n",
    "\n",
    "    # Case where w is larger than the maximum of v.\n",
    "    # Take the maximum of v.\n",
    "    if not b2_candidates:\n",
    "        b2 = np.argmax(v)\n",
    "    # Otherwise, take the index of the smallest value of v for which w < v[b]\n",
    "    else:\n",
    "        b2 = b2_candidates[0]  # Smallest v_b > w\n",
    "\n",
    "    # Vectors consisting of a 1 only in the b1-th (or b2-th) position\n",
    "    x1 = get_unit_vector(b1, C)\n",
    "    x2 = get_unit_vector(b2, C)\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "# For a fixed w, returns the solution x of (14)-(17),\n",
    "# the optimal multiplier, and the optimal value of the objective function.\n",
    "def cutting_plane_algorithm(xi, v, w, C):\n",
    "    # Count the iterations of the algorithm\n",
    "    iteration = 0\n",
    "    # Prevent infinite loops\n",
    "    max_iterations = 100  \n",
    "    \n",
    "    # Initialize x1 (x2) as a vector that satisfies w >= v * x1 (w < v * x2) \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    B = [x1, x2]\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        if iteration > max_iterations:\n",
    "            print(\"Maximum iterations reached.\")\n",
    "            break\n",
    "\n",
    "        x1, x2 = B\n",
    "\n",
    "        # Compute the intersection point (lambda^+, phi^+) also called (lambda_plus, phi_plus)\n",
    "        numerator = (xi @ x2 - xi @ x1)\n",
    "        denominator = ((w - v @ x1) - (w - v @ x2))\n",
    "        if denominator == 0:\n",
    "            lambda_plus = 0\n",
    "        else:\n",
    "            lambda_plus = numerator / denominator\n",
    "        phi_plus = xi @ x1 + lambda_plus * (w - v @ x1)\n",
    "\n",
    "        # Compute x^+ (x_plus) as the vector that has a 1 at the position \n",
    "        # where xi - lambda_plus * v is minimal\n",
    "        reduced_cost = xi - lambda_plus * v\n",
    "        b_plus = np.argmin(reduced_cost)\n",
    "        x_plus = get_unit_vector(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = xi @ x_plus + lambda_plus * (w - v @ x_plus)\n",
    "\n",
    "        # TERMINATION CONDITIONS\n",
    "        # Case 1:\n",
    "        # |phi_lambda_plus - phi_plus| <= 1e-08 + 1e-05 * phi_plus (see default of isclose())\n",
    "        if np.isclose(phi_lambda_plus, phi_plus):\n",
    "            # Compute theta^* as the coefficient of the convex combination of x1 and x2 \n",
    "            # that, when multiplied by v, gives w\n",
    "            numerator_theta = (w - v @ x2)\n",
    "            denominator_theta = v @ (x1 - x2)\n",
    "            if denominator_theta == 0:\n",
    "                theta_star = 0.5  # Arbitrary value since x1 == x2\n",
    "            else:\n",
    "                theta_star = numerator_theta / denominator_theta\n",
    "            x = theta_star * x1 + (1 - theta_star) * x2\n",
    "            return x, lambda_plus, phi_plus\n",
    "        # Case 2: w = v * x^+\n",
    "        # x^+ is a primal solution since, in this case, we have minimized xi*x \n",
    "        # while satisfying all constraints\n",
    "        elif np.isclose(w, v @ x_plus):\n",
    "            x = x_plus\n",
    "            phi_plus = xi @ x  # The term lambda^+ * (w - v * x^+) becomes 0\n",
    "            return x, lambda_plus, phi_plus\n",
    "        \n",
    "        else:\n",
    "            # Case 3: x^+ behaves like x1\n",
    "            # Iterate the algorithm with x^+ instead of x1\n",
    "            if w > v @ x_plus:\n",
    "                B = [x_plus, x2]\n",
    "            # Case 4: x^+ behaves like x2\n",
    "            # Iterate the algorithm with x^+ instead of x2\n",
    "            else:\n",
    "                B = [x1, x_plus]\n",
    "                \n",
    "C = 3\n",
    "xi = np.array([1,2,3])\n",
    "v = np.linspace(0, 1, C, endpoint=False)\n",
    "w = 1/3\n",
    "\n",
    "x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "\n",
    "# Comparison of solutions\n",
    "print(f\"xi:\", xi)\n",
    "print(\"v:\", v)\n",
    "print(\"w:\", w)\n",
    "\n",
    "print(\"\\nx_sol:\", x_opt)\n",
    "print(\"lambda_opt:\", lambda_opt)\n",
    "print(\"phi_opt:\", phi_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a3567",
   "metadata": {},
   "source": [
    "## Comparison of the results of cvxpy and the cutting plane algorithm in terms of correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ddec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0\n",
      "Difference in objective values: 1.1973563251999053e-09\n",
      "Difference in x: 1.030955100270796e-06\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 1\n",
      "Difference in objective values: 6.150421838491127e-11\n",
      "Difference in x: 8.065169592554692e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 2\n",
      "Difference in objective values: 1.9672916629076553e-09\n",
      "Difference in x: 1.1838869384236914e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 3\n",
      "Difference in objective values: 3.264444270456579e-11\n",
      "Difference in x: 6.600135777258744e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 4\n",
      "Difference in objective values: 1.812779926169128e-10\n",
      "Difference in x: 8.532771178929163e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 5\n",
      "Difference in objective values: 1.8395349132838135e-10\n",
      "Difference in x: 1.0499098136354973e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 6\n",
      "Difference in objective values: 1.721746634153476e-09\n",
      "Difference in x: 1.4561615169800928e-06\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 7\n",
      "Difference in objective values: 8.365874659688188e-11\n",
      "Difference in x: 9.507084449186415e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 8\n",
      "Difference in objective values: 1.6498263866182583e-09\n",
      "Difference in x: 2.0105486011552192e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 9\n",
      "Difference in objective values: 1.0609002565331593e-10\n",
      "Difference in x: 4.974098847671697e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 10\n",
      "Difference in objective values: 3.8621317255405074e-10\n",
      "Difference in x: 2.660986713835668e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 11\n",
      "Difference in objective values: 1.6252933443539064e-09\n",
      "Difference in x: 6.721214424832257e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 12\n",
      "Difference in objective values: 2.164629475664981e-09\n",
      "Difference in x: 3.3570360540200255e-06\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 13\n",
      "Difference in objective values: 1.0664857885700485e-10\n",
      "Difference in x: 7.187101631683347e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 14\n",
      "Difference in objective values: 1.3382140881534887e-09\n",
      "Difference in x: 7.115687896162939e-07\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 15\n",
      "Difference in objective values: 2.364543005839437e-10\n",
      "Difference in x: 1.971318201643916e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 16\n",
      "Difference in objective values: 8.492817560323829e-11\n",
      "Difference in x: 6.1371750295304514e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 17\n",
      "Difference in objective values: 4.006267539935493e-11\n",
      "Difference in x: 1.8537540454564828e-09\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 18\n",
      "Difference in objective values: 4.4017123279616044e-11\n",
      "Difference in x: 1.0407722344201146e-08\n",
      "----------------------------------------\n",
      "\n",
      "Iteration: 19\n",
      "Difference in objective values: 2.371799978639899e-10\n",
      "Difference in x: 2.302380988006146e-08\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Dimension of vectors xi, v, and x\n",
    "C = 256\n",
    "                \n",
    "np.random.seed(42)  \n",
    "for i in range(20):\n",
    "    xi = np.sort(np.random.random(C))\n",
    "    v = np.linspace(0, 1, C, endpoint=False)\n",
    "    w = np.random.choice(v)\n",
    "    \n",
    "    x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "    \n",
    "    # Comparison with cvxpy\n",
    "    x = cp.Variable(C)\n",
    "    equality_constraint = v @ x == w\n",
    "    constraints = [\n",
    "        equality_constraint,\n",
    "        cp.sum(x) == 1,\n",
    "        x >= 0,\n",
    "        x <= 1\n",
    "    ]\n",
    "    objective = cp.Minimize(xi @ x)\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "    \n",
    "    print(f\"\\nIteration: {i}\")\n",
    "\n",
    "    # Comparison of solutions\n",
    "    print(f\"Difference in objective values: {abs(phi_opt - prob.value)}\")\n",
    "    print(f\"Difference in x: {np.linalg.norm(x_opt - x.value)}\")\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe9da1",
   "metadata": {},
   "source": [
    "## Counts the number of iteration to convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93067b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Dimension of vectors xi, v, and x\n",
    "C = 256\n",
    "\n",
    "# For a fixed w, returns the solution x of (14)-(17),\n",
    "# the optimal multiplier, and the optimal value of the objective function.\n",
    "def cutting_plane_algorithm_histo(xi, v, w, C):\n",
    "    # Count the iterations of the algorithm\n",
    "    iteration = 0\n",
    "    # Prevent infinite loops\n",
    "    max_iterations = 100  \n",
    "    \n",
    "    # Initialize x1 (x2) as a vector that satisfies w >= v * x1 (w < v * x2) \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    B = [x1, x2]\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        if iteration > max_iterations:\n",
    "            print(\"Maximum iterations reached.\")\n",
    "            break\n",
    "\n",
    "        x1, x2 = B\n",
    "\n",
    "        # Compute the intersection point (lambda^+, phi^+) also called (lambda_plus, phi_plus)\n",
    "        numerator = (xi @ x2 - xi @ x1)\n",
    "        denominator = ((w - v @ x1) - (w - v @ x2))\n",
    "        if denominator == 0:\n",
    "            lambda_plus = 0\n",
    "        else:\n",
    "            lambda_plus = numerator / denominator\n",
    "        phi_plus = xi @ x1 + lambda_plus * (w - v @ x1)\n",
    "\n",
    "        # Compute x^+ (x_plus) as the vector that has a 1 at the position \n",
    "        # where xi - lambda_plus * v is minimal\n",
    "        reduced_cost = xi - lambda_plus * v\n",
    "        b_plus = np.argmin(reduced_cost)\n",
    "        x_plus = get_unit_vector(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = xi @ x_plus + lambda_plus * (w - v @ x_plus)\n",
    "\n",
    "        # TERMINATION CONDITIONS\n",
    "        # Case 1:\n",
    "        # |phi_lambda_plus - phi_plus| <= 1e-08 + 1e-05 * phi_plus (see default of isclose())\n",
    "        if np.isclose(phi_lambda_plus, phi_plus):\n",
    "            # Compute theta^* as the coefficient of the convex combination of x1 and x2 \n",
    "            # that, when multiplied by v, gives w\n",
    "            numerator_theta = (w - v @ x2)\n",
    "            denominator_theta = v @ (x1 - x2)\n",
    "            if denominator_theta == 0:\n",
    "                theta_star = 0.5  # Arbitrary value since x1 == x2\n",
    "            else:\n",
    "                theta_star = numerator_theta / denominator_theta\n",
    "            x = theta_star * x1 + (1 - theta_star) * x2\n",
    "            return iteration, x, lambda_plus, phi_plus\n",
    "        # Case 2: w = v * x^+\n",
    "        # x^+ is a primal solution since, in this case, we have minimized xi*x \n",
    "        # while satisfying all constraints\n",
    "        elif np.isclose(w, v @ x_plus):\n",
    "            x = x_plus\n",
    "            phi_plus = xi @ x  # The term lambda^+ * (w - v * x^+) becomes 0\n",
    "            return iteration, x, lambda_plus, phi_plus\n",
    "        \n",
    "        else:\n",
    "            # Case 3: x^+ behaves like x1\n",
    "            # Iterate the algorithm with x^+ instead of x1\n",
    "            if w > v @ x_plus:\n",
    "                B = [x_plus, x2]\n",
    "            # Case 4: x^+ behaves like x2\n",
    "            # Iterate the algorithm with x^+ instead of x2\n",
    "            else:\n",
    "                B = [x1, x_plus]\n",
    "\n",
    "iterations = []\n",
    "for i in range(10000):\n",
    "    np.random.seed()  # For reproducibility with different seeds\n",
    "    xi = np.sort(np.random.random(C))\n",
    "    v = np.linspace(0, 1, C, endpoint=False)\n",
    "    w = np.random.choice(v)\n",
    "    \n",
    "    iteration, x_opt, lambda_opt, phi_opt = cutting_plane_algorithm_histo(xi, v, w, C)\n",
    "    iterations.append(iteration)\n",
    "\n",
    "# Count occurrences\n",
    "occurrences = Counter(iterations)\n",
    "\n",
    "# Data for the histogram\n",
    "labels = list(occurrences.keys())  # Labels (unique values)\n",
    "values = list(occurrences.values())  # Frequencies\n",
    "\n",
    "# Create the histogram\n",
    "plt.bar(labels, values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of iterations to converge')\n",
    "plt.ylabel('Occurrences')\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f220876",
   "metadata": {},
   "source": [
    "## For a fixed seed, here there is the simulation of 10 thousand \n",
    "## istances with cutting plane algorithm and with cvxpy to compare execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794c9a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cutting Plane Algorithm\n",
      "Time taken by the Cutting Plane algorithm: 0.22 seconds\n",
      "----------------------------------------\n",
      "Start cvxpy solver\n",
      "Time taken by the cvxpy solver: 2.95 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize data\n",
    "C = 256  # Size of vectors xi, v, and x\n",
    "N = 1000  # Number of iterations for timing comparison\n",
    "\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "# Generate random xi vector and v values\n",
    "xi = np.sort(np.random.random(C))  # Sorted random values for xi\n",
    "v = np.linspace(0, 1, C, endpoint=False)  # Evenly spaced values between 0 and 1\n",
    "w = np.random.choice(v)  # Randomly select a value from v as w\n",
    "\n",
    "# Measure execution time of the Cutting Plane Algorithm\n",
    "print(\"Start Cutting Plane Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x_opt, lambda_opt, phi_opt = cutting_plane_algorithm(xi, v, w, C)\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the Cutting Plane algorithm: {training_time:.2f} seconds')\n",
    "\n",
    "print(\"-\" * 40)  # Separator for readability\n",
    "\n",
    "# Measure execution time of the cvxpy solver\n",
    "print(\"Start cvxpy solver\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    # Define optimization variable\n",
    "    x = cp.Variable(C)\n",
    "    \n",
    "    # Define constraints\n",
    "    equality_constraint = v @ x == w  # Enforce v * x = w\n",
    "    constraints = [\n",
    "        equality_constraint,\n",
    "        cp.sum(x) == 1,  # Ensure x sums to 1\n",
    "        x >= 0,  # Ensure non-negativity\n",
    "        x <= 1   # Ensure x values do not exceed 1\n",
    "    ]\n",
    "    \n",
    "    # Define objective function (minimize xi * x)\n",
    "    objective = cp.Minimize(xi @ x)\n",
    "    \n",
    "    # Solve the optimization problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the cvxpy solver: {training_time:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bb844",
   "metadata": {},
   "source": [
    "## Comparison between cvxpy and vectorized cutting plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e8344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken by Vectorized Cutting Plane Algorithm: 0.010 seconds\n",
      "Time taken by cvxpy solver: 14.505 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Configure PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "C = 5  # Size of vectors xi, v, and x\n",
    "N = 10000  # Number of problems in the batch\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(10)\n",
    "xi_np = np.sort(np.random.random(C))  # Sorted random values for xi\n",
    "v_np = np.array([0.0, 0.2, 0.4, 0.6, 0.8])  # Fixed vector v\n",
    "w_np = np.random.choice(v_np, N)  # Randomly select N values from v as w\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "xi = torch.tensor(xi_np, dtype=torch.float32, device=device)\n",
    "v = torch.tensor(v_np, dtype=torch.float32, device=device)\n",
    "w = torch.tensor(w_np, dtype=torch.float32, device=device)\n",
    "\n",
    "# Function to generate unit vectors\n",
    "def get_unit_vectors(indices, size):\n",
    "    \"\"\" Creates unit vectors based on given indices. \"\"\"\n",
    "    x = torch.zeros(indices.size(0), size, device=device)\n",
    "    x[torch.arange(indices.size(0)), indices] = 1.0\n",
    "    return x\n",
    "\n",
    "# Function to initialize B with two vectors satisfying w >= v * x1 and w < v * x2\n",
    "def initialize_B(v, w, C):\n",
    "    \"\"\" Initializes x1 and x2 for the cutting plane algorithm. \"\"\"\n",
    "    v_expanded = v.unsqueeze(0).repeat(w.size(0), 1)  # Expand v to match w's batch size\n",
    "    w_expanded = w.unsqueeze(1)  # Expand w for broadcasting\n",
    "    diff = v_expanded - w_expanded  # Compute the difference\n",
    "\n",
    "    # Find indices where w is between v values\n",
    "    b1 = torch.sum(diff <= 0, dim=1) - 1\n",
    "    b2 = b1 + 1\n",
    "\n",
    "    # Clamp values to stay within valid index range\n",
    "    b1 = torch.clamp(b1, 0, C - 1)\n",
    "    b2 = torch.clamp(b2, 0, C - 1)\n",
    "\n",
    "    # Create unit vectors\n",
    "    x1 = get_unit_vectors(b1, C)\n",
    "    x2 = get_unit_vectors(b2, C)\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "# Vectorized cutting plane algorithm implementation\n",
    "def cutting_plane_algorithm_vectorized(xi, v, w, x1, x2):\n",
    "    \"\"\" Cutting plane algorithm optimized for batch processing with PyTorch. \"\"\"\n",
    "    max_iterations = 8  # Limit the number of iterations\n",
    "    iteration = 0\n",
    "    x_plus = x1.clone()  # Initialize x_plus\n",
    "    lambda_plus = torch.zeros(N, device=device)  # Initialize lambda_plus\n",
    "    phi_plus = torch.zeros(N, device=device)  # Initialize phi_plus\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "\n",
    "        # Compute necessary inner products\n",
    "        xi_x1 = torch.sum(xi * x1, dim=1)\n",
    "        xi_x2 = torch.sum(xi * x2, dim=1)\n",
    "        v_x1 = torch.sum(v * x1, dim=1)\n",
    "        v_x2 = torch.sum(v * x2, dim=1)\n",
    "\n",
    "        # Compute lambda^+ and phi^+\n",
    "        numerator = xi_x2 - xi_x1\n",
    "        denominator = (w - v_x1) - (w - v_x2) + 1e-8  # Avoid division by zero\n",
    "        lambda_plus = numerator / denominator\n",
    "        phi_plus = xi_x1 + lambda_plus * (w - v_x1)\n",
    "\n",
    "        # Compute x^+ as the unit vector minimizing xi - lambda^+ * v\n",
    "        reduced_cost = xi.unsqueeze(0) - lambda_plus.unsqueeze(1) * v.unsqueeze(0)\n",
    "        b_plus = torch.argmin(reduced_cost, dim=1)\n",
    "        x_plus = get_unit_vectors(b_plus, C)\n",
    "\n",
    "        # Compute phi(lambda^+)\n",
    "        phi_lambda_plus = torch.sum(xi * x_plus, dim=1) + lambda_plus * (w - torch.sum(v * x_plus, dim=1))\n",
    "\n",
    "        # Check termination conditions\n",
    "        termination_condition = torch.isclose(phi_lambda_plus, phi_plus, atol=1e-6)\n",
    "        w_equals_vx_plus = torch.isclose(w, torch.sum(v * x_plus, dim=1), atol=1e-6)\n",
    "\n",
    "        # If all samples satisfy termination conditions, return solution\n",
    "        if torch.all(termination_condition | w_equals_vx_plus):\n",
    "            numerator_theta = w - torch.sum(v * x2, dim=1)\n",
    "            denominator_theta = torch.sum(v * (x1 - x2), dim=1) + 1e-8  # Avoid division by zero\n",
    "            theta_star = numerator_theta / denominator_theta\n",
    "            theta_star = torch.clamp(theta_star, 0, 1)  # Ensure valid range\n",
    "\n",
    "            # Compute final solution as a convex combination of x1 and x2\n",
    "            x = theta_star.unsqueeze(1) * x1 + (1 - theta_star).unsqueeze(1) * x2\n",
    "            return x, lambda_plus, phi_plus\n",
    "\n",
    "        # Update B for the next iteration\n",
    "        condition = w > torch.sum(v * x_plus, dim=1)\n",
    "        x1 = torch.where(condition.unsqueeze(1), x_plus, x1)\n",
    "        x2 = torch.where(~condition.unsqueeze(1), x_plus, x2)\n",
    "\n",
    "    return x_plus, lambda_plus, phi_plus  # Return last computed values\n",
    "\n",
    "# Measure execution time for the vectorized Cutting Plane Algorithm\n",
    "x1, x2 = initialize_B(v, w, C)\n",
    "start_time = time.time()\n",
    "x_opt, lambda_opt, phi_opt = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "cutting_plane_time = time.time() - start_time\n",
    "print(f\"\\nTime taken by Vectorized Cutting Plane Algorithm: {cutting_plane_time:.3f} seconds\")\n",
    "\n",
    "# Measure execution time for cvxpy solver\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x = cp.Variable(C)\n",
    "\n",
    "    # Define constraints\n",
    "    constraints = [\n",
    "        v_np @ x == w_np[i],  # Equality constraint\n",
    "        cp.sum(x) == 1,  # Ensure sum of x is 1\n",
    "        x >= 0,  # Ensure non-negativity\n",
    "        x <= 1   # Ensure x values do not exceed 1\n",
    "    ]\n",
    "\n",
    "    # Define objective function (minimize xi * x)\n",
    "    objective = cp.Minimize(xi_np @ x)\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "cvxpy_time = time.time() - start_time\n",
    "print(f\"Time taken by cvxpy solver: {cvxpy_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a06739",
   "metadata": {},
   "source": [
    "## KNAPSACK SPECIALIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9e3c46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_specialized(xi, v, w, C):\n",
    "    \"\"\"\n",
    "    Solves a specialized knapsack problem using a specialized method in a vectorized way\n",
    "\n",
    "    Args:\n",
    "        xi (torch.Tensor): xi variables.\n",
    "        v (torch.Tensor): Quantization vector.\n",
    "        w (torch.Tensor): Weight vector.\n",
    "        C (int): Number of buckets of quantization.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Optimal allocation (x_opt), optimal multipliers (lambda_opt), and objective values.\n",
    "    \"\"\"\n",
    "    \n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "    print(\"x_plus:\", x_plus)\n",
    "# ---------------------------------------------------------------------------\n",
    "    # Determine optimal allocation based on w\n",
    "    w_idx = torch.searchsorted(v, w) - 1\n",
    "    if(w_idx == -1):\n",
    "        w_idx = torch.tensor(0)\n",
    "    print(\"v:\", v)\n",
    "    print(\"w:\", w)\n",
    "    if(w_idx >= C):\n",
    "        w_idx = torch.tensor(C - 1)\n",
    "    print(\"w_idx:\", w_idx)\n",
    "\n",
    "    indices_breakpoints = torch.nonzero(x_plus == 1).squeeze()\n",
    "    print(\"indices_breakpoints:\", indices_breakpoints)\n",
    "    \"\"\"\n",
    "    left_positions = torch.searchsorted(indices_breakpoints, w_idx, right=False) - 1\n",
    "    right_positions = torch.searchsorted(indices_breakpoints, w_idx, right=True)\n",
    "    print(\"left_positions:\", left_positions)\n",
    "    print(\"right_positions:\", right_positions)\n",
    "    right_positions = torch.clamp(right_positions, max=indices_breakpoints.size(0) - 1)\n",
    "    left_positions = torch.clamp(left_positions, min=0)\n",
    "    \n",
    "    idx_left = torch.where(x_plus[w_idx] == 1, w_idx, indices_breakpoints[left_positions])\n",
    "    idx_right = torch.where(x_plus[w_idx] == 1, w_idx, indices_breakpoints[right_positions])\n",
    "    \"\"\"\n",
    "    \n",
    "    idx_left = w_idx\n",
    "    print(torch.where(indices_breakpoints == idx_left)[0] + 1)\n",
    "    if(torch.where(indices_breakpoints == idx_left)[0] == C - 1):\n",
    "        idx_right = idx_left\n",
    "    else:\n",
    "        idx_right = indices_breakpoints[torch.where(indices_breakpoints == idx_left)[0] + 1]\n",
    "    print(\"idx_left:\", idx_left)\n",
    "    print(\"idx_right\", idx_right)\n",
    "        \n",
    "    if(idx_left == idx_right):\n",
    "        print(\"mask_idx_equal == 1\")\n",
    "        idx_left = torch.searchsorted(v, w) - 1\n",
    "        if(idx_left < 0):\n",
    "            idx_left = torch.tensor(0)\n",
    "            idx_right = torch.tensor(0)\n",
    "        elif(idx_left == C - 1):\n",
    "            idx_left = torch.tensor(C - 1)\n",
    "            idx_right = torch.tensor(C - 1)\n",
    "        else:\n",
    "            idx_right = (torch.where(x_plus[idx_left + 1:] == 1)[0] + 1 + idx_left)[0]\n",
    "        print(\"idx_left:\", idx_left)\n",
    "        print(\"idx_right:\", idx_right)\n",
    "# ---------------------------------------------------------------------------\n",
    "    # Compute convex combination for optimal solution\n",
    "    x1 = torch.zeros(len(w), C, dtype=torch.float32)\n",
    "    x2 = torch.zeros(len(w), C, dtype=torch.float32)\n",
    "    x1[torch.arange(len(w)), idx_left] = 1\n",
    "    x2[torch.arange(len(w)), idx_right] = 1\n",
    "\n",
    "    numerator = w - torch.matmul(x2, v)\n",
    "    denominator = torch.matmul((x1 - x2), v)\n",
    "    theta = numerator / denominator\n",
    "    print(\"theta:\", theta)\n",
    "    \n",
    "    if(theta < 0):\n",
    "        x_opt = torch.zeros(len(w), C, dtype=torch.float32)\n",
    "        x_opt[torch.arange(len(w)), idx_right] = 1\n",
    "    else:\n",
    "        mask_equal = (x1 == x2)\n",
    "        theta_expanded = theta.unsqueeze(1)\n",
    "        x_opt = torch.where(mask_equal, x1, x1 * theta_expanded + x2 * (1 - theta_expanded))\n",
    "\n",
    "    # Compute optimal multipliers\n",
    "    denominator = (v[idx_right] - v[idx_left])\n",
    "    denominator_zero_mask = denominator == 0\n",
    "\n",
    "    lambda_opt_nonzero = (xi[idx_right] - xi[idx_left]) / denominator\n",
    "    lambda_opt_zero_full = xi / v\n",
    "    lambda_opt_zero_full[0] = 0\n",
    "    lambda_opt_zero = lambda_opt_zero_full[idx_left]\n",
    "\n",
    "    lambda_opt = torch.where(denominator_zero_mask, lambda_opt_zero, lambda_opt_nonzero)\n",
    "\n",
    "    # Compute objective function values\n",
    "    objective_values = torch.matmul(x_opt, xi)\n",
    "\n",
    "    return x_opt, lambda_opt, objective_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "50502d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_specialized(xi, v, w, C):\n",
    "    \"\"\"\n",
    "    Solves a specialized knapsack problem using a specialized method in a vectorized way\n",
    "\n",
    "    Args:\n",
    "        xi (torch.Tensor): xi variables.\n",
    "        v (torch.Tensor): Quantization vector.\n",
    "        w (torch.Tensor): Weight vector.\n",
    "        C (int): Number of buckets of quantization.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Optimal allocation (x_opt), optimal multipliers (lambda_opt), and objective values.\n",
    "    \"\"\"\n",
    "    \n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "    print(\"x_plus:\", x_plus)\n",
    "\n",
    "    # Determine optimal allocation based on w\n",
    "    w_idx = torch.searchsorted(v, w) \n",
    "    indices_breakpoints = torch.nonzero(x_plus == 1).squeeze()\n",
    "    print(\"v:\", v)\n",
    "    print(\"w:\", w)\n",
    "    print(\"indices_breakpoints:\", indices_breakpoints)\n",
    "    print(\"w_idx:\", w_idx)\n",
    "    if(w > v[-1]):\n",
    "        idx_right = indices_breakpoints[-1]\n",
    "        idx_left = idx_right\n",
    "    elif(w < v[0]):\n",
    "        idx_right = indices_breakpoints[0]\n",
    "        idx_left = idx_right    \n",
    "    else:\n",
    "        idx_right = indices_breakpoints[torch.searchsorted(indices_breakpoints, w_idx)]\n",
    "        idx_left = indices_breakpoints[torch.searchsorted(indices_breakpoints, w_idx) - 1]\n",
    "        \n",
    "    print(\"idx_left:\", idx_left)\n",
    "    print(\"idx_right:\", idx_right)\n",
    "\n",
    "    # Compute convex combination for optimal solution\n",
    "    x1 = torch.zeros(len(w), C, dtype=torch.float32)\n",
    "    x2 = torch.zeros(len(w), C, dtype=torch.float32)\n",
    "    x1[torch.arange(len(w)), idx_left] = 1\n",
    "    x2[torch.arange(len(w)), idx_right] = 1\n",
    "\n",
    "    numerator = w - torch.matmul(x2, v)\n",
    "    denominator = torch.matmul((x1 - x2), v)\n",
    "    theta = numerator / denominator\n",
    "    print(\"theta:\", theta)\n",
    "    \n",
    "    if(theta < 0):\n",
    "        x_opt = torch.zeros(len(w), C, dtype=torch.float32)\n",
    "        x_opt[torch.arange(len(w)), idx_right] = 1\n",
    "    else:\n",
    "        mask_equal = (x1 == x2)\n",
    "        theta_expanded = theta.unsqueeze(1)\n",
    "        x_opt = torch.where(mask_equal, x1, x1 * theta_expanded + x2 * (1 - theta_expanded))\n",
    "\n",
    "    # Compute optimal multipliers\n",
    "    denominator = (v[idx_right] - v[idx_left])\n",
    "    denominator_zero_mask = denominator == 0\n",
    "\n",
    "    lambda_opt_nonzero = (xi[idx_right] - xi[idx_left]) / denominator\n",
    "    lambda_opt_zero_full = xi / v\n",
    "    lambda_opt_zero_full[0] = 0\n",
    "    lambda_opt_zero = lambda_opt_zero_full[idx_left]\n",
    "\n",
    "    lambda_opt = torch.where(denominator_zero_mask, lambda_opt_zero, lambda_opt_nonzero)\n",
    "\n",
    "    # Compute objective function values\n",
    "    objective_values = torch.matmul(x_opt, xi)\n",
    "\n",
    "    return x_opt, lambda_opt, objective_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "950a98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = torch.tensor(0.843)\n",
    "#v = torch.tensor([0, 0.25, 0.5, 0.75])\n",
    "#x_plus = torch.tensor([1, 0, 1, 1])\n",
    "\n",
    "#w_idx = torch.searchsorted(v, w) # 3\n",
    "#indices_breakpoints = torch.nonzero(x_plus == 1).squeeze() #[0, 3, 4]\n",
    "\n",
    "#idx_right = w_idx\n",
    "#if(w < v[0] or w > v[-1]):\n",
    "#    idx_left = idx_right\n",
    "#else:\n",
    "#    idx_left = indices_breakpoints[torch.searchsorted(indices_breakpoints, w_idx) - 1]\n",
    "\n",
    "#print(idx_left)\n",
    "#print(idx_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61015d",
   "metadata": {},
   "source": [
    "## Verify correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "109e7da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_plus: tensor([1, 0, 0, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.2874])\n",
      "indices_breakpoints: tensor([0, 3])\n",
      "w_idx: tensor([2])\n",
      "idx_left: tensor([0])\n",
      "idx_right: tensor([3])\n",
      "theta: tensor([0.6169])\n",
      "\n",
      "Iteration: 0\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 0, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.7416])\n",
      "indices_breakpoints: tensor([0, 3])\n",
      "w_idx: tensor([3])\n",
      "idx_left: tensor([0])\n",
      "idx_right: tensor([3])\n",
      "theta: tensor([0.0112])\n",
      "\n",
      "Iteration: 1\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 1, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.4158])\n",
      "indices_breakpoints: tensor([0, 2, 3])\n",
      "w_idx: tensor([2])\n",
      "idx_left: tensor([0])\n",
      "idx_right: tensor([2])\n",
      "theta: tensor([0.1684])\n",
      "\n",
      "Iteration: 2\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 1, 1, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.6239])\n",
      "indices_breakpoints: tensor([0, 1, 2, 3])\n",
      "w_idx: tensor([3])\n",
      "idx_left: tensor([2])\n",
      "idx_right: tensor([3])\n",
      "theta: tensor([0.5044])\n",
      "\n",
      "Iteration: 3\n",
      "Difference in x: 8.429369557916289e-08\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 1, 1, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.6983])\n",
      "indices_breakpoints: tensor([0, 1, 2, 3])\n",
      "w_idx: tensor([3])\n",
      "idx_left: tensor([2])\n",
      "idx_right: tensor([3])\n",
      "theta: tensor([0.2067])\n",
      "\n",
      "Iteration: 4\n",
      "Difference in x: 1.4901161193847656e-08\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 0, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.9543])\n",
      "indices_breakpoints: tensor([0, 3])\n",
      "w_idx: tensor([4])\n",
      "idx_left: tensor(3)\n",
      "idx_right: tensor(3)\n",
      "theta: tensor([inf])\n",
      "\n",
      "Iteration: 5\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 0, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.9742])\n",
      "indices_breakpoints: tensor([0, 3])\n",
      "w_idx: tensor([4])\n",
      "idx_left: tensor(3)\n",
      "idx_right: tensor(3)\n",
      "theta: tensor([inf])\n",
      "\n",
      "Iteration: 6\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 1, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.1038])\n",
      "indices_breakpoints: tensor([0, 2, 3])\n",
      "w_idx: tensor([1])\n",
      "idx_left: tensor([0])\n",
      "idx_right: tensor([2])\n",
      "theta: tensor([0.7923])\n",
      "\n",
      "Iteration: 7\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 0, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.0977])\n",
      "indices_breakpoints: tensor([0, 3])\n",
      "w_idx: tensor([1])\n",
      "idx_left: tensor([0])\n",
      "idx_right: tensor([3])\n",
      "theta: tensor([0.8697])\n",
      "\n",
      "Iteration: 8\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 0, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.4234])\n",
      "indices_breakpoints: tensor([0, 3])\n",
      "w_idx: tensor([2])\n",
      "idx_left: tensor([0])\n",
      "idx_right: tensor([3])\n",
      "theta: tensor([0.4355])\n",
      "\n",
      "Iteration: 9\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 1, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.2047])\n",
      "indices_breakpoints: tensor([0, 2, 3])\n",
      "w_idx: tensor([1])\n",
      "idx_left: tensor([0])\n",
      "idx_right: tensor([2])\n",
      "theta: tensor([0.5907])\n",
      "\n",
      "Iteration: 10\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 1, 0, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.8298])\n",
      "indices_breakpoints: tensor([0, 1, 3])\n",
      "w_idx: tensor([4])\n",
      "idx_left: tensor(3)\n",
      "idx_right: tensor(3)\n",
      "theta: tensor([inf])\n",
      "\n",
      "Iteration: 11\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 1, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.8952])\n",
      "indices_breakpoints: tensor([0, 2, 3])\n",
      "w_idx: tensor([4])\n",
      "idx_left: tensor(3)\n",
      "idx_right: tensor(3)\n",
      "theta: tensor([inf])\n",
      "\n",
      "Iteration: 12\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 1, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.2121])\n",
      "indices_breakpoints: tensor([0, 2, 3])\n",
      "w_idx: tensor([1])\n",
      "idx_left: tensor([0])\n",
      "idx_right: tensor([2])\n",
      "theta: tensor([0.5757])\n",
      "\n",
      "Iteration: 13\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 1, 0, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.5108])\n",
      "indices_breakpoints: tensor([0, 1, 3])\n",
      "w_idx: tensor([3])\n",
      "idx_left: tensor([1])\n",
      "idx_right: tensor([3])\n",
      "theta: tensor([0.4783])\n",
      "\n",
      "Iteration: 14\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 1, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.6886])\n",
      "indices_breakpoints: tensor([0, 2, 3])\n",
      "w_idx: tensor([3])\n",
      "idx_left: tensor([2])\n",
      "idx_right: tensor([3])\n",
      "theta: tensor([0.2455])\n",
      "\n",
      "Iteration: 15\n",
      "Difference in x: 1.4901161193847656e-08\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 0, 1, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.3449])\n",
      "indices_breakpoints: tensor([0, 2, 3])\n",
      "w_idx: tensor([2])\n",
      "idx_left: tensor([0])\n",
      "idx_right: tensor([2])\n",
      "theta: tensor([0.3102])\n",
      "\n",
      "Iteration: 16\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 1, 0, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.5036])\n",
      "indices_breakpoints: tensor([0, 1, 3])\n",
      "w_idx: tensor([3])\n",
      "idx_left: tensor([1])\n",
      "idx_right: tensor([3])\n",
      "theta: tensor([0.4928])\n",
      "\n",
      "Iteration: 17\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 1, 0, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.4122])\n",
      "indices_breakpoints: tensor([0, 1, 3])\n",
      "w_idx: tensor([2])\n",
      "idx_left: tensor([1])\n",
      "idx_right: tensor([3])\n",
      "theta: tensor([0.6756])\n",
      "\n",
      "Iteration: 18\n",
      "Difference in x: 0.0\n",
      "----------------------------------------\n",
      "x_plus: tensor([1, 1, 1, 1], dtype=torch.int32)\n",
      "v: tensor([0.0000, 0.2500, 0.5000, 0.7500])\n",
      "w: tensor([0.3716])\n",
      "indices_breakpoints: tensor([0, 1, 2, 3])\n",
      "w_idx: tensor([2])\n",
      "idx_left: tensor([1])\n",
      "idx_right: tensor([2])\n",
      "theta: tensor([0.5135])\n",
      "\n",
      "Iteration: 19\n",
      "Difference in x: 8.429369557916289e-08\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  \n",
    "C = 4\n",
    "\n",
    "for i in range(20):\n",
    "    xi = torch.sort(torch.rand(C, device=device))[0]  \n",
    "    v = torch.linspace(0, 1 - (1 / C), C, device=device)  \n",
    "    #w = v[torch.randint(0, C, (1,), device=device)]  \n",
    "    w = torch.rand(1, device=device)\n",
    "    \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    x_opt1, lambda_opt1, phi_opt1 = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "    \n",
    "    x_opt2, lambda_opt2, phi_opt2 = knapsack_specialized(xi, v, w, C)\n",
    "    \n",
    "    print(f\"\\nIteration: {i}\")\n",
    "\n",
    "    # Comparison of solutions\n",
    "    print(f\"Difference in x: {np.linalg.norm(x_opt1 - x_opt2)}\")\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e0b4836e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_left = torch.tensor(2)\n",
    "x_plus = torch.tensor([1, 1, 0, 1, 1, 0])\n",
    "torch.where(x_plus[:idx_left] == 1)[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8bac7c",
   "metadata": {},
   "source": [
    "## Compare execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a6f42027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cutting Plane Algorithm\n",
      "Time taken by the Cutting Plane algorithm: 4.61 seconds\n",
      "----------------------------------------\n",
      "Start Specialized Algorithm\n",
      "Time taken by the specialized algorithm: 2.65 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize data\n",
    "C = 256  \n",
    "N = 10000  # Number of iterations for timing comparison\n",
    "\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "v = torch.linspace(0, 1 - (1 / C), C, device=device)  \n",
    "\n",
    "# Measure execution time of the Cutting Plane Algorithm\n",
    "print(\"Start Cutting Plane Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    xi = torch.sort(torch.rand(C, device=device))[0]  \n",
    "    w = v[torch.randint(0, C, (1,), device=device)]  \n",
    "    x1, x2 = initialize_B(v, w, C)\n",
    "    x_opt1, lambda_opt1, phi_opt1 = cutting_plane_algorithm_vectorized(xi, v, w, x1, x2)\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the Cutting Plane algorithm: {training_time:.2f} seconds')\n",
    "\n",
    "print(\"-\" * 40)  # Separator for readability\n",
    "\n",
    "# Measure execution time of the specialized algorithm\n",
    "print(\"Start Specialized Algorithm\")\n",
    "start_time = time.time()\n",
    "for i in range(N):\n",
    "    x_opt2, lambda_opt2, phi_opt2 = knapsack_specialized(xi, v, w, C)\n",
    "training_time = time.time() - start_time\n",
    "print(f'Time taken by the specialized algorithm: {training_time:.2f} seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
