{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96beffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Accuracies: [78.52]\n",
      "\n",
      "Entropies: [685819]\n",
      "\n",
      "Max Accuracy: 78.52\n",
      "Min entropy: 685819\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 32.97 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Accuracies: [78.52, 87.02]\n",
      "\n",
      "Entropies: [685819, 685839]\n",
      "\n",
      "Max Accuracy: 87.02\n",
      "Min entropy: 685819\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.47 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 3\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36]\n",
      "\n",
      "Entropies: [685819, 685839, 685859]\n",
      "\n",
      "Max Accuracy: 90.36\n",
      "Min entropy: 685819\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.94 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 4\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847]\n",
      "\n",
      "Max Accuracy: 92.27\n",
      "Min entropy: 685819\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.91 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 5\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816]\n",
      "\n",
      "Max Accuracy: 93.49\n",
      "Min entropy: 685816\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.73 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 6\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771]\n",
      "\n",
      "Max Accuracy: 94.31\n",
      "Min entropy: 685771\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.84 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 7\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688]\n",
      "\n",
      "Max Accuracy: 94.92\n",
      "Min entropy: 685688\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.07 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 8\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619]\n",
      "\n",
      "Max Accuracy: 94.92\n",
      "Min entropy: 685619\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.84 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 9\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381]\n",
      "\n",
      "Max Accuracy: 95.84\n",
      "Min entropy: 685381\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.12 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 10\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172]\n",
      "\n",
      "Max Accuracy: 95.97\n",
      "Min entropy: 685172\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.77 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 11\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941]\n",
      "\n",
      "Max Accuracy: 95.97\n",
      "Min entropy: 684941\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 31.05 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 12\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346]\n",
      "\n",
      "Max Accuracy: 96.42\n",
      "Min entropy: 684346\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.98 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 13\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42, 96.51]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346, 683491]\n",
      "\n",
      "Max Accuracy: 96.51\n",
      "Min entropy: 683491\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.35 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 14\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42, 96.51, 96.52]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346, 683491, 682928]\n",
      "\n",
      "Max Accuracy: 96.52\n",
      "Min entropy: 682928\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.85 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 15\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42, 96.51, 96.52, 96.33]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346, 683491, 682928, 680991]\n",
      "\n",
      "Max Accuracy: 96.52\n",
      "Min entropy: 680991\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.84 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 16\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42, 96.51, 96.52, 96.33, 96.84]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346, 683491, 682928, 680991, 680521]\n",
      "\n",
      "Max Accuracy: 96.84\n",
      "Min entropy: 680521\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.74 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 17\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42, 96.51, 96.52, 96.33, 96.84, 96.88]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346, 683491, 682928, 680991, 680521, 678321]\n",
      "\n",
      "Max Accuracy: 96.88\n",
      "Min entropy: 678321\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.92 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 18\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42, 96.51, 96.52, 96.33, 96.84, 96.88, 97.16]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346, 683491, 682928, 680991, 680521, 678321, 677395]\n",
      "\n",
      "Max Accuracy: 97.16\n",
      "Min entropy: 677395\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.00 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 19\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42, 96.51, 96.52, 96.33, 96.84, 96.88, 97.16, 97.17]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346, 683491, 682928, 680991, 680521, 678321, 677395, 675951]\n",
      "\n",
      "Max Accuracy: 97.17\n",
      "Min entropy: 675951\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.16 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 20\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42, 96.51, 96.52, 96.33, 96.84, 96.88, 97.16, 97.17, 97.3]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346, 683491, 682928, 680991, 680521, 678321, 677395, 675951, 675588]\n",
      "\n",
      "Max Accuracy: 97.3\n",
      "Min entropy: 675588\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.16 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 21\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42, 96.51, 96.52, 96.33, 96.84, 96.88, 97.16, 97.17, 97.3, 97.25]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346, 683491, 682928, 680991, 680521, 678321, 677395, 675951, 675588, 675104]\n",
      "\n",
      "Max Accuracy: 97.3\n",
      "Min entropy: 675104\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 33.20 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.1, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 22\n",
      "\n",
      "Accuracies: [78.52, 87.02, 90.36, 92.27, 93.49, 94.31, 94.92, 94.78, 95.84, 95.97, 95.39, 96.42, 96.51, 96.52, 96.33, 96.84, 96.88, 97.16, 97.17, 97.3, 97.25, 97.19]\n",
      "\n",
      "Entropies: [685819, 685839, 685859, 685847, 685816, 685771, 685688, 685619, 685381, 685172, 684941, 684346, 683491, 682928, 680991, 680521, 678321, 677395, 675951, 675588, 675104, 673239]\n",
      "\n",
      "Max Accuracy: 97.3\n",
      "Min entropy: 673239\n",
      "------------------------------------------------------------\n",
      "Entropy is not decreasing enough! (A)\n",
      "Time spent to train the model: 672.05 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.102, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Accuracies: [39.82]\n",
      "\n",
      "Entropies: [685672]\n",
      "\n",
      "Max Accuracy: 39.82\n",
      "Min entropy: 685672\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 35.99 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.102, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Accuracies: [39.82, 54.92]\n",
      "\n",
      "Entropies: [685672, 682178]\n",
      "\n",
      "Max Accuracy: 54.92\n",
      "Min entropy: 682178\n",
      "------------------------------------------------------------\n",
      "Accuracy is too low! (C)\n",
      "Time spent to train the model: 70.67 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.104, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Accuracies: [39.35]\n",
      "\n",
      "Entropies: [685565]\n",
      "\n",
      "Max Accuracy: 39.35\n",
      "Min entropy: 685565\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 35.41 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.104, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Accuracies: [39.35, 44.88]\n",
      "\n",
      "Entropies: [685565, 680549]\n",
      "\n",
      "Max Accuracy: 44.88\n",
      "Min entropy: 680549\n",
      "------------------------------------------------------------\n",
      "Accuracy is too low! (C)\n",
      "Time spent to train the model: 71.00 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.106, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Accuracies: [20.25]\n",
      "\n",
      "Entropies: [685597]\n",
      "\n",
      "Max Accuracy: 20.25\n",
      "Min entropy: 685597\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.35 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.106, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Accuracies: [20.25, 29.46]\n",
      "\n",
      "Entropies: [685597, 681523]\n",
      "\n",
      "Max Accuracy: 29.46\n",
      "Min entropy: 681523\n",
      "------------------------------------------------------------\n",
      "Accuracy is too low! (C)\n",
      "Time spent to train the model: 60.51 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.108, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Accuracies: [49.53]\n",
      "\n",
      "Entropies: [685591]\n",
      "\n",
      "Max Accuracy: 49.53\n",
      "Min entropy: 685591\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.54 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.108, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Accuracies: [49.53, 56.32]\n",
      "\n",
      "Entropies: [685591, 661994]\n",
      "\n",
      "Max Accuracy: 56.32\n",
      "Min entropy: 661994\n",
      "------------------------------------------------------------\n",
      "Accuracy is too low! (C)\n",
      "Time spent to train the model: 61.07 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Accuracies: [69.41]\n",
      "\n",
      "Entropies: [685781]\n",
      "\n",
      "Max Accuracy: 69.41\n",
      "Min entropy: 685781\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.06 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Accuracies: [69.41, 81.88]\n",
      "\n",
      "Entropies: [685781, 684225]\n",
      "\n",
      "Max Accuracy: 81.88\n",
      "Min entropy: 684225\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.99 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 3\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02]\n",
      "\n",
      "Entropies: [685781, 684225, 681990]\n",
      "\n",
      "Max Accuracy: 89.02\n",
      "Min entropy: 681990\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.53 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 4\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962]\n",
      "\n",
      "Max Accuracy: 91.56\n",
      "Min entropy: 674962\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.67 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 5\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209]\n",
      "\n",
      "Max Accuracy: 94.01\n",
      "Min entropy: 671209\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.60 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 6\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463]\n",
      "\n",
      "Max Accuracy: 94.63\n",
      "Min entropy: 658463\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.63 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 7\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243]\n",
      "\n",
      "Max Accuracy: 95.4\n",
      "Min entropy: 620243\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.65 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 8\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093]\n",
      "\n",
      "Max Accuracy: 95.5\n",
      "Min entropy: 521093\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.24 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 9\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884]\n",
      "\n",
      "Max Accuracy: 95.99\n",
      "Min entropy: 521093\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.72 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 10\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500]\n",
      "\n",
      "Max Accuracy: 95.99\n",
      "Min entropy: 491500\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.98 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 11\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422]\n",
      "\n",
      "Max Accuracy: 95.99\n",
      "Min entropy: 491500\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.65 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 12\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308]\n",
      "\n",
      "Max Accuracy: 96.25\n",
      "Min entropy: 468308\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.86 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 13\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451]\n",
      "\n",
      "Max Accuracy: 96.91\n",
      "Min entropy: 419451\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 30.89 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 14\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613]\n",
      "\n",
      "Max Accuracy: 97.18\n",
      "Min entropy: 347613\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.72 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 15\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974]\n",
      "\n",
      "Max Accuracy: 97.18\n",
      "Min entropy: 347613\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.60 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 16\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097]\n",
      "\n",
      "Max Accuracy: 97.18\n",
      "Min entropy: 347613\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 29.63 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 17\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625]\n",
      "\n",
      "Max Accuracy: 97.31\n",
      "Min entropy: 334625\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 33.52 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 18\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834]\n",
      "\n",
      "Max Accuracy: 97.31\n",
      "Min entropy: 284834\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 33.42 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 19\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365]\n",
      "\n",
      "Max Accuracy: 97.31\n",
      "Min entropy: 245365\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 33.37 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 20\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084]\n",
      "\n",
      "Max Accuracy: 97.33\n",
      "Min entropy: 245365\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 33.07 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 21\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33, 97.41]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084, 249338]\n",
      "\n",
      "Max Accuracy: 97.41\n",
      "Min entropy: 245365\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 32.65 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 22\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33, 97.41, 95.87]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084, 249338, 359194]\n",
      "\n",
      "Max Accuracy: 97.41\n",
      "Min entropy: 245365\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 32.85 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 23\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33, 97.41, 95.87, 97.52]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084, 249338, 359194, 201817]\n",
      "\n",
      "Max Accuracy: 97.52\n",
      "Min entropy: 201817\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 32.60 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 24\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33, 97.41, 95.87, 97.52, 97.58]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084, 249338, 359194, 201817, 231419]\n",
      "\n",
      "Max Accuracy: 97.58\n",
      "Min entropy: 201817\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 32.57 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 25\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33, 97.41, 95.87, 97.52, 97.58, 97.62]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084, 249338, 359194, 201817, 231419, 327078]\n",
      "\n",
      "Max Accuracy: 97.62\n",
      "Min entropy: 201817\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 32.08 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 26\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33, 97.41, 95.87, 97.52, 97.58, 97.62, 97.51]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084, 249338, 359194, 201817, 231419, 327078, 238666]\n",
      "\n",
      "Max Accuracy: 97.62\n",
      "Min entropy: 201817\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 32.38 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 27\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33, 97.41, 95.87, 97.52, 97.58, 97.62, 97.51, 97.7]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084, 249338, 359194, 201817, 231419, 327078, 238666, 434503]\n",
      "\n",
      "Max Accuracy: 97.7\n",
      "Min entropy: 201817\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 31.83 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 28\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33, 97.41, 95.87, 97.52, 97.58, 97.62, 97.51, 97.7, 97.65]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084, 249338, 359194, 201817, 231419, 327078, 238666, 434503, 415447]\n",
      "\n",
      "Max Accuracy: 97.7\n",
      "Min entropy: 201817\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 31.90 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 29\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33, 97.41, 95.87, 97.52, 97.58, 97.62, 97.51, 97.7, 97.65, 97.5]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084, 249338, 359194, 201817, 231419, 327078, 238666, 434503, 415447, 349591]\n",
      "\n",
      "Max Accuracy: 97.7\n",
      "Min entropy: 201817\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 32.09 seconds\n",
      "\n",
      "C=6, lr=0.0007, lambda_reg=0.0015, alpha=0.533, subgradient_step=100000.0, w0=-0.11, r=1.11, target_acc=98.99, target_entr=996020.0, min_xi=0, max_xi=1, n_epochs=100, train_optimizer=A entropy_optimizer=F\n",
      "\n",
      "Epoch: 30\n",
      "\n",
      "Accuracies: [69.41, 81.88, 89.02, 91.56, 94.01, 94.63, 95.4, 95.5, 95.99, 95.9, 95.86, 96.25, 96.91, 97.18, 97.05, 97.17, 97.31, 96.67, 97.2, 97.33, 97.41, 95.87, 97.52, 97.58, 97.62, 97.51, 97.7, 97.65, 97.5, 97.74]\n",
      "\n",
      "Entropies: [685781, 684225, 681990, 674962, 671209, 658463, 620243, 521093, 573884, 491500, 520422, 468308, 419451, 347613, 406974, 476097, 334625, 284834, 245365, 399084, 249338, 359194, 201817, 231419, 327078, 238666, 434503, 415447, 349591, 492590]\n",
      "\n",
      "Max Accuracy: 97.74\n",
      "Min entropy: 201817\n",
      "------------------------------------------------------------\n",
      "Time taken for a epoch: 31.95 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import product\n",
    "import math\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from torch.linalg import norm\n",
    "\n",
    "# Define the LeNet-5 architecture\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # First convolutional layer: input 1 channel, output 6 channels, kernel size 5x5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        # Average pooling layer with kernel size 2x2 and stride 2\n",
    "        self.pool = nn.AvgPool2d(2, 2)\n",
    "        # Second convolutional layer: input 6 channels, output 16 channels, kernel size 5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)  # Flattened input size 16*4*4, output 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # Output 84 neurons\n",
    "        self.fc3 = nn.Linear(84, 10)  # Output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first convolution, then activation function (tanh), then pooling\n",
    "        x = torch.tanh(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # Apply second convolution, then activation function (tanh), then pooling\n",
    "        x = torch.tanh(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        # Pass through fully connected layers with activation (tanh)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        # Output layer without activation (raw scores for classification)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def compute_entropy(string):\n",
    "    \"\"\"\n",
    "    Function to compute the entropy of a given string.\n",
    "    \"\"\"\n",
    "    # Count the frequency of each character in the string\n",
    "    frequencies = Counter(string)\n",
    "    # Calculate the total length of the string\n",
    "    total_length = len(string)\n",
    "    \n",
    "    # Compute entropy\n",
    "    entropy = 0\n",
    "    for freq in frequencies.values():\n",
    "        probability = freq / total_length  # Compute probability of each character\n",
    "        entropy -= probability * math.log2(probability)  # Apply entropy formula\n",
    "    \n",
    "    return entropy * total_length  # Return the entropy weighted by string length\n",
    "            \n",
    "def test_accuracy(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Function to calculate the accuracy of a model on a given dataloader.\n",
    "    \"\"\"\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to the appropriate device\n",
    "            outputs = model(images)  # Get model predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the class with the highest probability\n",
    "            total += labels.size(0)  # Update total number of samples\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "    \n",
    "    accuracy = 100 * correct / total  # Compute accuracy percentage\n",
    "    return accuracy\n",
    "\n",
    "def knapsack_specialized(xi, v, w, C):\n",
    "    \"\"\"\n",
    "    Solves a specialized knapsack problem using a specialized method in a vectorized way\n",
    "\n",
    "    Args:\n",
    "        xi (torch.Tensor): xi variables.\n",
    "        v (torch.Tensor): Quantization vector.\n",
    "        w (torch.Tensor): Weight vector.\n",
    "        C (int): Number of buckets of quantization.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Optimal allocation (x_opt), optimal multipliers (lambda_opt), and objective values.\n",
    "    \"\"\"\n",
    "    \n",
    "    b_list = []\n",
    "    b = 0\n",
    "\n",
    "    # Compute breakpoint vector x_plus\n",
    "    while True:\n",
    "        delta_xi = (xi[b + 1:] - xi[b])\n",
    "        delta_v = (v[b + 1:] - v[b])\n",
    "        b = torch.argmin(delta_xi / delta_v) + 1 + b_list[-1] if b_list else 0\n",
    "\n",
    "        if b != C - 1:\n",
    "            b_list.append(int(b))\n",
    "\n",
    "        if b + 1 > C - 1:\n",
    "            break\n",
    "    b_list.append(C - 1)\n",
    "    x_plus = torch.zeros(C, dtype=torch.int32)\n",
    "    b_tensor = torch.tensor(b_list, dtype=torch.int32)\n",
    "    x_plus[b_tensor] = 1\n",
    "\n",
    "    # Determine optimal allocation based on w\n",
    "    w_idx = torch.searchsorted(v, w) \n",
    "    indices_breakpoints = torch.nonzero(x_plus == 1).squeeze()\n",
    "\n",
    "    # Creation of masks for extreme cases\n",
    "    mask_right = w > v[-1]\n",
    "    mask_left = w < v[0]\n",
    "\n",
    "    # Find indices using searchsorted\n",
    "    search_idx = torch.searchsorted(indices_breakpoints, w_idx)\n",
    "\n",
    "    # Ensure that the indices are valid\n",
    "    search_idx = torch.clamp(search_idx, 1, len(indices_breakpoints) - 1)\n",
    "\n",
    "    # Initialize idx_right and idx_left with the result of the search\n",
    "    idx_right = indices_breakpoints[search_idx]\n",
    "    idx_left = indices_breakpoints[search_idx - 1]\n",
    "\n",
    "    # Correct the indices for extreme cases\n",
    "    idx_right = torch.where(mask_right, indices_breakpoints[-1], idx_right)\n",
    "    idx_left = torch.where(mask_right, indices_breakpoints[-1], idx_left)\n",
    "\n",
    "    # Correct the indices for the case when w < v[0]\n",
    "    idx_right = torch.where(mask_left, indices_breakpoints[0], idx_right)\n",
    "    idx_left = torch.where(mask_left, indices_breakpoints[0], idx_left)\n",
    "\n",
    "    # Compute convex combination for optimal solution\n",
    "    x1, x2 = torch.zeros(2, len(w), C, dtype=torch.float32)\n",
    "\n",
    "    x1[torch.arange(len(w)), idx_left] = 1\n",
    "    x2[torch.arange(len(w)), idx_right] = 1\n",
    "\n",
    "    numerator = w - torch.matmul(x2, v)\n",
    "    denominator = torch.matmul((x1 - x2), v)\n",
    "    theta = numerator / denominator\n",
    "\n",
    "    mask_equal = (x1 == x2)\n",
    "    theta_expanded = theta.unsqueeze(1)\n",
    "    x_opt = torch.where(mask_equal, x1, x1 * theta_expanded + x2 * (1 - theta_expanded))\n",
    "\n",
    "    # Compute optimal multipliers\n",
    "    denominator = (v[idx_right] - v[idx_left])\n",
    "    denominator_zero_mask = denominator == 0\n",
    "\n",
    "    lambda_opt_nonzero = (xi[idx_right] - xi[idx_left]) / denominator\n",
    "    lambda_opt_zero_full = xi / v\n",
    "    lambda_opt_zero_full[0] = 0\n",
    "    lambda_opt_zero = lambda_opt_zero_full[idx_left]\n",
    "\n",
    "    lambda_opt = torch.where(denominator_zero_mask, lambda_opt_zero, lambda_opt_nonzero)\n",
    "\n",
    "    # Compute objective function values\n",
    "    objective_values = torch.matmul(x_opt, xi)\n",
    "\n",
    "    return x_opt, lambda_opt, objective_values\n",
    "\n",
    "def FISTA(xi, v, w, C, subgradient_step, max_iterations):\n",
    "    \"\"\"\n",
    "    Implements the Fast Iterative Shrinking-Thresholding Algorithm (FISTA) \n",
    "    for optimizing a constrained objective function.\n",
    "\n",
    "    Args:\n",
    "        xi (torch.Tensor): Initial parameter vector.\n",
    "        v (torch.Tensor): Constraint-related vector.\n",
    "        w (torch.Tensor): Weight vector.\n",
    "        C (float): Constraint parameter.\n",
    "        subgradient_step (float): Step size for subgradient descent.\n",
    "        max_iterations (int): Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated xi, lambda_plus (Lagrange multiplier), \n",
    "               x_i_star (optimal allocation), and phi (objective function value).\n",
    "    \"\"\"\n",
    "    \n",
    "    upper_c = w.size(0)  # Define an upper bound for constraints\n",
    "    \n",
    "    # Initialize previous values for FISTA acceleration\n",
    "    xi_prev = xi.clone()\n",
    "    t_prev = torch.tensor(1.0)\n",
    "\n",
    "    for iteration in range(1, max_iterations + 1):\n",
    "        # Solve the simil-knapsack problem for the current xi\n",
    "        x_i_star, lambda_plus, phi_plus = knapsack_specialized(xi, v, w, C)\n",
    "        sum_x_star = torch.sum(x_i_star, dim=0)\n",
    "\n",
    "        # Compute the optimal c values c_star\n",
    "        c_star = torch.exp(torch.log(torch.tensor(2)) * xi - 1)\n",
    "        c_star = torch.clamp(c_star, min=0, max=upper_c)\n",
    "\n",
    "        # Compute the super-gradient\n",
    "        g = -(c_star - sum_x_star)\n",
    "        \n",
    "        # Compute the 3 pieces of the objective function value phi and put them together\n",
    "        phi1 = torch.sum(c_star * torch.log(c_star) / torch.log(torch.tensor(2)))\n",
    "        phi2 = -torch.sum(xi * c_star)\n",
    "        phi3 = torch.sum(xi * sum_x_star)\n",
    "        phi = phi1 + phi2 + phi3\n",
    "\n",
    "        # FISTA acceleration step\n",
    "        t_current = (1 + torch.sqrt(1 + 4 * t_prev**2)) / 2\n",
    "        y = xi + ((t_prev - 1) / t_current) * (xi - xi_prev)\n",
    "\n",
    "        # Gradient update step\n",
    "        xi_next = y + (1 / subgradient_step) * g \n",
    "\n",
    "        # Update variables for next iteration\n",
    "        xi_prev = xi.clone()\n",
    "        xi = xi_next.clone()\n",
    "        t_prev = t_current\n",
    "\n",
    "        # Ensure xi remains sorted\n",
    "        xi = torch.sort(xi)[0]\n",
    "\n",
    "    return xi, lambda_plus, x_i_star, phi\n",
    "\n",
    "def ProximalBM(xi, v, w, C, zeta, subgradient_step, max_iterations):\n",
    "    \"\"\"\n",
    "    Implements the Proximal Bundle Method (PBM) for solving constrained \n",
    "    optimization problems using bundle techniques.\n",
    "\n",
    "    Args:\n",
    "        xi (torch.Tensor): Initial parameter vector.\n",
    "        v (torch.Tensor): Constraint-related vector.\n",
    "        w (torch.Tensor): Weight vector.\n",
    "        C (float): Constraint parameter.\n",
    "        zeta (float): Regularization parameter for proximal term.\n",
    "        subgradient_step (float): Step size for subgradient descent.\n",
    "        max_iterations (int): Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated xi, lambda_plus (Lagrange multiplier), \n",
    "               x_i_star (optimal allocation), and phi (objective function value).\n",
    "    \"\"\"\n",
    "    \n",
    "    upper_c = w.size(0)  # Define an upper bound for constraints\n",
    "\n",
    "    # Parameters for the bundle method\n",
    "    epsilon = 1e-5  # Convergence tolerance\n",
    "    bundle_size = 5  # Maximum bundle size\n",
    "    bundle = []  # Initialize the bundle (list of points, phi values, and gradients)\n",
    "\n",
    "    for iteration in range(1, max_iterations + 1):\n",
    "        # Solve the knapsack problem for the current xi\n",
    "        x_i_star, lambda_plus, phi_plus = knapsack_specialized(xi, v, w, C)\n",
    "        sum_x_star = torch.sum(x_i_star, dim=0)\n",
    "\n",
    "        # Compute the optimal c values c_star\n",
    "        c_star = torch.exp(torch.log(torch.tensor(2)) * xi - 1)\n",
    "        c_star = torch.clamp(c_star, min=0, max=upper_c)\n",
    "\n",
    "        # Compute the super-gradient\n",
    "        g = -(c_star - sum_x_star)\n",
    "\n",
    "        # Compute the objective function value phi\n",
    "        phi1 = torch.sum(c_star * torch.log(c_star) / torch.log(torch.tensor(2)))\n",
    "        phi2 = -torch.sum(xi * c_star)\n",
    "        phi3 = torch.sum(xi * sum_x_star)\n",
    "        phi = phi1 + phi2 + phi3\n",
    "\n",
    "        # Add the current point to the bundle\n",
    "        bundle.append((xi.clone(), phi, g.clone()))\n",
    "        if len(bundle) > bundle_size:\n",
    "            bundle.pop(0)  # Remove the oldest point if the bundle exceeds max size\n",
    "\n",
    "        # Solve the quadratic regularization subproblem\n",
    "        bundle_points = torch.stack([item[0] for item in bundle])  # Bundle points\n",
    "        bundle_phis = torch.tensor([item[1] for item in bundle])  # Phi values\n",
    "        bundle_gradients = torch.stack([item[2] for item in bundle])  # Gradient values\n",
    "\n",
    "        # Construct the quadratic approximation model\n",
    "        diff = xi - bundle_points\n",
    "        model_phi = bundle_phis + torch.sum(bundle_gradients * diff, dim=1)\n",
    "        proximal_term = (zeta / 2) * norm(diff, dim=1)**2\n",
    "        subproblem_objective = model_phi + proximal_term\n",
    "\n",
    "        # Determine the next xi by minimizing the subproblem objective\n",
    "        best_idx = torch.argmin(subproblem_objective)\n",
    "        xi_next = bundle_points[best_idx] + (1 / zeta) * bundle_gradients[best_idx]\n",
    "\n",
    "        # Clip xi to enforce constraints\n",
    "        xi_next = torch.clamp(xi_next, min=0.01, max=upper_c)\n",
    "\n",
    "        # Check for convergence\n",
    "        if norm(xi_next - xi) < epsilon:\n",
    "            break\n",
    "\n",
    "        # Update xi for the next iteration\n",
    "        xi = xi_next.clone()\n",
    "        \n",
    "    return xi, lambda_plus, x_i_star, phi\n",
    "\n",
    "def initialize_weights(model, min_w, max_w):\n",
    "    \"\"\"\n",
    "    Initializes the weights of a given model using a uniform distribution.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model whose weights need initialization.\n",
    "        min_w (float): Minimum value for weight initialization.\n",
    "        max_w (float): Maximum value for weight initialization.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        torch.nn.init.uniform_(param, a=min_w, b=max_w)\n",
    "\n",
    "def train_and_evaluate(C, lr, lambda_reg, alpha, subgradient_step, w0, r, \n",
    "                       target_acc, target_entr, min_xi, max_xi, n_epochs, device, \n",
    "                       train_optimizer, entropy_optimizer, trainloader, testloader):\n",
    "    \n",
    "    model = LeNet5().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if(train_optimizer == 'A'):\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=lambda_reg * alpha)\n",
    "    elif(train_optimizer == 'S'):\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=lambda_reg * alpha)\n",
    "    \n",
    "    # Parameters initialization\n",
    "    min_w, max_w = w0 - r, w0 + r\n",
    "    v = torch.linspace(min_w, max_w - (max_w - min_w)/C, steps=C)\n",
    "    initialize_weights(model, min_w, max_w)    \n",
    "    w = torch.cat([param.data.view(-1) for param in model.parameters()])\n",
    "    upper_c, lower_c = w.size(0), 1e-2\n",
    "    xi = min_xi + (max_xi - min_xi) * torch.rand(C, device=device)    \n",
    "    xi = torch.sort(xi)[0]   \n",
    "    entropy, accuracy = 0, 0\n",
    "    accuracies, entropies, distinct_weights = [], [], []\n",
    "    zeta, l = 50000, 0.5\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            w = torch.cat([param.data.view(-1) for param in model.parameters()])\n",
    "            #unique_weights = torch.unique(w).numel() \n",
    "            #indices = torch.searchsorted(v, w, right=True) - 1\n",
    "            #indices = torch.clamp(indices, min=0)\n",
    "            #w_quantized = v[indices]\n",
    "\n",
    "            zeta *= 1 + l\n",
    "            l = l / 1.5\n",
    "            if(entropy_optimizer == 'F'):\n",
    "                #xi, beta_tensor, x_star, phi = FISTA(xi, v, w_quantized, C, subgradient_step, max_iterations=15) \n",
    "                xi, beta_tensor, x_star, phi = FISTA(xi, v, w, C, subgradient_step, max_iterations=15) \n",
    "            elif(entropy_optimizer == 'PM'):\n",
    "                #xi, beta_tensor, x_star, phi = ProximalBM(xi, v, w_quantized, C, zeta, subgradient_step, max_iterations=15) \n",
    "                xi, beta_tensor, x_star, phi = ProximalBM(xi, v, w, C, zeta, subgradient_step, max_iterations=15)      \n",
    "            \n",
    "            # Update of ∇ɸ\n",
    "            idx = 0\n",
    "            for param in model.parameters():\n",
    "                numel = param.numel()\n",
    "                if param.grad is not None:\n",
    "                    param_grad = param.grad.view(-1)\n",
    "                else:\n",
    "                    param_grad = torch.zeros_like(param.data.view(-1))\n",
    "                param_grad += (1 - alpha) * lambda_reg * beta_tensor[idx:idx + numel]\n",
    "                param.grad = param_grad.view(param.size())\n",
    "                idx += numel\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        w = torch.cat([param.data.view(-1) for param in model.parameters()])\n",
    "        \n",
    "        entropy = round(compute_entropy(w.tolist())) + 1\n",
    "        entropies.append(entropy)\n",
    "        accuracy = test_accuracy(model, testloader, device)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"C={C}, lr={lr}, lambda_reg={lambda_reg}, \"\n",
    "              f\"alpha={alpha}, subgradient_step={subgradient_step}, w0={w0}, r={r}, \"\n",
    "              f\"target_acc={target_acc}, target_entr={target_entr}, \"\n",
    "              f\"min_xi={min_xi}, max_xi={max_xi}, n_epochs={n_epochs}, train_optimizer={train_optimizer} \"\n",
    "              f\"entropy_optimizer={entropy_optimizer}\")\n",
    "        print(\"\\nEpoch:\", epoch+1)\n",
    "        print(\"\\nAccuracies:\", accuracies)\n",
    "        print(\"\\nEntropies:\", entropies)\n",
    "        print(\"\\nMax Accuracy:\", max(accuracies))\n",
    "        print(\"Min entropy:\", min(entropies))\n",
    "\n",
    "        # Saving a better model\n",
    "        if(accuracy >= target_acc and entropy <= target_entr):\n",
    "            print(\"💥💥💥💥💥💥💥\\n💥ATTENTION!💥\\n💥💥💥💥💥💥💥\")\n",
    "            torch.save(model.state_dict(), f\"BestModelsBeforeQuantization/C{C}_r{round(r*1000)}.pth\")\n",
    "            target_acc = accuracy\n",
    "            target_entr = entropy\n",
    "        \n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        # Entropy exit conditions\n",
    "        if(epoch > 20 and entropy > 600000):\n",
    "            print(\"Entropy is not decreasing enough! (A)\")\n",
    "            return accuracy, entropy, target_acc, target_entr\n",
    "        if(epoch > 50):\n",
    "            if(entropies[-1] > 200000 and entropies[-2] > 200000 and entropies[-3] > 200000 and entropies[-4] > 200000):\n",
    "                print(\"Entropy is not decreasing enough! (B)\")\n",
    "                return accuracy, entropy, target_acc, target_entr           \n",
    "            \n",
    "        # Accuracy exit condition\n",
    "        if(epoch == 1 and accuracies[-1] < 70):\n",
    "            print(\"Accuracy is too low! (C)\")\n",
    "            return accuracy, entropy, target_acc, target_entr                    \n",
    "        if(epoch > 10):\n",
    "            if(accuracies[-1] < 90 and accuracies[-2] < 90 and accuracies[-3] < 90 and accuracies[-4] < 90):\n",
    "                print(\"Accuracy is too low! (D)\")\n",
    "                return accuracy, entropy, target_acc, target_entr     \n",
    "        \n",
    "        # ... ADD OTHER EXIT CONDITIONS ...      \n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"Time taken for a epoch: {training_time:.2f} seconds\\n\")\n",
    "              \n",
    "    return accuracy, entropy, target_acc, target_entr\n",
    "\n",
    "# Select the computing device: use GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Define a transformation: convert images to tensors\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "# Load the MNIST training dataset with the defined transformation\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# Create a DataLoader for the training set with batch size 64, shuffling enabled, and 4 worker threads\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\n",
    "# Load the MNIST test dataset with the same transformation\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "# Create a DataLoader for the test set with batch size 1000, shuffling disabled, and 4 worker threads\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=4)\n",
    "\n",
    "np.set_printoptions(precision=6)\n",
    "\n",
    "# Grid search \n",
    "param_grid = {\n",
    "    \"C\": [6, 256],  # Number of buckets of quantization\n",
    "    \"lr\": [0.0007], # Learning rate for the optimizer\n",
    "    \"lambda_reg\": [0.0015], # Regularization factor\n",
    "    \"alpha\": [0.533], # Percentage of standard regularization wrt entropic one \n",
    "    \"subgradient_step\": [1e5],  # Step size for subgradient\n",
    "    \"w0\": [-0.11], # Initial weight parameters\n",
    "    \"r\": [round(1.1 + i * 0.002, 3) for i in range(10)],\n",
    "    \"target_acc\": [98.99], # Target accuracy percentage\n",
    "    \"target_entr\": [0.99602e6], # Target entropy threshold \n",
    "    \"min_xi\": [0], # lower bound for xi initialization\n",
    "    \"max_xi\": [1],  # upper bound for xi initialization\n",
    "    \"n_epochs\": [100], # Number of training epochs\n",
    "    \"device\": [device], # Computing device (GPU or CPU)\n",
    "    \"train_optimizer\": ['A'],  # 'A' for Adam, and 'S' for SGD\n",
    "    \"entropy_optimizer\": ['F'], # 'F' for FISTA, 'PM' for proximal bundle\n",
    "    \"trainloader\": [trainloader],  # Training data loader\n",
    "    \"testloader\": [testloader] # Test data loader\n",
    "}\n",
    "\n",
    "combination = 0\n",
    "\n",
    "for (C, lr, lambda_reg, alpha, subgradient_step, w0, r, \n",
    "     target_acc, target_entr, min_xi, max_xi, n_epochs, \n",
    "     device, train_optimizer, entropy_optimizer, trainloader, \n",
    "     testloader) in product(param_grid[\"C\"],\n",
    "                            param_grid[\"lr\"],\n",
    "                            param_grid[\"lambda_reg\"],\n",
    "                            param_grid[\"alpha\"],\n",
    "                            param_grid[\"subgradient_step\"],\n",
    "                            param_grid[\"w0\"],\n",
    "                            param_grid[\"r\"],\n",
    "                            param_grid[\"target_acc\"],\n",
    "                            param_grid[\"target_entr\"],\n",
    "                            param_grid[\"min_xi\"],\n",
    "                            param_grid[\"max_xi\"],\n",
    "                            param_grid[\"n_epochs\"],\n",
    "                            param_grid[\"device\"],\n",
    "                            param_grid[\"train_optimizer\"],      \n",
    "                            param_grid[\"entropy_optimizer\"],   \n",
    "                            param_grid[\"trainloader\"], \n",
    "                            param_grid[\"testloader\"]\n",
    "                            ):\n",
    "    \n",
    "    # Counts combinations\n",
    "    combination += 1\n",
    "    \n",
    "    # Start training\n",
    "    start_time = time.time()\n",
    "    accuracy, entropy, target_acc, target_entr = train_and_evaluate(C=C,              \n",
    "                                                                lr=lr,           \n",
    "                                                                lambda_reg=lambda_reg,    \n",
    "                                                                alpha=alpha,          \n",
    "                                                                subgradient_step=subgradient_step, \n",
    "                                                                w0=w0,             \n",
    "                                                                r=r,              \n",
    "                                                                target_acc=target_acc,      \n",
    "                                                                target_entr=target_entr, \n",
    "                                                                min_xi=min_xi,              \n",
    "                                                                max_xi=max_xi,             \n",
    "                                                                n_epochs=n_epochs,        \n",
    "                                                                device=device,      \n",
    "                                                                train_optimizer=train_optimizer,     \n",
    "                                                                entropy_optimizer=entropy_optimizer,   \n",
    "                                                                trainloader=trainloader, \n",
    "                                                                testloader=testloader     \n",
    "                                                            )\n",
    "        \n",
    "    training_time = time.time() - start_time\n",
    "    print(f'Time spent to train the model: {training_time:.2f} seconds\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[round(1.1 + i * 0.002, 3) for i in range(10)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
